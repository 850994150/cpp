
<!-- TOC -->

- [C++语言基础](#c语言基础)
    - [`i++ / ++i` 是否为原子操作？](#i--i-是否为原子操作)
    - [类里面`static`和`const`可以同时修饰成员函数吗](#类里面static和const可以同时修饰成员函数吗)
    - [`C++`中的四种类型转换方式](#c中的四种类型转换方式)
    - [编译过程](#编译过程)
    - [`make`](#make)
        - [`core dump`调试](#core-dump调试)
        - [动态静态库](#动态静态库)
    - [同步与阻塞的概念](#同步与阻塞的概念)
    - [五种 `I/O` 模型](#五种-io-模型)
    - [`select` 检测到可读，调用read的情况](#select-检测到可读调用read的情况)
    - [如果一个单线程阻塞了一个系统调用，比如read,如何解决](#如果一个单线程阻塞了一个系统调用比如read如何解决)
    - [`select & epoll`](#select--epoll)
    - [`select 和 epoll` 的区别](#select-和-epoll-的区别)
    - [`select 和 poll` 的区别](#select-和-poll-的区别)
    - [`epoll` 两种触发模式](#epoll-两种触发模式)
    - [为什么浮点数有误差](#为什么浮点数有误差)
    - [如何判断两个浮点数是否相等，为什么不用 ==](#如何判断两个浮点数是否相等为什么不用-)
    - [比较结构体是否相等](#比较结构体是否相等)
    - [`main` 函数和启动例程](#main-函数和启动例程)
    - [`main` 函数不能被调用， 为什么还需要返回值](#main-函数不能被调用-为什么还需要返回值)
    - [如何获取`main`函数的返回值](#如何获取main函数的返回值)
    - [`main` 函数结束后就结束了吗？](#main-函数结束后就结束了吗)
    - [函数调用过程](#函数调用过程)
    - [`printf` 是怎么可以输出多个和不同类型的数据的](#printf-是怎么可以输出多个和不同类型的数据的)
    - [为什么没有格式化字符串没有也能输出字符串?](#为什么没有格式化字符串没有也能输出字符串)
    - [格式化字符串漏洞](#格式化字符串漏洞)
    - [`printf` 函数参数](#printf-函数参数)
    - [`__stdcall` 和 `__cdecl`的区别](#__stdcall-和-__cdecl的区别)
    - [`this` 指针调用成员函数时的压栈和相关寄存器使用？](#this-指针调用成员函数时的压栈和相关寄存器使用)
    - [函数符号生成规则](#函数符号生成规则)
    - [位操作](#位操作)
    - [操作符优先级](#操作符优先级)
    - [为什么要分内核态和用户态](#为什么要分内核态和用户态)
    - [内核态和用户态区别](#内核态和用户态区别)
    - [系统调用和库函数调用的区别](#系统调用和库函数调用的区别)
    - [为什么系统调用比库函数调用更耗时?](#为什么系统调用比库函数调用更耗时)
    - [结构体与联合体的区别](#结构体与联合体的区别)
    - [结构体和类的区别](#结构体和类的区别)
    - [结构体对齐`sizeof`](#结构体对齐sizeof)
    - [结构体为什么要对齐字节](#结构体为什么要对齐字节)
    - [说一说 `static`](#说一说-static)
    - [说一说 `extern`](#说一说-extern)
    - [说一说 `explicit`](#说一说-explicit)
    - [说一说 `const`](#说一说-const)
    - [说一说 `mutable`](#说一说-mutable)
    - [两个一样的函数，一个带const，一个不带，会有问题吗?](#两个一样的函数一个带const一个不带会有问题吗)
    - [说一说 `volatile`](#说一说-volatile)
    - [`volatile`能保证线程安全吗?](#volatile能保证线程安全吗)
    - [`const` 和 `#define` 的区别](#const-和-define-的区别)
    - [`typedef`和`#define`的区别](#typedef和define的区别)
    - [`inline`和`#define`的区别](#inline和define的区别)
    - [什么技术可以代替宏定义 `#define`](#什么技术可以代替宏定义-define)
    - [内联函数和成员函数的区别](#内联函数和成员函数的区别)
    - [`new`和`malloc`的区别](#new和malloc的区别)
    - [字符操作函数 `#include <string.h>`](#字符操作函数-include-stringh)
    - [哪些情况一定要使用初始化成员列表](#哪些情况一定要使用初始化成员列表)
    - [虚函数表](#虚函数表)
    - [虚函数表并不很安全](#虚函数表并不很安全)
    - [虚函数的入口地址和普通函数有什么不同？](#虚函数的入口地址和普通函数有什么不同)
    - [子类指针可不可以指向父类对象呢？](#子类指针可不可以指向父类对象呢)
    - [父类的指针，怎么调用子类的虚函数？调用流程是什么](#父类的指针怎么调用子类的虚函数调用流程是什么)
    - [父类指针指向子类对象，指向的是哪张虚函数表？](#父类指针指向子类对象指向的是哪张虚函数表)
    - [抽象类和纯虚函数](#抽象类和纯虚函数)
    - [虚函数和纯虚函数的区别](#虚函数和纯虚函数的区别)
    - [析构函数的作用](#析构函数的作用)
    - [为什么要用虚析构？](#为什么要用虚析构)
    - [为什么默认的析构函数不是虚析构？](#为什么默认的析构函数不是虚析构)
    - [引用是否能实现动态绑定，为什么引用可以实现](#引用是否能实现动态绑定为什么引用可以实现)
    - [为什么构造函数不声明为虚函数呢？](#为什么构造函数不声明为虚函数呢)
    - [拷贝构造函数的参数不是引用可以吗?](#拷贝构造函数的参数不是引用可以吗)
    - [哪些情况用到拷贝构造函数？](#哪些情况用到拷贝构造函数)
    - [哪些自动生成的构造函数需要禁止，为什么](#哪些自动生成的构造函数需要禁止为什么)
    - [`operator char()` 什么意思?](#operator-char-什么意思)
    - [虚继承](#虚继承)
    - [访问权限和继承权限](#访问权限和继承权限)
    - [多态实现方式](#多态实现方式)
        - [`RTTI`的使用？](#rtti的使用)
    - [对象三种创建方式](#对象三种创建方式)
    - [友元](#友元)
    - [指针](#指针)
        - [`printf`输出字符串指针](#printf输出字符串指针)
        - [数组和指针的区别](#数组和指针的区别)
        - [数组指针、指针数组、函数指针](#数组指针指针数组函数指针)
        - [引用和指针的区别](#引用和指针的区别)
        - [智能指针的原理是什么](#智能指针的原理是什么)
        - [智能指针什么时候改变引用计数？ (shared_ptr使用引用计数)](#智能指针什么时候改变引用计数-shared_ptr使用引用计数)
        - [你知道的智能指针有哪些？](#你知道的智能指针有哪些)
        - [野指针](#野指针)
    - [柔性数组](#柔性数组)
    - [STL](#stl)
        - [容器](#容器)
        - [结构](#结构)
    - [使用两个栈实现一个队列](#使用两个栈实现一个队列)
    - [使用两个队列实现一个栈](#使用两个队列实现一个栈)
    - [可变参数](#可变参数)
    - [你对内存的了解](#你对内存的了解)
    - [内存溢出和内存泄漏](#内存溢出和内存泄漏)
    - [堆栈的区别](#堆栈的区别)
    - [段页式存储管理](#段页式存储管理)
    - [`mmap`](#mmap)
    - [虚拟地址是怎么映射到物理地址的，说一下这个过程](#虚拟地址是怎么映射到物理地址的说一下这个过程)
- [操作系统](#操作系统)
    - [进程](#进程)
        - [`fork`](#fork)
        - [僵尸进程、孤儿进程](#僵尸进程孤儿进程)
        - [`wait 和 waitpid` 的区别](#wait-和-waitpid-的区别)
        - [守护进程](#守护进程)
        - [`IPC`进程间通信](#ipc进程间通信)
    - [线程](#线程)
        - [多线程编程会带来什么问题](#多线程编程会带来什么问题)
        - [进程和线程的区别](#进程和线程的区别)
        - [线程状态](#线程状态)
        - [`Linux` 编程中的锁有哪些](#linux-编程中的锁有哪些)
        - [自旋锁和互斥锁的区别](#自旋锁和互斥锁的区别)
        - [条件变量的使用](#条件变量的使用)
        - [互斥锁](#互斥锁)
        - [死锁](#死锁)
        - [线程死锁](#线程死锁)
        - [生产者消费者问题](#生产者消费者问题)
        - [线程池](#线程池)
    - [协程](#协程)
    - [大小端](#大小端)
    - [哈希](#哈希)
        - [解决哈希冲突的方法](#解决哈希冲突的方法)
    - [信号](#信号)
        - [常见信号](#常见信号)
        - [进程如何处理收到的信号](#进程如何处理收到的信号)
        - [信号传递机制](#信号传递机制)
        - [系统如何将一个信号通知到进程？](#系统如何将一个信号通知到进程)
- [计算机网络和网络安全](#计算机网络和网络安全)
    - [分层模型](#分层模型)
    - [`ARP`](#arp)
        - [`Arp`欺骗](#arp欺骗)
    - [`TCP/UDP`的区别](#tcpudp的区别)
    - [三次握手](#三次握手)
    - [如果已经建立了连接，但是客户端突然出现故障了怎么办?](#如果已经建立了连接但是客户端突然出现故障了怎么办)
    - [三次握手过程网络中会发生什么错误](#三次握手过程网络中会发生什么错误)
    - [全连接、半连接](#全连接半连接)
    - [`SYN`攻击](#syn攻击)
    - [`SYN` 防洪防范措施](#syn-防洪防范措施)
    - [四次挥手](#四次挥手)
    - [为什么握手三次, 而挥手要四次](#为什么握手三次-而挥手要四次)
    - [只有两次握手行不行?](#只有两次握手行不行)
    - [`Time_Wait`为什么要等待`2MSL`](#time_wait为什么要等待2msl)
    - [如何避免 Time_wait](#如何避免-time_wait)
    - [TCP重传机制](#tcp重传机制)
    - [TCP确认机制](#tcp确认机制)
    - [滑动窗口机制](#滑动窗口机制)
    - [长连接、短链接](#长连接短链接)
    - [`GET`请求和`POST`请求的区别](#get请求和post请求的区别)
    - [浏览器输入地址后发生了什么](#浏览器输入地址后发生了什么)
    - [常用端口](#常用端口)
    - [拥塞](#拥塞)
        - [拥塞控制方法](#拥塞控制方法)
    - [`TCP`的超时重传](#tcp的超时重传)
    - [指数退避](#指数退避)
    - [对称加密、非对称加密](#对称加密非对称加密)
    - [`SSL`四次握手](#ssl四次握手)
    - [`HTTPS`](#https)
    - [`HTTP` 和 `HTTPS` 的区别](#http-和-https-的区别)
    - [挑战响应认证](#挑战响应认证)
    - [`socket`](#socket)
        - [`socket`在什么情况下可读](#socket在什么情况下可读)
        - [`socket`在什么情况下可写](#socket在什么情况下可写)
        - [`connect` 会阻塞，怎么解决](#connect-会阻塞怎么解决)
        - [`send 和 recv` 阻塞和非阻塞模式](#send-和-recv-阻塞和非阻塞模式)
        - [read 常见错误码](#read-常见错误码)
        - [send/recv 和 write/read的区别](#sendrecv-和-writeread的区别)
- [设计模式](#设计模式)
    - [单例模式](#单例模式)
- [数据结构](#数据结构)
    - [排序](#排序)
        - [写个快排看看、如何优化？不用递归怎么写](#写个快排看看如何优化不用递归怎么写)
    - [队列和栈](#队列和栈)
        - [用栈来判断括号是否匹配](#用栈来判断括号是否匹配)
        - [用两个栈实现一个队列](#用两个栈实现一个队列)
        - [用两个队列实现一个栈](#用两个队列实现一个栈)
    - [链表](#链表)
        - [构造带头结点链表和插入](#构造带头结点链表和插入)
        - [冒泡排序](#冒泡排序)
        - [翻转链表](#翻转链表)
        - [输出倒数第k个结点](#输出倒数第k个结点)
        - [输出链表中间结点](#输出链表中间结点)
        - [判断链表是否有环](#判断链表是否有环)
        - [求单向局部循环链表的环入口](#求单向局部循环链表的环入口)
        - [判断链表是否相交](#判断链表是否相交)
        - [有序链表合并](#有序链表合并)
    - [二叉树](#二叉树)
        - [父节点和子节点下标关系](#父节点和子节点下标关系)
        - [概念](#概念)
        - [二叉树还原](#二叉树还原)
        - [二叉树的存储](#二叉树的存储)
        - [二叉排序树](#二叉排序树)
        - [优先队列（堆）](#优先队列堆)
        - [线索二叉树](#线索二叉树)
        - [最优二叉树](#最优二叉树)
        - [红黑树](#红黑树)
        - [二叉树计算](#二叉树计算)
    - [树的遍历](#树的遍历)
    - [图](#图)
        - [图的遍历](#图的遍历)
            - [DFS](#dfs)
            - [BFS](#bfs)
- [综合题](#综合题)
    - [100层楼和两个玻璃球](#100层楼和两个玻璃球)
    - [4亿个数，你只有1G内存，你怎么判断某个数已经出现？](#4亿个数你只有1g内存你怎么判断某个数已经出现)
    - [有n级台阶，一个人每次上一级或者两级，问有多少种走完n级台阶的方法。](#有n级台阶一个人每次上一级或者两级问有多少种走完n级台阶的方法)
    - [一个公交站在1分钟内有车经过概率是p，问3分钟内有车经过概率](#一个公交站在1分钟内有车经过概率是p问3分钟内有车经过概率)
- [数据库](#数据库)
    - [连接查询](#连接查询)
    - [关系数据库的三大范式](#关系数据库的三大范式)
    - [MySql性能调优](#mysql性能调优)
    - [什么情况下设置了索引但无法使用](#什么情况下设置了索引但无法使用)
- [项目](#项目)
    - [一篇英文文章，求找出出现频率最多的单词(双缓存多线程分析大文件词频)](#一篇英文文章求找出出现频率最多的单词双缓存多线程分析大文件词频)
    - [探针](#探针)
    - [dbf提交到oracle的工具](#dbf提交到oracle的工具)
    - [中登账户数据核对](#中登账户数据核对)
- [架构](#架构)
    - [如何设计一个高并发的系统](#如何设计一个高并发的系统)
    - [分布式](#分布式)
    - [缓存系统](#缓存系统)
        - [缓存穿透](#缓存穿透)
        - [缓存雪崩](#缓存雪崩)
        - [缓存击穿](#缓存击穿)
    - [消息队列](#消息队列)
        - [消息队列主要解决了什么问题](#消息队列主要解决了什么问题)
- [Linux](#linux)
    - [`netstat`](#netstat)
    - [`grep / sed / awk`](#grep--sed--awk)

<!-- /TOC -->

---

# C++语言基础

## `i++ / ++i` 是否为原子操作？

* 不是。操作系统原子操作是不可分割的，在执行完毕不会被任何其它任务或事件中断，分为两种情况（两种都应该满足）
  * 在单线程中， 能够在单条指令中完成的操作都可以认为是" 原子操作"，因为中断只能发生于指令之间。
  * 在多线程中，不能被其它进程（线程）打断的操作就叫原子操作。

* `i++`
  ```
  // 分为三个阶段, 这三个阶段中间都可以被中断分离开.
  内存加载到寄存器
  寄存器自增
  写回内存
  ```

* `++i`  
  在多核的机器上，cpu在读取内存i时也会可能发生同时读取到同一值，这就导致两次自增，实际只增加了一次。

##  类里面`static`和`const`可以同时修饰成员函数吗

* 不可以同时用const和static修饰成员函数
* C++编译器在实现const的成员函数的时候为了确保该函数不能修改类的实例的状态，会在函数中添加一个隐式的参数`const this*`。但当一个成员为static的时候，该`lstatic函数是没有this指针`的。也就是说此时const的用法和static是冲突的。


## `C++`中的四种类型转换方式

> [C++中的四种类型转换方式](https://www.cnblogs.com/carsonzhu/p/5251012.html)

* C风格的强制类型转换(Type Cast)很简单，不管什么类型的转换统统是：`TYPE b = (TYPE)a`  
  常见的(type)类型转换是C语言中的类型转换方式，其有很多缺陷如：容易产生两个不可互相转换的类型被转换，从而引发错误等等  

* 有的时候用c风格的转换是不合适的，因为它可以在任意类型之间转换;  
  比如你可以把一个指向const对象的指针转换成指向非const对象的指针;  比如：`char* test = (char*) string.c_str();`
  把一个指向基类对象的指针转换成指向一个派生类对象的指针，这两种转换之间的差别是巨大的;
  但是传统的c语言风格的类型转换没有区分这些

* `static_cast`c++内置类型间转化  
   C++内置数据类型转换，如把int转换为float;
   如：int i；float f；f=(float) i; 或者用C++类型转换模式：f=static_cast<float>(i)；

* `const_cast`  
   用于取出const属性，把const类型的指针变为非const类型的指针; 只能作用于引用或指针; 编译器执行
   如：`const int *fun(int x,int y){}; int *ptr=const_cast<int *>(fun(2,3))；`

* `dynamic_cast`含虚函数的类  
  * dynamic_cast主要用于类层次间的上行转换和下行转换，还可以用于类之间的交叉转换。  
    在进行`下行转换`时（如基类指针转为派生类指针），dynamic_cast具有类型检查的功能，比static_cast更安全。
  * 其他三种都是编译时完成的，dynamic_cast是运行时处理的，运行时要进行类型检查。  
  * 不能用于内置的基本数据类型的强制转换。 
  * `dynamic_cast转换如果成功的话返回的是指向类的指针或引用，转换失败的话则会返回NULL`
  * 使用dynamic_cast进行转换的，基类中`一定要有虚函数`(因为是运行时转换，没有虚函数就是静态绑定了)，否则编译不通过  
  * 通常在它被用于安全地沿着类的继承关系向下进行类型转换，但是被转换类必须是多态的，即必须含有虚函数  
  * 用dynamic_cast进行下行转换时，有类型检查功能，如:基类指针转子类指针正常，反过来则异常
    ```c++
    Base* pb = new Driver;   // 基类指针指向子类对象
    Driver* pd = dynamic_cast<Driver*>(pb); // 下行转换，基类指针转为子类指针
    Base* pb2 = new Base;
    Driver* pd2 = dynamic_cast<Driver*>(pb2); // error 上行转换，不能把子类指针转成基类对象
    ```
  如：`dynamic_cast<T*> (new C);`其中类C必须含有虚函数，否则转换就是错误的；

* `reinterpret_cast`  
   interpret是解释的意思，reinterpret即为重新解释，可以把一个指针转换成一个整数，也可以把一个整数转换成一个指针
   如：`int i; char *ptr="hello freind!"; i=reinterpret_cast<int>(ptr);`


##  编译过程

![](http://img1.ph.126.net/7ZAv6jFsbumWjsswWZmmgg==/1474647403087348363.jpg)

* 预处理  
  ```
  gcc -E test.c -o test.i(条件编译、头文件引入、注释删除、宏替换等)
  ```
* 编译   
  ```
  gcc -S test.i -o test.s(把源代码装换为汇编代码,在此过程加入调试选项 -g)
  ```
* 汇编   
  ```
  gcc -c test.s -o test.o(把汇编代码转换为机器可识别的二进制指令)
  ```
* 链接    
  ```
  gcc test.o -o test(链接器将多个源文件生成的.o文件捆绑在一起，同时链接到程序所需要的函数的函数库，生成一个单一完整的可执行程序)
  ```

## `make`

* `make` 传递参数给 `makefile`  
  * `makefile`：
    ```
    CFLAGS=CFLAG // CFLAG相当于一个变量
    CFLAGS+=-g -Wall
    object=myprog
    all:$object
    myprog:a.c 
      gcc ${CFLAGS} a.c -o ${object}
    ```
  * `make` 传递参数
    ```
    make CFLAG=-DDEBUG
    ```
  * make默认寻找makefile，也可以自己指定文件 `make -f file`

* `makefile` 传递参数到代码： `-D DEBUG`

### `core dump`调试

> 调试方法：`gdb -c core.pid program_name`

* 不用编译器，如何确定代码的错误位置，除了打日志，抛异常。
  不用编译器就是不用assert，不用打印日志就是不用printf，只能使用core dump，通过gdb去调试，定位堆栈信息

* `core dump` 怎么打印堆栈信息  
  * `gdb`命令`where 或 bt` 可查看当前sp指针所在的堆栈帧

### 动态静态库

* 静态库是指编译连接时，把库文件的`代码全部加入到可执行文件中`
  * 静态库有更新就要重新打包
  * 生成的文件较大
  * 运行时就不再需要库文件

* 动态库只在`执行时才加载`，如果删除动态库文件，程序将会因为无法读取动态库而产生异常。
  * 程序升级简单，动态库更新，依赖动态库的程序无需重新编译
  * 没把库文件的加入到可执行文件中，生成的文件较小
  * 动态链接库可供多个程序共享

## 同步与阻塞的概念

* 同步和异步  
  > 指用户`进程与内核的【交互方式】`，即需不需要等待函数返回

  * `同步`  
    所谓同步，就是在发出一个功能调用时，在没有得到结果之前，该调用就不返回,绝大多数函数都是同步调用的    
  * `异步`   
    指用户线程发起IO请求后仍继续执行，当内核IO操作完成后会通知用户线程，或者调用用户线程注册的回调函数。

* 阻塞和非阻塞  
  > 关注的是进程本身在`等待结果时的【状态】`，即是否让进程进入休眠（阻塞）

  * `阻塞`  
    指IO操作需要彻底完成后才返回到用户空间  
  * `非阻塞`  
    指IO操作被调用后立即返回给用户一个状态值，无需等到IO操作彻底完成。

## 五种 `I/O` 模型

> [`I/O` 模型](https://blog.csdn.net/baixiaoshi/article/details/48708347)

* `I/O` 操作有两个步骤   
  * 等待数据准备好  
    这里应该是指从磁盘拷贝到页面缓存
  * 数据从内核拷贝到用户进程

* [`UNIX` 下有五种 `I/O` 模型](https://www.cnblogs.com/pandang/p/7366781.html)  
  > 前三种都是同步 `IO`。异步必定是非阻塞的，所以不存在异步阻塞、异步非阻塞之分

  * 阻塞式 `I/O`  
  * 非阻塞式 `I/O`  
  * `I/O` 多路复用（select 、poll、epoll）
  * 信号驱动式 `I/O`（SIGIO）
  * 异步 `I/O`（AIO）

* `阻塞式IO`  

  * 应用进程被阻塞，直到所有数据到达，并成功从内核复制到应用进程才返回。
  * 下图红色部分表示阻塞   
    ![](https://s1.51cto.com/attachment/201310/202707564.jpg)


* `非阻塞式IO`
  * 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是`需要不断的执行系统调用(轮询)来获知 I/O 是否完成`
  * 如下图    
    ![](https://s1.51cto.com/attachment/201310/202858660.jpg)

* `IO多路复用 select、pool、epoll`  

  * 这几个函数**也会使进程阻塞**，即select函数是阻塞的，但是和阻塞I/O所不同的的，这两个函数 **`可以同时阻塞多个I/O操作`**。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。

  *  用户首先将需要进行IO操作的socket添加到 select 中，然后循环调用select（`会 **阻塞** 直到select系统调用返回`）。当数据到达时，socket被激活，select函数返回。用户线程正式发起read请求，读取数据并继续执行  
  * 如下图   
    ![](https://s1.51cto.com/attachment/201310/202009980.jpg)


* `信号驱动IO`
  * 比较少用，`因为信号个数有限，多个描述符时不适用`，不过免去了`select`的阻塞和轮询
  * 应用进程使用 `sigaction` 系统调用，内核立即返回，应用进程可以继续执行，在等待数据阶段应用进程是 **`非阻塞`** 的。内核在数据到达时向应用进程发送 `SIGIO` 信号，应用进程收到之后在信号处理程序中调用 `recvfrom` 将数据从内核复制到应用进程中。
  * 如下图   
    ![](https://s1.51cto.com/attachment/201310/202028686.jpg)

* `异步IO`
  * 应用进程执行 `aio_read` 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会`在所有操作完成之后向应用进程发送信号`。
  * 异步 I/O 与信号驱动 I/O 的区别在于，`异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O`
  * 如下图  
    ![](https://s1.51cto.com/attachment/201310/202055894.jpg)


## `select` 检测到可读，调用read的情况

* 当是接收缓冲区的数据大于低潮阀值时，调用read返回实际读出的字节数
* 收到FIN，调用read返回的是0
* 收到RST，调用read返回-1


## 如果一个单线程阻塞了一个系统调用，比如read,如何解决

* 使用select函数进行定时读取，多次阻塞无效后，放弃资源，提示应用系统错误信息，交给用户进一步排查；也可以是将read设置为非阻塞


## `select & epoll`

* 问题的引出   
  当需要读两个以上的I/O的时候（`比如socket编程中有多个客户端连接进来`），如果使用阻塞式的I/O，那么可能长时间的阻塞在一个描述符上面，另外的描述符虽然有数据但是不能读出来，这样实时性不能满足要求。

* 可能的解决方案有以下几种

  * `同步阻塞IO`使用`多进程或者多线程`   
    这种方法会造成程序的复杂，而且对与进程与线程的创建维护也需要很多的开销。（Apache服务器是用的子进程的方式，优点可以隔离用户）

  * 用一个进程，但是使用`同步非阻塞`的I/O读取数据，当一个I/O不可读的时候立刻返回，检查下一个是否可读，这种形式的循环为`轮询（polling）`，这种方法比较浪费CPU时间，因为大多数时间是不可读，但是仍花费时间不断反复执行read系统调用。

  * `信号驱动I/O`    
    当一个描述符准备好的时候用一个信号告诉进程。

  * `I/O多路复用`    
    构造一张有关描述符的列表（epoll中为队列），然后调用一个函数，直到这些描述符中的一个准备好时才返回，返回时告诉进程哪些I/O就绪。select和epoll这两个机制都是多路I/O机制的解决方案，select为POSIX标准中的，而epoll为Linux所特有的。


## `select 和 epoll` 的区别

> 是否重复拷贝、是否遍历所有   
> 句柄数限制、FD增长与效率、mmap消息传递   
>  [`epoll` 相对 `select` 的优点](https://blog.csdn.net/u014800094/article/details/60591852)  

* `select` 的句柄数目受限，`linux`系统中最多同时监听1024个fd。  
  `epoll` 没有，它的限制是最大的打开文件句柄数目。

* `select` 会随着FD的数目增长而降低效率   
  在`selec中采用轮询文件描述符的方式处理`，其中的数据结构类似一个数组的数据结构，而`epoll是维护一个队列`，直接看队列是不是空就可以了   
  (`select`存放在数组，`poll` 存放在链表,`epoll`存放在队列)   

* 使用 `mmap加速内核与用户空间的消息传递`    
  epoll是通过内核于用户空间`mmap`同一块内存实现的，加快了消息拷贝到用户空间的过程。


## `select 和 poll` 的区别

> 同：轮询、整体复制    
> 异：连接数(因为poll采用链表)

* `poll`的机制与`select`类似，与`select`在本质上没有多大差别，管理多个描述符`也是进行轮询，根据描述符的状态进行处理`  

* `poll 没有最大连接数的限制，原因是它是基于链表来存储的`

* `poll` 缺点  
  * 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义                   
  * poll还有一个`特点是水平触发`，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd

* `poll和select`同样存在一个缺点就是，包含大量`文件描述符的数组【被整体复制于用户态和内核的地址空间之间】`，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。

## `epoll` 两种触发模式

> `LT`水平触发(条件触发): `socket`可写就会一直提示   
> `ET`边缘触发: `socket`可写只提醒一次，等到再次可写才提醒  


* `LT`模式下，**只要这个fd还有数据可读，每次 `epoll_wait` 都会返回它的事件**，提醒用户程序去操作，只要还有没有处理的事件就会一直通知，只要有数据都会触发。

* `ET`模式中，**只会提示一次**，直到下次再有数据流入才会再次提示，无论`fd`中是否还有数据可读，也就是说一直读到read的返回值小于请求值，或者 遇到EAGAIN错误

* 扩展  
 `epoll` 使用事件的就绪通知方式（感觉就像信号处理一样注册函数），通过`epoll_ctl`注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，`epoll_wait`便可以收到通知。


## 为什么浮点数有误差

> 十进制小数转换为二进制过程中出现了误差   
> 对于小数部分转换后出现无限循环的部分，计算机只保存了有限位

* 十进制小数是怎么转化为二进制?   
  整数部分 `连除2取余，倒序排列`，小数部分`连乘2取整，正序排列`
  ```
  例如：将十进制数值`42.65`转换为二进制数值，步骤如下：
  42(整数部分)
  42/2=21......0
  21/2=10......1
  10/2=5 ......0
  5/2=2  ......1
  2/2=1  ......0
  1/2=1  ......1
  (42) 10=(101010) 2
  // 10进制42用2进制，连除取余结果倒序排列

  0.65(小数部分)
  0.65*2=1.3......1
  0.3*2=0.6 ......0
  0.6*2=1.2 ......1
  0.2*2=0.4 ......0
  0.4*2=0.8 ......0
  0.8*2=1.6 ......1
  0.6*2=(重复上述循环了)
  (0.65) 10=(0.101001...) 2

  (42.65) 10=(101010) 2+(0.101001...) 2=(101010.101001...) 2
  ```

* `IEEE`标准   
  `IEEE`标准规定，单精度浮点数共32位，`23位小数f`，8位偏置指数e，1位符号s；同理，`double类型有52位`可以存放小数

* 总结  
  上面将0.65转换出的二进制代码，计算机只能存储23位，所以后面`超出23位以后的都被忽略掉了`的


## 如何判断两个浮点数是否相等，为什么不用 ==

> `计算机本质是二进制，通过浮点表示小数，都是模拟出来的`， `float` 和 `double` 都不能保证可以把所有实数都准确的保存在计算机中，采用`==`运算符是不可行的

* 浮点数大小比较为什么不能用 `==`
  * 浮点数精度不同，同一小数，但用不同精度表示时，结果不一样
    ```c++
    float a = (float) 0.1;
    float b = (double) 0.1;
    ```

* 可以通过求绝对值的差值和精度作比较来判断是否相等
  ```c++
  const double eps = 1e-6;
  if (fabs(double_a - double_b) < eps)
  {
    ...
  }
  ```


## 比较结构体是否相等

* 不能直接用 `==` , 该操作符不能比较自建类型
* 不能用 `memcpy` , 因为memcpy是逐字节比较的, 结构体对齐时`填充的字节是随机的`
* 可以通过重载 `==` 来实现，或者写一个成员函数
  ```c++
  struct s
  {
      int a;
      int b;
      bool operator == (const s &rhs);
  };
  
  bool s::operator == (const s &rhs)
  {
      // 这里并没有 this.a
      return ((a == rhs.a) && (b == rhs.b));
  }
  ```


## `main` 函数和启动例程

> [深度剖析c语言main函数 --- main函数的执行顺序](https://blog.csdn.net/z_ryan/article/details/80985101)

* `main` 函数启动前，系统主要做了初始化的工作
  * `初始化静态和全局变量` + 运行`全局对象的构造函数`
  * `将未初始化部分的赋初值`  
    数值型short,int,long等为0,bool为false,指针为NULL,等等
  * `传递参数给main函数`   
    argc,argv等传递给main函数，然后才真正运行main函数

* `main` 函数是怎么启动的
  * `main` 函数之前有启动例程 `_start`  
    这个函数是Linux系统库的一部分，当我们的程序和Glibc库链接在一起形成最终的可执行文件的之后这个函数就是程序执行初始化的入口函数。
  * 编译器缺省是找 `__start` 符号, 而不是 `main` 
  * `__start` 这个符号是程序的起始 
  * `main` 是被标准库 `stdlib` 调用的一个符号


## `main` 函数不能被调用， 为什么还需要返回值  

> 告诉内核程序的退出状态

* `return n; 其实相当于 exit(n);`  
  * 当一个进程执行完毕时，该进程会调用一个名为 `atexit` 的例程来`通知内核它已经做好"消亡"的准备了`;
  * 该进程会提供一个退出码（一个整数）表明它准备退出的原因


## 如何获取`main`函数的返回值

* Linux 终端可以通过 `echo $?` 查看退出码
* 在`atexit`中注册的函数中获取
  ```c++
  int code; // 全局变量
  void my_exit(){ cout << code << endl; }
  int main()
  {
    atexit(my_exit);
    ...
    return code=0;
  }
  ```
* 在另一个程序中使用`system`来获取
  ```c++
  cout << system("/path/to/exe_file") << endl;
  // 如果可执行文件退出码为 n，则system函数输出为 n * 256
  // 因为exe_file返回值是 system 返回值的8～15位。
  ```


## `main` 函数结束后就结束了吗？

* `exit(0)（相当与执行return 0;）`先是执行`atexit`注册的函数（用法和信号处理signal一样），然后再执行 _exit 函数， _exit `会关闭进程所有的文件描述符，清理内存以及其他一些内核清理函数`

* `全局对象的析构函数`会在main函数之后执行； 

* 获取当前执行文件路径 `argv[0]`


## 函数调用过程

* 从栈空间`分配存储空间`
* 从实参的存储空间`复制实参到形参栈空间`
* 进行运算
  * `形参`在函数未调用之前都是没有分配存储空间的，在函数调用结束之后，形参弹出栈空间，清除形参空间。
    * `传值`  
      传值，实际是把实参的值`拷贝`给形参。那么对形参的修改，不会影响实参的值 。
    * `传址`  
      实际是传值的一种特殊方式，只是他传递的是地址，不是普通的赋值，那么`传地址以后实参和行参都指向同一个对象`，因此对形参的修改会影响到实参。
    * `传引用`  
      引用是变量的一个别名，它不会另外分配空间，所以最终修改的还是原来的变量
  * `数组`作为参数的函数调用方式是地址传递，形参和实参都指向相同的内存空间，调用完成后，形参指针被销毁，但是所指向的内存空间依然存在，不能也不会被销毁。
* 函数中如果有return返回变量时，其实所返回的也是一个拷贝。所以当使用return返回对象时一定要考虑所返回对象的拷贝构造函数是否能够满足要求。


## `printf` 是怎么可以输出多个和不同类型的数据的

* `printf` 是C语言函数，哪来的重载，是通过变长参数来实现的


## 为什么没有格式化字符串没有也能输出字符串?

* 因为 `printf(const char* formate, ...)` 使用变长参数实现的，参数列表第一个参数就是 `const char*`，所以可以直接输出字符串
  ```c++
  char* a = "huangjinjie";
  printf("%s", a);
  printf(a); // 相当于变长参数为0，只给formate入参
  ```


## 格式化字符串漏洞

> [格式化字符串漏洞简介](https://wooyun.js.org/drops/%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%BC%8F%E6%B4%9E%E7%AE%80%E4%BB%8B.html)

* 现象  
  ```c++
  char * p = "huangjinjie";
  printf("%s", p); // 正常情况
  printf(p);       // 这样也可以输出
  ```
* 格式化字符串漏洞
  * 原理    
    一般的函数都是固定参数个数和类型的，所以调用的时候知道从内存中读取出多少字节     
    但是变长参数则是`依赖用户把参数个数和类型输进来`以保证灵活性，但如果编程者`不加格式化字符，就会产生后面任意地址读写的漏洞`
  * 实践  
    `%n` 功能是将%n之前printf已经打印的字符个数赋值给传入的指针。通过%n我们就可以修改内存中的值了
    ```c++
    char a;
    printf("zzzzzzz%n\n", &a);
    printf("%d\n", a); // a变为7了(刚好是z的个数)

    char b[100];
    printf(b);
    // 如果输入的b是 %010x%010x%010x%01970x%n 就可以访问后面的内存了
    ```
  * 危害   
    可以通过 `%n` 来达到访问程序的任意地址，**`甚至直接访问和修改内存`**    
    

## `printf` 函数参数

> [你可能不知道的 `printf`](https://mp.weixin.qq.com/s?__biz=MzI2OTA3NTk3Ng==&mid=2649284608&idx=2&sn=3449445af2ff6db0525c78cd08a48b4e&chksm=f2f99367c58e1a719036932aac6d16c9b525060bb4662e05abec6b5961ed2253d463337080db&mpshare=1&scene=1&srcid=#%E6%A0%BC%E5%BC%8F%E6%8E%A7%E5%88%B6%E7%AC%A6%E6%98%AF%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E5%8F%82%E6%95%B0%E7%9A%84)

* 可变参数中的类型提升  
  调用者会对每个参数执行`默认实际参数提升`，比如`%d`会从堆栈中取 4 字节，如下
  ```c++
  float将提升到double (8字节)
  char、short和其相应的signed、unsigned类型将提升到int (4字节)
  ```

* 参数入栈顺序以及计算顺序  
  见 `__stdcall、__cdecl、__fastcall`

* 格式控制符是如何处理参数的   
  * 根据控制字符`从堆栈中取其对应大小`     
    例如，%f 期望一个double（8字节）类型，但是传入的参数是int（4字节），那么在处理这个int参数值会按照double处理，则多处理4个字节，会造成处理数据错误。

  * `printf("%d%d",i)`会发生什么，为什么?  
    ```c++
    输出 i 的值以及一个不确定的数
    会造成获取一个错误的参数，`输出数据是不确定的`
    ```

* 可变域宽和精度
  ```c++
  scanf("%3d", &i);
  // i【最多接收宽度】3位整数，如果输入多余3位后面多余部分会被舍弃, 少于3位则直接赋给i

  scanf("%3d%4d", &i, &j);
  // 如果输入1234567890，则 i=123 j=4567,剩余部分被舍弃

  printf("%07d", i);
  // 表示【最少输出宽度】为7，0表示不足7位则在前面补0, 如果没有0则以空格填补

  printf("%*d", 5, i);
  // %*d, 表示可变域宽，宽度又右面的入参控制，这里是 5
  ```


## `__stdcall` 和 `__cdecl`的区别

> `__stdcall`c++标准调用方式，由被调用函数清理    
> `__cdecl` c和c++默认调用方式，堆栈由函数清理   

> [`__stdcall、__cdecl和__fastcall` 调用约定](https://blog.csdn.net/luoweifu/article/details/52425733)  
> [`__cdecl,__stdcall,__fastcall,__pascal,thiscall` 的区别](https://www.cnblogs.com/john-h/p/6276828.html)   

* 清理堆栈是什么意思？    
  `__cdecl`是默认的调用方式，每一个调用它的`函数都包含清空堆栈的代码`，所以产生的可执行文件大小会比调用`_stdcall`函数的大。

* 调用约定决定以下内容：
  * 函数参数的`压栈顺序`
  * 由调用者还是被调用者把参数`弹出栈`
  * 以及产生`函数修饰名`的方法  

* 如下表    
  |要点|__cdecl|  __stdcall|
  |:-:|:--:|:--:|
  |**压栈顺序**|	右->左|	右->左	|
  |**清理栈方**|	调用者清理|	被调用函数清理|
  |适用场合|	C/C++、MFC的【默认方式】	|Win API|
  |**产生的修饰名**|	_funcname|	_funcname@arg_bit_num|


## `this` 指针调用成员函数时的压栈和相关寄存器使用？

> `this`指针默认通过`ECX寄存器`传递给调用者，其参数`从右到左入栈`，是C++`类成员函数缺省的调用约定`

* `thiscall`是唯一一个`不能明确指明的函数修饰`，因为thiscall不是关键字。
* 如果参数个数确定，this指针通过ecx传递给被调用者；如果参数个数不确定，this指针在所有参数压栈后被压入堆栈；
* 对参数个数不定的，调用者清理堆栈，否则函数自己清理堆栈。


## 函数符号生成规则

> [C/C++函数符号生成规则](https://blog.csdn.net/Scl_Diligent/article/details/83990429)

* `_funcname@arg_bit_name` 表示函数名+@+参数字节数
  ```c++
  sum(int x,int y) 对应 _sum@8
  ```
  

## 位操作

* `& 与`（1&&0=0），如：1010 & 1100 = 1000
* `| 或`（1||0=1），如：1010 & 1100 = 1110
* `~ 非`，如：a = 1010; ~a = 0101
* `^ 异或`（同则为0），如：1010 ^ 1100 = 0110
* `<< 左移`，如：1110 << 1 = 1100
* `>> 右移`，如：1000 >> 1 = 0100
* 把一个整型的二进制后三位清零: `n &=~7;`


## 操作符优先级
TODO



## 为什么要分内核态和用户态

* 内核态能有效`保护硬件资源`的安全  
  如创建进程、读取文件、网络传输等都是`系统核心功能`，这些核心功能必须交给`特权级`最高的进程去执行

* 为了确保系统不会受到破坏  
  * 内核态为`特权级别`，有权对一些关键资源进行修改，用户态为`非特权级别`   
  * 操作系统中发一些指令属于`极其危险的级别，如清理内存、设置时钟等`。如果允许用户随意调用，将发生无法预估的灾难，`导致系统奔溃`


## 内核态和用户态区别

* 用户态切换到内核态  
   系统调用、 异常、中断
   
* 当进程执行系统调用而陷入内核代码中执行时，处于内核态
   * 此时处理器处于`特权级`最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会`使用当前进程的内核栈`。每个进程都有自己的内核栈

* 当进程在执行用户自己的代码时，则称其处于用户态
   * 此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。这与处于内核态的进程的状态有些类似。

* 既然库函数是调用系统函数, 那为什么不所有代码都放在内核中执行?  
   * 虽然内核执行高效, 但是放内核中执行太危险了, 一旦发生问题就会有宕机的风险；所以把有风险的程序放到用户态执行

## 系统调用和库函数调用的区别

* 函数库调用是语言的一部分，而系统调用是系统提供的一套访问系统资源的API。

* 系统调用是为了`方便应用使用操作系统的接口`  
  库函数是为了方便人们编写应用程序而引出的，比如自己编写一个函数也可以说是一个库函数。

* 用户应用程序访问并使用内核所提供的各种服务的途径即是系统调用
  在内核和用户应用程序相交界的地方,`内核提供了一组系统调用接口，通过这组接口，应用程序可以访问系统硬件和各种操作系统资源`


## 为什么系统调用比库函数调用更耗时?

> 上下文切换、恢复现场

* `上下文的切换`  
  系统调用一般都需要保存用户程序的上下文(context) ,在进入内核的时候（系统调用实在内核态）需要保存用户态的寄存器，在内核态返回用户态得时候会恢复这些寄存器的内容，`需要从用户地址空间切换到内核地址空间`

* `堆栈恢复现场`  
  当程序中有系统调用语句，程序执行到系统调用时，首先保存现场;去调系统调用号, 在内核态执行，然后恢复现场； 每个进程都会有两个栈，一个内核态栈和一个用户态栈。

* 进行系统调用时，系统要`进行额外的检查`来确保这次调用是安全的。系统调用的返回过程有很多额外工作; 比如检查是否需要调度等。

* 不是所有的库函数都会调用系统调用的，比如strncpy、memcpy


## 结构体与联合体的区别

> 联合体所有成员共用一块内存、结构体为所有成员都分配内存

* 结构和联合都是由多个不同的数据类型成员组成  
  在任何同一时刻, `联合中只存放了一个被选中的成员（所有成员共用一块地址空间）`,结构的所有成员都分配空间（不同成员的存放地址不同）。

* 对于联合的不同成员赋值, 将会对其它成员重写, 原来成员的值就不存在了, 而对于结构的不同成员赋值是互不影响的。


## 结构体和类的区别

> 默认访问权限和继承权限不同，类private 结构体public

```
1. C++中的struct对C中的struct进行了扩充，它已经不再只是一个包含不同数据类型的数据结构了，它已经获取了太多的功能：
   ① struct能包含成员函数吗？ 能
   ② struct能继承吗？ 能
   ③ struct能实现多态吗？ 能
2. 既然这些它都能实现，那它和class还能有什么区别？
   ①若不指明，struct成员的默认属性是public的，class成员的默认属性是private的；
   ②若不指明，struct成员的默认继承权限是public的，class成员的默认继承权限是private的；
```


## 结构体对齐`sizeof`

> 静态成员、成员函数不计入类大小

* 结构体大小计算
* 位域：`struct s{ char a:3; int b;};` // 表示char a只占一个字节中的低3位

* 类的大小计算
  * 类的存储大小sizeof运算也可以当做结构体来计算
  * 注意函数声明不占内存; 静态成员分配在全局区, 也`不计入类大小`，this指针不是对象本身的一部分，不计入sizeof结果
  * `空类`会有一个字节做标记;
  * 有虚函数的类, 会包含一个虚函数指针的大小;不论这个类有多少个虚函数都是只有一个虚函数指针
  * 如果父类有虚函数, 子类也有虚函数, 则子类大小 = 基类大小 + 子类大小 + `一个虚函数指针`(因为子类的虚函数被放到了第一个父类的虚函数表表中, 在没有重写的情况下）
  * 要注意继承问题：比如派生类继承基类，那么： 派生类大小=基类成员（不包括静态成员）+自己本身

* 修改默认对齐数 `#param pack(4)`


## 结构体为什么要对齐字节

> 平台移植、访问效率、节省空间

> [结构体为什么要4字节对齐？](https://blog.csdn.net/yilese/article/details/76199869?locationNum=9&fps=1)  
>[C/C++字节对齐，以及为什么要对齐？](http://blog.sina.com.cn/s/blog_455b20c10100g01z.html)

  * `提高访问效率`    
    如果不对齐，一个变量可能一部分在前一个字节，后一部分在后一字节；所以对齐可以避免一个变量要读两次

  * `平台移植`  
    就像上面说的，如果分在两个字节中，`cpu要读取两次，但是不是所有的硬件平台都能访问任意地址上的任意数据，某些硬件平台只能在某些地址(如偶数地址)处取某些特定类型的数据`，否则抛出硬件异常

  * `节省存储空间`  
    因为要对齐，编程时可以合理安排成员的顺序达到节省空间的目的


## 说一说 `static`

> 内存、生命周期、作用域

* `内存分配、生命周期`  
   static修饰的变量在编译阶段被分配在全局区, 其生命周期随程序的结束而结束

* `静态局部变量`  
   static修饰局部变量时，使得被修饰的变量成为静态变量，存储在静态区。存储在静态区的数据生命周期与程序相同;
   但是作用域只限制于其所在的函数中。 main函数执行之前初始化，程序退出时销毁。（无论是局部静态还是全局静态）

* `静态全局变量`  
   全局变量本来就存储在静态区，因此static并没有改变其存储位置。但是，static限制了其链接属性;
   被static修饰的全局变量只能被该包含该定义的文件访问（即改变了作用域）。
   
* `修饰函数`  
   static修饰函数使得函数只能在包含该函数定义的文件中被调用。对于静态函数，声明和定义需要放在同一个文件夹中。

* `类static成员变量`  
   用static修饰类的数据成员变量使其成为类的全局变量，会被类的所有对象共享(包括派生类的对象), 所有的对象都只维持
   同一个实例。 因此，static成员必须在类外进行初始化(初始化格式：intse::var=10;)，而不能在构造函数内进行初始化
   不过也可以用const修饰static数据成员在类内初始化。 静态成员变量在构造类之前就存在了，所有类对象只有一份拷贝

* `static成员函数`  
   用static修饰成员函数，使这个类只存在这一份函数，所有对象共享该函数，不含this指针，因而只能访问类的static成员变量
   只可以访问static成员，因为没有this指针(所以也不能声明为虚函数)

* `隐藏`  
   用static修饰的变量或函数仅在本文件内有效， 所以用static可以在不同文件中定义相同名称的变量或函数


## 说一说 `extern`

* `extern int g_Int;`  
   它的作用就是声明函数或全局变量的作用范围的关键字, 其声明的函数和变量可以在本模块或其他模块中使用,不能重复初始化

* 声明函数的时候使用`extern "C" {void fun(int a,int b);}` 可以让编译器按照C语言的方式生成函数的符号（C语言的方式生成的是什么样的

## 说一说 `explicit`

> 防止隐性转换和拷贝初始化  

> 类构造函数默认情况下声明为隐式的即 `implicit`（英语隐式的意思，explicit是显式的意思）   
> [C++中`explicit`关键字的使用](https://www.cnblogs.com/gklovexixi/p/5622681.html)  

* 用来修饰类的构造函数，`被修饰的构造函数的类，不能发生相应的隐式类型转换，只能以显示的方式进行类型转换`

* 只能用于修饰`只有一个参数的类构造函数`或者，有n个参数，n-1个是默认参数的情况

* 如AAA = xxx，这样的代码，且恰好xxx的类型正好是AAA单参数构造的参数类型，这时候编译器就自动调用这个构造器，创建一个AAA的对象． 使用explicit声明构造函数，则可防止隐式转换，避免上述情况的发生
  ```c++
  Class A
  {
     A(int a);
     // explicit A(int a);
  }

  A a;
  a = 10; // 会默认构造
          // 带explicit关键字则会无效，必须要显示做转换
          // A = A(10); 或者 a = (A)10;
  ```


## 说一说 `const`

> 变量、函数名前、函数名后、函数参数

* const修饰变量(包括指针)
   ```c++
   const int a = 10;
   const int *p = 10; // 表示*p的值不允许改变，*p = 100;// error; int b = 20; p = &b; // ok
   int c = 10;
   int * const p = &c; // p存放了一个固定的地址，所以初始化的时候要给他一个初值，表示p的地址不允许改变
   					   // int d = 20; p = &d // error; c = 20; //ok
   ```
* const修饰函数参数
   ```
   char* strcpy(char* dst, const char* src); // 防止src在strcpy函数内部被改变
   ```
* const修饰函数返回值
   ```
   const int get(); // 防止get() 函数返回值被改变
   ```
* const修饰函数
   ```c++
   int get() const;
   // 只可以用于类成员函数, 表示get()函数仅可访问类成员变量, 但是不可以改变类成员变量; 
   // 非const对象也可以调用const成员函数
   // 常对象（如 const A a(10);）,只能调用const 成员函数，因为get()函数隐含了一个const this*指针
   ```


## 说一说 `mutable`

> 如果某成员变量允许在 `const成员函数内更改`，可用 `mutable` 修饰

* mutable也是为了突破const的限制而设置的，二者作用相反

* 被mutable修饰的变量(mutable只能由于修饰类的非静态数据成员)，将永远处于可变的状态，即使在一个const函数中。



## 两个一样的函数，一个带const，一个不带，会有问题吗?

> 分别提供给const对象和非const对象进行调用的  

> [C++中，经常有同名成员函数，一个const形式一个非const形式的解读](https://blog.csdn.net/ly131420/article/details/51823551)  
> [C++中const成员函数和非const成员函数的重载](https://blog.csdn.net/bzhxuexi/article/details/43408015)

* 不会，函数间是 **`重载`** 的

* 设计两个成员函数，`主要是提供给非const对象和const对象进行调用的`，只设计任何一个都无法满足全部需求。只用A类的const对象才能调用const版本的function函数，而`虽然const对象可以调用任意一种`，通常非const对象调用不是const版本的function函数。

* 这两个函数的定义和实现都是完全一样的，差异的地方就是一个函数名后面会跟一个const，嫌写两边臃肿，可以用`const_cast<T>()`来转换，如果成员函数需要返回引用类型，那么设计两个相同的成员函数，一个const一个非const才是合理的
  ```c++
  class CTextBlock
  {
  public:
    // 这个版本给const对象调用，返回值加const是因为const对象是不可更改的，如果返回值是引用又不加const的话，很容易就会被更改，这就与const语义冲突了
  	const char& operator[](std::size_t position) const
  	{
      // ...
  	}
  	char& operator[](std::size_t position)
  	{
  		return const_cast<char&>(static_cast<const CTextBlock&>(*this)[position]);
  	}
  	void prepare()const;//一些准备动作
  };
  ```


## 说一说 `volatile`

> 语法声明和从const一样：`int volatile vInt;`  
> 每次使用都重新从内存取数据。

* 不用该关键字修饰，编译器有可能会`先把数据从内存加载到寄存器，然后再到用户空间`, 而用它声明的类型变量，编译器对访问该变量的代码就不再进行优化，`当使用 volatile 时系统总是重新从它所在的内存读取数据`。

* volatile关键字保证了在多线程环境下,被修饰的变量在别修改后会马上同步到主存,这样`该线程对这个变量的修改就是对所有其他线程可见的`,其他线程能够马上读到这个修改后值. 


## `volatile`能保证线程安全吗?

> [`volatile` 能保证线程安全吗?](https://blog.csdn.net/qq_43401808/article/details/86540962)

* 不能指望volatile能解决多线程竞争问题，除非所用的环境系统不可靠才会为了保险加上volatile，

* volatile解决的是多线程间共享变量的可见性问题，而`保证不了多线程间共享变量原子性问题`。对于多线程的i++,++i,依然还是会存在多线程问题,volatile是无法解决的,详见上面的[i++/++i是否为原子操作]


## `const` 和 `#define` 的区别

* const 常量有数据类型, 而宏常量没有数据类型。编译器可以对前者进行`类型安全检查`。 而define只进行字符替换，没有类型安全检查，并且在字符替换可能会产生意料不到的错误。

* 有些集成化的调试工具可以对 `const 常量进行调试`，但是不能对宏常量进行调试。

* #define 是在`预处理`阶段进行替换，const会在`编译阶段`替换, 会做安全检查, define只是简单地做替换;  


## `typedef`和`#define`的区别

> 类型别名与宏的三点区别，如`typedef char* MYTYPE; 和#define MYTYPE char *`两句：

* 前者是类型别名，要做`类型检查`，后者只是一个替换，不做类型检查；
* `前者编译时处理，后者预编译时处理`，即预编译期间替换掉宏；
* 前者能保证定义的全都是char* 类型，String_d却不能;

## `inline`和`#define`的区别

* 区别在于，宏是由`预处理器`对宏进行替代，而内联函数是通过`编译器`控制来实现的
* 内联函数是真正的函数，只是在需要用到的时候，`内联函数像宏一样的展开`，所以取消了函数的参数压栈，`减少了调用的开销`。你可以像调用函数一样来调用内联函数，而不必担心会产生于处理宏的一些问题


## 什么技术可以代替宏定义 `#define`

> [宏在C++中的替代解决方案](https://blog.csdn.net/github_33736971/article/details/52634191)

* const 实现常量
  ```c++
  #define N 10;     // c
  const int N = 10; // c++
  ```
  
* inline 内联替代宏函数
  ```c++
  #define MAX(x, y) (((x) > (y)) ? (x) : (y));   // c
  inline int max(int x, int y){ return x>y?x:y;} // c++
  ```

* typedef 替代类型定义
  ```c++
  #define DWORD unsigned int; // c
  typedef int DataType ;      // c++
  ```

* 条件编译
  ```c++
  // c语言形式
  #ifdef DDEBUG
  ...
  #else
  ...
  #endif
  // c++形式
  // 据说可以用模板 template来实现
  ```

* 防止头文件重复包含**C++暂时也只能这样做**
  ```c++
  #ifndef _TEST_H
  #define _TEST_H
  ...
  #endif
  ```


## 内联函数和成员函数的区别

* 既然内联函数可以节省函数调用的开销, 那为什么不把所有的函数都声明为内联函数?  
如果程序在10个不同的地方调用同一个内联函数，则该程序将包含该函数代码的10个副本,会`消耗更多空间`,所以作为内敛函数的`运行时长越短越好`(因为会展开,所以含有递归调用的函数不能设置为inline)

## `new`和`malloc`的区别

* `性质`  
   new是操作符，操作符可以进行重载，malloc是库函数
* `使用`  
   new使用的时候会`自动计算大小`，malloc则要指定大小
   new/delete在对象(如类对象)创建的同时会`【自动执行构造函数】`做初始化，在对象在消亡时会自动执行析构函数  
   而malloc只管分配内存，并不能对所得的内存进行初始化，所以得到的一片新内存中，其值将是随机的；
* `成功`  
   new成功后返回对象类型的指针，malloc返回void* 指针，需要自己做类型转换
* `失败`  
   new抛出异常，malloc返回会NULL，所以用new之后在判断是否为NULL没什么意义
* `扩容`  
   new不支持扩容, malloc在使用过程中发现内存不够可以使用realloc来进行扩容
* 既然有了malloc为什么还要new呢？

## 字符操作函数 `#include <string.h>`

> 这部分内容更详细的注释在 `string_test.cpp`  
> [Linux中的字符串和字节序列处理函数](https://blog.csdn.net/frecon/article/details/79605941)

* `sizeof / strlen`
  ```c++
  const char a[] = "abc";  // sizeof(a) = 4; 末尾隐藏了\0 strlen(a) = 3
  char b[10]="abc";        // sizeof(b) = 10;            strlen(b) = 3;
  char b1[3]="abc";        // error 末尾隐藏的\0无处安放
  char c[] = {'a','b','c'};// sizeof(c) = 3;             strlen(c) = xxx(不确定的值)这种初始化不会默认加\0;
  printf("%s", c); cout << c << endl; 都无法准确将c输出，因为这种初始化不会在末尾补\0

  char *a = "asdfg";
  strlen(a) = 5; // 虽然可以计算长度，但是要注意不能修改常量字符串
  // 真实字符串大小，一般的系统函数若返回值为char*类型，也【会自动在末尾加上'\0'】，故在初始化后，strlen是可以用的
  ```


* 字符串翻转 `huangjinjie --> eijnijgnauh`
  * 思路:  直接从两头往中间走，同时交换两边的字符即可
    ```c++
    void reverseChar2(char *msg, int len)
    {
      int left = 0;
      int right = len - 1;
      while (left < right)
      {
          *(msg + left) = *(msg + left) + *(msg + right);
          *(msg + right) = *(msg + left) - *(msg + right);
          *(msg + left) = *(msg + left) - *(msg + right);
          left++;
          right--;
      }
    }
    void reverseChar(char *left, char *right)
    {
      assert(left != NULL && right != NULL);
      while (left < right)
      {
        // 异或的方法交换
        *left ^= *right;
        *right ^= *left;
        *left ^= *right;
        left++;
        right--;
      }
    }
    ```

* 单词翻转 `huang jin jie --> jie jin huang`
  * 先把整个字符串翻转, 然后再按照空格把一个个单词翻转(最后一个不是空格)
    >huang jin jie --> eij nij gnauh --> jie jin huang
    ```c++
    void reverseWord(char *msg)
    {
      char *cur = msg;
      int len = strlen(msg) - 1;
      int left = 0, right = 0;
      reverseChar(msg, msg + len);
      // while (*cur != '\0') // 用这个做退出条件的话，会导致第一个单词没有翻过来 huang jin jie --> jie jin gnauh
      while (right <= strlen(msg))
      {
        if (*cur == ' ' || *cur == '\0')
        {
          reverseChar(msg + left, msg + right - 1); // -1 空格
          left = right + 1;
        }
        right++; // 遍历
        cur++;
      }
    }
    ```

* 左旋字符串 `huangjinjie --> angjinjiehu` (左旋两位)
  * `思路1`  
    拿出首个字符h, 将其与后面的每一个字符交换一次, 即可完成一次左旋
    > huang -> uhang -> uahng -> uanhg -> uangh
  * `思路2`  
    先翻转**前cnt**个字符, 再翻转**后len-cnt**个字符, 最后把整个字符翻转
    > huangjinjie --> auhngjinjie --> auheijnijgn --> ngjinjiehua

* 右旋字符串 `huangjinjie --> iehuangjinj` (右旋两位)
  * 思路和左旋一样
  * 先翻转**后cnt**个字符, 再翻转**前len-cnt**个字符, 最后把整个字符串翻转
    > huangjinjie --> huangjineij --> nijgnauheij --> jiehuangjin


* strcpy
  ```c++
  char* strcpy(char* dst, const char* src)
  {
  	assert(dst!=NULL);
  	assert(src!=NULL);
  	while((*dst++ = *src++)!= '\0');
  	return dst;
  }
  ```

* memcpy
  ```c++
  char* memcpy(char* dst, const char* src, size_t n)
  {
  	assert((dst!=NULL) && (src!=NULL));
  	while((*dst++ = *src++) != '\0' && --n);
  }
  ```
  
* memmove
  ```c++
  char *mymemmove(char *dst, char *src, int n)
  {
      // 判断是否存在内存重叠
      // src: [低地址] 1 2 3 4 5 6
      // dst: [低地址]         1 2 3 4 5 6
      bool flag = dst > src && dst <= src + n;
      if (flag) // 倒序拷贝
      {
          char *dst_cp = dst + n - 1;
          char *src_cp = src + n - 1;
          while ((*dst_cp-- = *src_cp--) != NULL && --n)
              ;
      }
      else
      {
          while ((*dst++ = *src++) && --n)
              ;
      }
      return dst;
  }
  ```

* strcmp
  ```c++
  int MyStrcmp(const char* str1, const char* str2)
  {
  	   assert((dst!=NULL) && (src!=NULL));
      while ((*str1++ == *str2++)!='\0' && *str1 && *str2);
      int result = *(--str1) == *(--str2) ? 0 : (*(--str1) > *(--str2) ? 1 : -1);
  }
  ```

* strncpy
  这个库函数不会在末尾补`\0`的，自己写的那个是为了安全，才把最后一位改为`\0`
  ```c++
  char *mystrncpy(char *dest, const char *str, int dest_len, int len)
  {
      int n;
      assert((dest != NULL) && (str != NULL));
  
      char *cp=dest;
      if (dest_len > len)
          n = len;
      if (dest_len <= len)
          n = dest_len; // 只拷贝dest_len个字符
  
      while ((*cp++ = *str++) != NULL && --n)
          ;
  	return dest;
  }
  ```

* strstr
  ```c++
  char* MyStrstr(char* str1, const char* str2)
  {
      assert(str1 != NULL);
      assert(str2 != NULL);
  
      if (*str2 == '\0')
          return str1;
  
      while(str1)
      {
          const char *cur = str2;
          // 每次不相等都从第一个字符重新开始
          while ((*str1++ == *cur++) && *str1 && *cur)
              ;
          // 循环退出, 指向【不相等字符的下一个字符】包括字符遍历结束的情况
          if (*(--cur) == *(--str1))
              return str1 - strlen(str2) + 1; 
          if (*str1 == '\0')
              return NULL;
          str1++;
      }
      return NULL;
  }
  ```

## 哪些情况一定要使用初始化成员列表

> [初始化列表](https://www.cnblogs.com/weizhixiang/p/6374430.html)   
> `const` 常量只能初始化，不能赋值    
> `& 引用`也是只能初始化，不能赋值

* `常量成员 const`，因为常量只能初始化不能赋值，所以必须放在初始化列表里面
* `引用类型 &`，引用必须在定义的时候初始化，并且不能重新赋值，所以也要写在初始化列表里面
* 没有对应的默认构造函数的类类型，因为使用初始化列表可以不必调用默认构造函数来初始化，而是直接调用拷贝构造函数初始化
  * **如果类中声明了构造函数，那么系统不再提供默认构造函数，此时用户如果还要使用无参构造函数，则需要自己重载构造函数**
    ```c++
    class A
    {
      public:
        A(int a){_num = a;}
      private:
        int _num;
    }
    A aobj; // 报错
    ```

  
## 虚函数表

* 编译器为`每个类维护一个虚函数表`（本质是一个函数指针数组，数组里面存放着该类所有虚函数的地址）  
  * 每个对象的**首地址保存着各自**指向该虚函数表的指针, 同一个类的不同对象实际上指向同一张虚函数表。    
  `_vptr存在于对象实例中最前面的位置`是为了保证取到虚函数表有最高的性能——如果有多层继承或是多重继承的情况下
  * `对象不包含虚函数表，只有虚指针，类才包含虚函数表`，虚指针指向虚函数表，派生类会生成一个兼容基类的虚函数表

* 在单继承形式下, 子类完全获得父类的虚函数表和数据；`子类的虚函数表包含父类的虚函数地址，且子类虚函数地址在后面`  
  * 子类如果重写了父类的虚函数fun;就会把子类虚函数表中原本父类的虚函数fun对应的记录（内容BaseClass::fun）覆盖为子类的fun函数地址（内容SonClass::fun）  

* `【到底调用那个函数要根据指针的原型来确定，而不是根据指针实际指向的对象类型确定】`   
  这就解释了为什么无法通过父类指针指向子类对象来访问子类特有的成员或虚函数，因为这些成员不是父类的（虽然继承之后父类虚函数了子类虚函数放在同一张表里）

* [单继承、多继承下的虚函数表](https://blog.csdn.net/qq_20309055/article/details/79298593)   
  * 单继承无重写
    ![](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_vtable2.JPG)  
    父类虚函数地址排列在子类虚函数地址前面

  * 单继承有重写  
    ![单继承](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_vtable3.JPG)  
    父类虚函数地址排列在子类虚函数地址前面，父类中被重写的虚函数换成了子类对应的虚函数地址   

  * 多继承无重写  
    ![多继承](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_vtable4.JPG)  
    * 每个父类都有自己的虚表（所以对应每个基类，子类对象中就多一个指针所占的空间）。  
    * `子类的虚函数被放到了第一个父类的表中(在没有重写的情况下)。（所谓的第一个父类是按照声明顺序来判断的）`估计也是为了寻址快才放到第一位
    * 第一个虚表就是`Base1的虚函数加上子类的虚函数`

  * 多继承有重写  
    ![](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_vtable5.jpg)  
    (三个父类都有f函数, 子类重写了f函数)  
    三个父类虚函数表中的f()的位置被替换成了子类的函数指针。这样，我们就可以任一静态类型的父类来指向子类，并调用子类的f()了

## 虚函数表并不很安全

>  虽然任何妄图【使用父类指针想调用子类中的未覆盖父类的成员函数】的行为都会被编译器视为非法，所以，这样的程序根本无法编译通过，但运行时，【却可以通过指针的方式访问虚函数表】来达到违反C++语义的行为。

* 对象的地址就是虚函数的地址，对于没有重写的虚函数，无法通过指向子类的父类指针来调用`Base b = new Driver();`  
  但是却可以通过对象的`地址计算来访问其他未重写的虚函数`
* 如果父类的虚函数是private或是protected的，但这些非public的虚函数同样会存在于虚函数表中，所以，我们同样可以使用访问虚函数表的方式来访问这些non-public的虚函数


## 虚函数的入口地址和普通函数有什么不同？

* 每个虚函数在虚函数表vtable中占了一个表项，保存了它的入口地址。当一个包含虚函数的对象被创建的时候，它在头部附加一个指针，指向虚函数表vtable中的相应位置
* 调用虚函数的时候，不管用什么制作调用，它`先根据vtable找到虚函数的入口地址，再执行。从而实现了“动态联编”。而不像普通函数那样简单地跳转到一个固定地址`。

## 子类指针可不可以指向父类对象呢？

> 子类指针不可以指向父类对象, 因为子类包含了父类没有的方法。

* 子类总是含有一些父类没有的成员变量，或者方法函数。而子类肯定含有父类所有的成员变量和方法函数。所以用父类指针指向子类时，没有问题，因为父类有的，子类都有，不会出现非法访问问题。

* 用子类指针指向父类的话，`一旦访问子类特有的方法函数或者成员变量，就会出现非法`，因为被子类指针指向的由父类创建的对象，根本没有要访问的那些内容，那些是子类特有的，只有用子类初始化对象时才会有


## 父类的指针，怎么调用子类的虚函数？调用流程是什么

> [C++父类指针指向子类对象的实现原理](https://blog.csdn.net/FX677588/article/details/77727110)  
> 父类指针指向子类对象，通过该指针只能访问父类的成员，但为了访问子类成员引入虚函数，而且只能访问重写了该父类的虚函数的函数  
> 依据的是【继承】+【重写】

* 父类指针指向子类对象时，由于子类【继承】了父类,因此内存中的子类里包含父类的所有成员。但`【由于声明的是父类指针，因此该指针不能够访问子类的成员，而只能访问父类的成员】`
* 在父类里可以声明纯虚函数和定义虚函数，使用父类指针访问虚函数或纯虚函数的时候，访问到的是子类里【重写】的函数。当然，对于虚函数，如果子类里没有对其重写的话，仍然访问到父类里定义的虚函数


## 父类指针指向子类对象，指向的是哪张虚函数表？

> 子类对象继承了父类的虚函数表，重写也是重写子类的虚函数表，所以指向的是子类的虚函数表

* 虽然子类继承父类后包含了父类的虚函数表，但无法通过父类指针指向子类对象来访问子类的虚函数（除非是重写父类的虚函数），父类指针指向子类对象，指向的虚函数表应该是子类的虚函数表


## 抽象类和纯虚函数

> 带有纯虚函数的类为抽象类，它不能生成对象。`如果实现了纯虚函数，就不再是抽象类`。

* 为一个继承体系提供一个公共的根，为派生类提供操作接口的通用语义。

* 就像动物类，它是一个类别的抽象(`抽象类`)，没有实际意义，就像马、牛这样实实在在的生物，他们属于动物这个类别。这些动物都有一个属性就是[会动]，那这个属性就可以看成是动物这个类的纯虚函数，但不同的动物动的方式不一样，所以这个属性应该由马、牛这些子类去做具体的实现

* 在很多情况下，基类本身生成对象是不合情理的。为了解决这个问题，方便使用类的多态性，引入了纯虚函数的概念，将函数定义为纯虚函数（方法：virtual ReturnType Function()= 0;）`纯虚函数不能在基类中实现`，编译器要求在派生类中必须予以重写以实现多态性。

* 抽象类只能作为基类来使用(`比如动物不是实实在在的一个实体`)，而继承了抽象类的派生类如果没有实现纯虚函数，而只是继承纯虚函数，那么该类仍旧是一个抽象类(`比如马是动物的一种, 但马还可以分不同品种`)，抽象类不能生成对象(`比如动物, 只知道它会动, 但不知道怎么动, 这个对象也就没实际意义`)


## 虚函数和纯虚函数的区别

> 区别仅仅在于：`纯虚函数没有定义,只有声明`

* 纯虚函数相当于占位符, 先在`虚函数表`中占一个位置由派生类实现后再把真正的函数指针填进去；除此之外和普通的虚函数没什么区别


## 析构函数的作用

* 析构函数是用来`释放所定义的对象中使用的指针`，默认的析构函数不用显示调用，自建的析构函数要在程序末尾调用。
* 默认析构 
  * 如果类里面只用到的基本类型，如int char double等，系统的默认析构函数其实什么都没有做
  * `如果使用了其他的类如vector，string等，系统的默认析构函数就会调用这些类对象的析构函数`
* 自己写的析构
  * 如果`动态申请了内存`，析构函数中需要进行释放
  * 如果`打开了文件`，析构函数中也要进行关闭


## 为什么要用虚析构？

> 有派生类的时候  
> 不用的危害：在派生类中申请的资源就不会得到释放，就会`造成内存泄漏`

* 如果不是虚析构   
  假如析构函数不是`virtual`的，就不会发生动态绑定，而是静态绑定，指针的静态类型为基类指针;  因此在释放内存时候只会调用基类的析构函数,而不会调用派生类的析构函数;

* 如果声明为虚析构    
  如果声明为虚析构，那么子类的析构函数会【重写】父类的析构函数，所以析构的时候调用道德是重写后的也即是子类的析构函数，由于存在【继承】关系，所以会继续运行父类的析构函数

* 由于基类函数是虚函数  
   派生类相同函数就自动变虚函数，所以派生类同名函数可以不指定为虚函数

## 为什么默认的析构函数不是虚析构？

* 默认不是虚析构函数是因为如果析构函数为虚函数就`需要编译器在类中增加虚函数表来实现虚函数机制，这样所需内存空间就更大了`，因此没有必要默认为虚析构函数。

* 析构函数不一定必须是虚函数，是否为虚函数`取决于该类的使用，一般该类为基类产生继承和多态时`，才会是虚函数，单独使用可以不是虚函数。


## 引用是否能实现动态绑定，为什么引用可以实现

> 可以

* 因为引用（或指针）`既可以指向基类对象也可以指向派生类对象，这一事实是动态绑定的关键`。用引用（或指针）调用的虚函数在运行时确定，被调用的函数是引用（或指针）所指的对象的实际类型所定义的。


## 为什么构造函数不声明为虚函数呢？

> 虚函数要有`_vptr指针`才能访问，虚函数指针存放在对象中，是在`类构造之后才有的`

* 虚函数相应一个指向虚函数表的指针，但是`这个_vptr指针是存储在对象的内存空间`
* 如果构造函数是虚的，就须要通过 vtable 来调用，但是对象还没有实例化，也就是内存空间还没有，怎么找vtable呢？所以构造函数不能是虚函数。


## 拷贝构造函数的参数不是引用可以吗?

> 不可以，参数【默认传递方式是值传递(拷贝)】，所以调用拷贝构造的时候又去找拷贝构造函数...

* 如果是值传递的话，调用拷贝构造函数时会进行拷贝（`函数参数默认是通过值传递），然后编译器又去找拷贝构造函数，于是会造成无限的调用，[直至函数栈溢出]`。编译是编译不通过的
  ```c++
  A a1(1);
  A a2(a1); // 这里调用了拷贝构造
  ```


## 哪些情况用到拷贝构造函数？

> 发生拷贝，函数参数的传递、函数的返回值、拷贝构造

* `用一个对象来初始化另一个对象`
  ```
  Account ac2（ac1）
  ```

* 当对象作为函数实参传递给函数形参
  ```
  fun（Account ac1）
  ```

* 当对象作为函数的返回值，创建一个临时对象
  ```
  Account add（Account &x）
  ```


## 哪些自动生成的构造函数需要禁止，为什么

> `拷贝构造、赋值构造`，因为这些都是【浅拷贝】

* 拷贝构造函数 和 赋值构造函数   
  定义类的时候, 编译器会自动产生哪些函数?
  ```c++
  A();
  A(const A&);                // 拷贝构造函数
  A& operator = (const A& a); // 赋值构造函数
  ~A();
  ```

* 哪些自动生成的函数要禁止? 为什么?   
  因为默认生成的这两个函数进行拷贝的时候都是进行`浅拷贝`, 如果类的成员中有指针的话，`浅拷贝方式的结果是只拷贝了变量, 没有重新分配内存`，导致两个不同对象的指针指向同一块内存区域，容易出现访问冲突，比如多次delete等错误

* 怎么禁止?
  * 用关键字`delete`  
    如：`A(const A&)=delete` 表示删除默认拷贝构造函数，即不能进行默认拷贝
  * 自定义拷贝构造函数


## `operator char()` 什么意思?

> [operator char() 什么意思](https://www.cnblogs.com/edwardlost/archive/2010/12/01/1887983.html)

* `operator` 不仅仅用于`操作符重载`，还可用于`强制类型转换`， 即该类型可以自动转换为char类型。
  ```c++
  class A
  {
     ...
     operator int() {return static_cast<int>(date);}
  }
  ... 
  cout << add(a1, a2) << std::endl; // a1, a2为A类对象
  ```

## 虚继承
TODO


## 访问权限和继承权限

* **三种继承方式`不影响子类对父类的访问权限`，子类对父类只看父类的访问控制权**   
* **继承方式是`为了控制子类的调用方对父类的访问权限`**
  * 相当于控制怎么继承父类的成员后，子类对这些成员的访问权限
  * 如果不想让任何人（包括外人和自己的亲子）知道自己继承了什么，这就叫private基础
  * 如果不想让`外人`知道继承了什么，但可以让自己的`儿子`知道，这就叫protected方式
  * 如果你大大方方地继承你父类的东西，不怕被外人看到，这就叫public继承

## 多态实现方式

* 编译时多态  
  * `重载`  
    * 同一类中的同名函数是重载, 这些方法的名称相同, 但是参数类型或个数不同, virtual关键字可有可无
    * 不同类中同名函数可能是覆盖，也可能是隐藏。根据是否有virtual以及函数参数是否相同区分；
  * `隐藏`
    * 指派生类的函数屏蔽了与其**同名**的基类函数，派生对象都是调用派生类的同名函数。
    * 如果子类的函数与父类同名，但是**参数不同，不论有无virtual**关键字、基类的函数都将被隐藏;
    * 如果子类的函数与父类同名，且**参数也相同，但是基类函数无virtual**关键字，此时基类的函数被隐藏  
      别和重写混淆了,覆盖是必须有virtual关键字

* 运行时多态
  > 父类指针指向子类对象 + 虚函数
  * `重写(覆盖)`  
   是指子类重新定义父类虚函数的方法, 以实现不同的功能; 函数体特征相同(函数名、参数类型个数),基类要是虚函数


### `RTTI`的使用？
* `Runtime Type Information`的缩写，运行时类型鉴定，如`dynamic_cast<>()`，适用于使用基类的指针或引用转换为派生类并调用非虚函数方法


## 对象三种创建方式

> [C++用new创建对象和不用new创建对象的区别解析](http://www.cnblogs.com/GODYCA/archive/2013/01/10/2854777.html)

```
A a(1);           //栈中分配
A b = A(1);       //栈中分配
A* c = new A(1);  //堆中分配 1. 内存分配在堆中; 2. 用new会自动调用构造函数
```

## 友元

> `friend int func(int arg); // 友元函数`  
> `friend class CA; // 友元类` 

* 通过友元，一个不同函数或者另一个类中的成员函数可以访问类中的私有成员和保护成员（那也就是说可以访问所有成员了）。
* 友元函数是可以访问类的私有成员的非成员函数。它是定义在类外的普通函数，`不属于任何类`，但是需要在类的定义中加以声明。

* 友元类的所有成员函数都是另一个类的友元函数，都可以访问另一个类中的隐藏信息（包括私有成员和保护成员）。        
* 友元关系`不能被继承`。 
* 友元关系是`单向`的，不具有交换性
* 友元关系`不具有传递性`。若类B是类A的友元，类C是B的友元，类C不一定是类A的友元，同样要看类中是否有相应的申明
* 友元破坏了类的封装性，数据的隐藏性


## 指针

### `printf`输出字符串指针

* 定义一个字符串指针, 并输出
   ```c++
   char* p_buff = "huangjinjie";
   printf("%s", p_buff);

   Q1: 可不可以去掉`"%s"`  
   A1: 字符串是可以的, 如果printf一个非字符串不加字符格式是不行的
    如: `printf("hello world");`可以打印,  
    `"hell world"`是一个字符串常量, 和`printf(p_buff)` 一样, 传入了一个地址`char*`, 所以可以不需要`%s`
   ```

### 数组和指针的区别

> 字符数组   `char sza[4] = "abc";`    
> 指针       `char *pszb = "abc";`   
> ++ 操作、取地址操作、 赋值操作、字符常量是否可修改

* `++ 操作`   
  * 数组   
    数组名是常量，常量不可以进行 `++` 操作
  * 指针  
    指针++ 表示移动到下一个指针地址（即地址+sizeof(int*)）

* `取地址操作`    
  数组名表示首地址，那么数组名前取地址符什么意思   
  * 数组    
    ```c++
    int a[3] = {1, 3, 4};
    cout << &a << endl;      // 数组的地址(即第一个元素的地址)
    cout << &a + 1 << endl;  // 整个数组之后的一个地址，即元素4之后的地址
    ```

  * 指针  
    ```c++
    int b = 4;
    int *p = &b;
    cout << &p << endl;     // 指针的地址
    cout << &p + 1 << endl; // 指针的下一个地址 + 1 * sizeof(int*)
    ```

* `sizeof`
  * 数组  
    `sizeof(数组名)` = 数组所占内存大小,,如果是char数组，别忘了末尾有个\0
  * 指针  
    `sizeof(指针)` = 指针大小(4字节/8字节)

* `赋值操作`   
  * 数组   
    数组名不可以被赋值
    ```c++
    char s[4];
    char* p = "abc";
    s = p; // 错误，不要以为数组名表示地址，p指针也是地址就可以赋值
    ```
  * 指针   
    可以把新的地址赋值给指针

* `字符常量`    
  【字符指针变量指向的字符常量中的内容是不能修改】
  * 数组
    数组p存放在栈上 ，内存分配时，会把`常量字符【拷贝】到栈`，所以可修改
    ```c++
    char p[] = "abcdef";
    ```

  * 指针
    指针存放在栈上，`指向全局区的常量字符串`，所以不可修改
    ```c++
    char *p = "abcdef";
    ```



### 数组指针、指针数组、函数指针

* 数组指针：`int (*p)[n];`  
   其中()优先级高，首先说明p是一个指针，指向一个整型的一维数组（或二维数组的某一行）
* 指针数组: `int *p[n];`  
   * 其中[]优先级高，先与p结合成为一个数组，再由`int*`说明这是一个整型指针数组，它有n个指针类型的数组元素。
   * `int *p=new int(12)与int *p=new int[12]`的区别  
      前者表示创建一个指针变量; 其指向一个存储数字12的地址; 后者表示创建一个长度为12的数组。
* 函数指针: `int (*pf)(int *)`  
   为一个返回值为int，参数为`int*`的函数指针;

### 引用和指针的区别

* `内存`   
  引用只是个符号，不占用空间; 指针则要分配空间;
  ```
  占内存大小:
  sizeof(引用) = sizeof(原变量);
  sizeof(指针) = 4 (32位机器上)
  ```
* `初始化`  
  指针可以为空，但是引用不可以为空;

* `使用`  
  引用在定义的时候必须初始化, 而且初始化之后就不许修改了，指针则可以随时改变指向;


### 智能指针的原理是什么

> [智能指针](https://www.cnblogs.com/wxquare/p/4759020.html)

* 智能指针的原理是什么  
  智能指针`实质是一个类`，行为上表现得像一个指针（如使用->访问）这个类的构造函数中传入一个普通指针，析构函数中释放传入的指针来实现资源的分配和释放。智能指针的类都是栈上的对象，所以当函数（或程序）结束时会自动被释放  

### 智能指针什么时候改变引用计数？ (shared_ptr使用引用计数)

* 构造函数中计数初始化为 1
* 拷贝构造函数中计数值 +1
* 析构函数中引用计数 -1
* 赋值运算符中，左边的对象引用计数 -1 ，右边的对象引用计数 +1
* 赋值运算符和析构函数中，如果减一后为0，则调用delete释放对象

### 你知道的智能指针有哪些？

* C++11 `unique_ptr` 只能由一个智能指针指向对象   
  不支持复制和赋值，但比auto_ptr好，直接赋值会编译出错。实在想赋值的话，需要使用：std::move
  ```c++
  {
      std::unique_ptr<int> uptr(new int(10));  // 绑定动态对象
      // 和shared_ptr相比，不能拷贝，不能赋值
      // std::unique_ptr<int> uptr2 = uptr;    // 不能赋值
      // std::unique_ptr<int> uptr2(uptr);     // 不能拷贝
      std::unique_ptr<int> uptr2 = std::move(uptr); // 转换所有权
      uptr2.release(); // 释放所有权
  }
  // 超过作用域，会自动释放内存
  ```

* C++11的 `shared_ptr` 允许多个指针指向同一个对象    
  * 基于引用计数的智能指针。可随意赋值，直到内存的引用计数为0的时候这个内存会被释放。
  ```c++
  int a = 10;
  int *p = NULL;
  int testp = new int;
  shared_ptr<int> test(testp); // 传入指针，通过构造函数初始化
  shared_ptr<int> ptra = make_shared<int> a; // 用make_shared初始化
  shared_ptr<int> ptra2(ptra); // copy 指针ptra和ptra2都指向a
  p = ptr.get(); // 获取原始指针
  ```
  * 引用计数有一个问题就是互相引用形成环，这样两个指针指向的内存都无法释放。需要手动打破循环引用或使用weak_ptr

* C++11的 `weak_ptr`  
  `weak_ptr`是一个弱引用，只引用，不计数。如果一块内存被shared_ptr和weak_ptr同时引用，当所有shared_ptr析构了之后，不管还有没有weak_ptr引用该内存，内存也会被释放。所以weak_ptr不保证它指向的内存一定是有效的，在使用之前需要检查weak_ptr是否为空指针。



### 野指针

* `产生`
  * `声明`  
  指针的时候, 没有初始化为NULL, 这样的话这个指针指向什么地方都是不确定的
  * `释放`  
  动态申请的内存时, 只delete或free了, delete只是表示程序释放  
  delete 释放空间，只是做个标志，表示p所在的内存空间可以被其他进程使用了  
  没释放之前，使用权是当前进程的；而且还需把指针p赋为NULL
* `危害`   
  指向不可访问地址  
  破坏正在使用的地址空间
* `防范`  
定义指针的时候就进行初始化    
释放的时候要把指针指向NULL


## 柔性数组

* 在结构体末尾声明`0长数组`  
  对编译器来说，此时长度为0的数组并不占用空间，因为数组名本身不占空间，它`只是一个偏移量`  
* 这个符号本身代表了一个不可修改的地址常量 （注意：数组名永远都不会是指针！ ）; 但对于这个数组的大小，我们可以进行动态分配
  ```c++
  typedef struct FlexiableStruct
  {
      int a;
      char array[0]; //或char array[];
      // 定义0长数组,只是把一个符号放在结构体内, 不占用内存
  }stFlexiable, *pstFlexiable;
  char szStr[] = "huangjinjie";
  pstFlexiable p_stFlexiable = (pstFlexiable)malloc(sizeof(stFlexiable) + strlen(szStr) + 1); // 给柔性数组申请空间
  ```

* 动态申请的内存只是申请给数组拓展所用，结构体的大小在创建时已经确定了 array明确来说不算是结构体成员，只是挂羊头卖狗肉而已  
   这样的变长数组常用于网络通信中构造不定长数据包，不会浪费空间浪费网络流量

## STL

* [c++标准模板库STL【快速查找】【最全】【常用】【语法】](https://blog.csdn.net/sinat_25721683/article/details/79073336)

### 容器

> `list` 封装了双向链表, `vector` 封装了数组  
> 最主要的区别在于vector使用连续内存存储的，他支持`[]`运算符，而list是以链表形式实现的，不支持`[]`

* `Vector`对于随机`访问`的速度很快，但是对于`插入`尤其是在头部插入元素速度很慢，在尾部插入速度很快。List对于随机访问速度慢得多，因为可能要遍历整个链表才能做到，但是对于插入就快的多了，不需要拷贝和移动数据，只需要改变指针的指向就可以了。另外对于新添加的元素，Vector有一套算法，而List可以任意加入。
* vector 当插入新的元素内存不够时，通常以2倍重新申请更大的一块内存，将原来的元素拷贝过去，释放旧空间。

* `map / set`
  * Map,Set属于标准关联容器，使用了非常高效的平衡检索二叉树：`红黑树`，他的插入删除效率比其他序列容器高是因为不需要做内存拷贝和内存移动，而直接替换指向节点的指针即可。
  * Set不包含重复的数据。Set只含有Key，而Map有一个Key和Key所对应的Value两个元素。
  * unorder_map和map, 前者是通过哈希表来实现的, 后者则是通过红黑树(默认就是有序的)

### 结构

* `queue / stack`
  ```
  #include <queue>
  queue<typename> name;
  队首：front()
  队尾：back()
  栈首：top()
  
  公用:
  入：push() 
  出：pop()
  是否空：empty()
  大小：size()
  ```

## 使用两个栈实现一个队列

> [使用两个栈实现一个队列](https://www.cnblogs.com/tracyhan/p/5490775.html)

* 队先进先出，栈先进后出
* 思路  
  入队时全入到stack1中, 出队时把stack1全倒到stack2后，再由stack2来pop ；这样stack1是正确的入队顺序，stack2是正确的出队顺序
  * 缺陷   
    如果是连续出栈操作或连续进栈操作的话没问题, 但是如果入队1 2 3 4 5 6 7 出队 1 2 3 4 再入队 8 9
    ```
    [top] stack1: 1 2 3 4 5 6 7 ---> 5 6 7 ---> 5 6 7 8 9 ; stack2: 1 2 3 4 5 6 7 ---> 8 9 5 6 7
    ```
  * 修复  
    问题在于stack2中的元素还没出队完就把stack1倒进去了, 修改为先判断stack2输出完, stack2不空则继续输出，否则才把stack1倒到stack2里

## 使用两个队列实现一个栈

* 思路  
  入栈：队列1保存入栈序列  
  出栈：队列1的size-1个元素转移到队列2，这样最后剩下的那个就是最后一个元素了  
    再把队列2的元素放回队列1，以待下次pop，队列1暂时用队列2来保存队头前面的元素
    ```
    [back] queue1: 1 2 3 4  --> 4   queue2: 1 2 3 ---> queue1: 1 2 3
    ```


## 可变参数

> 三个宏`va_start, va_arg 和 va_end`，一个类型`va_list` 

* `va_list` 类型 
  ```
  va_list ap;
  定义 typedef char* va_list;
  只是一个指向char类型的指针。可以理解为指向当前参数的一个指针，取参必须通过这个指针进行。
  ```

* `va_start` 宏
  ```c++
  va_start(ap, paramN);
  初始化可变参数列表（把函数在 paramN **之后**的参数地址放到 ap 中）。
  ```

* `va_arg` 宏
  ```c++
  va_arg(ap, arg_type);
  取类型为arg_type的下一个值
  # 但是对于参数类型不止一种的例子呢 vsprintf
  ```

* `va_end` 宏
  ```c++
  va_end(ap);
  功能：关闭初始化列表（将 ap 置空）。
  ```



## 你对内存的了解

* `内存分配方式(生命周期)`  
  * 静态存储连续性   
    函数外定义的变量(全局变量)和使用satic定义的变量, 他们在整个程序运行过程中都存在  
  * 自动存储连续性   
    函数内定义的局部变量(包括函数参数), 他们在开始执行所属函数时被创建, 执行完函数后被释放  
  * 线程存储连续性  
    用thread_local定义的变量, 其声明周期和所属线程一样  
  * 动态存储连续性   
    用new/malloc动态申请的变量, 申请时被创建, 直到用delete/free将其释放

* `内存分配时期`  
  * 编译时不分配内存    
    编译时是不分配内存的。此时只是根据声明时的类型进行占位，到以后程序执行时分配内存才会正确;   
    所以声明是给编译器看的，聪明的编译器能根据声明帮你识别错误；  
  * 运行时必分配内存    
    运行时程序是必须调到“内存”的。因为CPU（其中有多个寄存器）只与内存打交道的。程序在进入实际内存之前要首先分配物理内存;    
    注意，涉及到内存分配的都是在运行阶段分配才有意义。

* `内存分区`  
  * 栈区  
    由编译器自动分配释放, 存放函数参数值和局部变量值等  
  * 堆区  
    由程序员动态申请释放, 存放用new/malloc等申请的变量  
  * 代码区  
    存放二进制代码  
  * 全局区/静态存储区   
    这块内存在程序编译的时候就已经分配好了, 存放全局变量和静态变量  
  * 文字常量区   
    存放字符串常量, 程序结后由系统释放

* `内存碎片`  
  * 内部碎片（操作系统导致）  
    * 已经被分配出去(能明确指出属于哪个进程)却不能被利用的内存空间;
    * 如某一数组容量为90，但实际只可以分配8字节的倍数大小可被 4、8 或 16 整除（视处理器体系结构而定）的地址容量即96,  
      也就是说会分配比实际需要稍微大一点的空间,`比如之前写dbf解析的时候用到mmap, 就是按整页分配, 不满一页也分配一页大小`
    * 剩下的6个字节内存在当前程序中得不到利用也不能再次分配给其他程序，所以成为了碎片。  

  * 外部碎片（程序员导致）  
    * 频繁的分配与回收物理页面会导致大量的、连续且小的页面块夹杂在已分配的页面中间，就会产生外部碎片。  
    * 例如:  
      ```
      有连续空闲字节空间0~99, 刚开始申请了10个字节(占用0~9), 接着申请了5个字节(10~14);  
      把刚才0~9的那10个字节释放, 然后需要申请20个字节, 此时, 刚释放掉的空间不满足大小, 所以分配在了15~34了;  
      0 --- 9 10 +++ 14 15 +++ 34 35 --- 99 (--表示空闲, ++表示占用)  
      所以, 如果10~14的空间一直占用着, 而往后申请的空间都大于10字节, 那么0~9的空间就一直用不上了
      ```

  * 怎么解决?  
    1. 利用分页单元把一组非连续的空闲页框映射到连续的线性地址, 意思是，我们使用地址转换技术，`把非连续的物理地址转换成连续的线性地址`
    2. 开发一种适当的技术来`记录现存的空闲的内存情况`，以尽量避免为满足对小块的请求而分割大的空闲块


## 内存溢出和内存泄漏

* 内存溢出
  > 程序在申请内存时，`没有足够的内存空间`
  * `使用安全的函数`，如snprintf而不是sprintf

* 内存泄漏
  > 内存`没有回收`，即申请了的内存没有正确释放
  * 类的构造函数和析构函数中 `new和delete没有配套`
  * 释放对象 `数组时没有使用delete[]`，使用了delete
  * 没有将 `基类的析构函数`定义为虚函数


## 堆栈的区别

* `管理方式不同`  
  栈是编译器自动管理的，堆需手动释放
* `空间大小不同`  
  在32位系统下，堆内存可达到4GB的的空间，而栈就小得可怜。(VC6中,栈默认大小是1M,当然,你可以修改它)
* `能否产生碎片不同`  
  对于栈来说，进栈/出栈都有着严格的顺序(先进后出)，不会产生碎片；而堆频繁的new/delete,会造成内存空间的不连续,容易产生碎片
* `生长方向不同`  
  栈向下生长，地址从高到低分配。以降序分配内存地址；堆向上生长，地址从低到高分配，以升序分配内在地址.
* `分配方式不同`  
  堆动态分配,无静态分配;栈分为静态分配和动态分配,比如局部变量的分配,就是动态分配(alloca函数)
* `分配效率不同`  
  栈是系统提供的数据结构,计算机会在底层对栈提供支持,进栈/出栈都有专门的指令,这就决定了栈的效率比较高.堆则不然,它由C/C++函数库提供,机制复杂,堆的效率要比栈低得多.


## 段页式存储管理  
TODO


## `mmap`

> 常规文件操作需要从 **`磁盘到页缓存再到用户主存`** 的两次数据拷贝    
>  
> `mmap` 操控文件，只需要从磁盘到用户主存的一次数据拷贝过程

* 常规操作需要两次拷贝  
  为了提高读写效率和保护磁盘，使用了页缓存机制。这样造成读文件时需要先将文件页从磁盘`拷贝到页缓存中，由于页缓存处在内核空间`，不能被用户进程直接寻址，所以还需要将`页缓存中数据页拷贝到用户空间`对应的内存

* `mmap`  
  mmap操作文件中，创建新的虚拟内存区域和`建立文件磁盘地址和虚拟内存区域映射`这两步，并没有把文件拷贝到主存。而之后进程真正发器读写操作，`访问数据时发现内存中并无数据而发起的缺页异常`过程，通过已经建立好的映射关系，只使用一次数据拷贝，就`从磁盘中将数据传入内存的用户空间`中，供进程使用。


## 虚拟地址是怎么映射到物理地址的，说一下这个过程

> `mmu` 将虚地址转换成物理地址，达到访存的目的

* 虚拟地址    
  > 你网盘有1T的空间，你最多可以用1T，但实际上没用到的部分是被其他用户共享的

  虚拟地址并不真实存在计算机中，`系统给每个进程都分配了虚拟空间`，进程可以认为这段虚拟空间是连续的，这个范围跟CPU位数相关，如32位系统中，进程的虚拟地址最大即为 2^32（4G）

* 物理地址
  即`内存芯片级的单元寻址`，进程运行时执行的指令和数据最终都落到物理地址上，比如一条4G的内存条，其可寻址空间就是 4G

* 地址翻译  
  * `linux` 内核采用页式存储管理。虚拟地址空间划分为固定大小的页面。由 `MMU 在运行时将虚拟地址映射成（或者说地址翻译）某个物理内存页面中的地址`


# 操作系统

## 进程

### `fork`
> pid = 0 // 子进程; pid < 0 // error; pid >0; //父进程

* 写时复制(copy-on-write):
   * fork()进程如果没有调用exec的话, 其代码空间和父进程是一样的
   * 只有`在fork之后exec之前两个进程用的是相同的物理空间（内存区）子进程的代码段、数据段、堆栈都是指向父进程的物理空间`，也就是说
      两者的虚拟空间不同，但其对应的物理空间是同一个。当父子进程中有更改相应段的行为发生时，再为子进程相应的段分配物理空间，所以fork操作是很快的
   * `资源的复制只有在写入的时候才进行`
    > 例: 进程A malloc()了一块内存，并将string s，存入该空间，fork出子进程B,B是否可以访问该内存，可以对内存的变量修改吗？   
      不能，虽然是在堆上分配的，子进程还是会自己重新复制一份自己的空间，在自己的空间上操作

### 僵尸进程、孤儿进程

* 僵尸进程
  * 什么是僵尸进程  
     父进程还在运行, 而子进程挂了, 但父进程没有清理子进程的进程信息，导致子进程虽然运行实体已消失, 但是仍在内核进程表中占有数据，造成资源浪费
  * 有哪些危害  
     `浪费系统资源`，子进程号会一直被占用,系统所能使用的进程号是有限的,如果产生大量的僵尸进程,最终可能导致系统没有可用的进程号,从而不能产生新的进程  
  * 解决方法
    * 杀死其所属父进程, 使其孤儿进程
      ```
      wait
        主进程阻塞, 随便一个子进程结束就停止阻塞
      waitpid
        非阻塞, 但需要用轮询的方式监控子进程
      signal
        其实是子进程退出时会给父进程一个信号, signal里用wait或waitpid都是非阻塞的
      只要父进程还在就都会监测子进程信号, 可以把所有子进程都回收
      ```
    * `kill -s SIGCHLD pid`  
      将这里的 pid 替换成父进程的进程 id, 这样父进程就会删除所有已经死掉的子进程了

* `孤儿进程`  
  子进程还在运行, 而父进程挂了, 子进程变为孤儿进程, 将由init进程收养，并清理进程信息

### `wait 和 waitpid` 的区别

* 从本质上讲，系统调用waitpid和wait的作用是完全相同的，但waitpid多出了两个可由用户控制的参数pid和options，从而为我们编程提供了另一种更灵活的方式
  ```c++
  sub_pid = waitpid(-1, &stat, WNOHANG);

  >0    只等待进程ID等于指定进程号的子进程，不管其它已经有多少子进程运行结束退出了，只要指定的子进程还没有结束 waitpid就会一直等下去。

  =-1   等待任何一个子进程退出，没有任何限制，此时waitpid和wait的作用一模一样。 　　

  =0    等待同一个进程组中的任何子进程，如果子进程已经加入了别的进程组，waitpid不会对它做任何理睬。

  <-1   等待一个指定进程组中的任何子进程，这个进程组的ID等于pid的绝对值
  ```

### 守护进程

* 运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件
  * 守护进程最重要的特性是`后台运行` 
  * 守护进程必须与其运行前的环境[隔离]开来  
    这些环境包括未关闭的文件描述符，控制终端，会话和进程组，工作目录以及文件创建掩码等; 这些环境通常是守护进程从执行它的父进程（特别是shell）中继承下来的  
    * 进程组  
      就是多个进程，进程组由进程组ID标识，进程组ID 也是一个进程的必备属性，每个进程组都有一个组长进程,
      组长进程的ID等于进程组的ID，进程ID不会因为组长进程的退出而受到影响  
    * 会话组  
      是多个进程组组成的，一个会话开始于用户登录，终止于用户退出，在此期间用户运行的所有进程都属于这个会话期，

    * 除这些特殊性以外，守护进程与普通进程基本上没有什么区别  
      编写守护进程实际上是把一个普通进程按照上述的守护进程的特性改造成为守护进程
* 步骤
  ```
  1. 【脱离终端】
  　　创建子进程，父进程退出
  　　所有工作在子进程中进行
  　　形式上脱离了控制终端

  2. 在子进程中【创建新会话】
  　　setsid()函数
  　　使子进程完全独立出来，脱离控制

  3. 【改变当前目录】为根目录
  　　chdir()函数
  　　防止占用可卸载的文件系统
  　　也可以换成其它路径

  4. 重设【文件权限掩码】
  　　umask()函数
  　　防止继承的文件创建屏蔽字拒绝某些权限
  　　增加守护进程灵活性

  5. 【关闭文件描述符】
  　　继承的打开文件不会用到，浪费系统资源，无法卸载
  ```

### `IPC`进程间通信

> [进程间通信](https://www.cnblogs.com/xcywt/category/778140.html)   
> [面试题：进程间通信的方式](https://blog.csdn.net/wm12345645/article/details/82381407)  
> 管道、信号、共享内存、消息队列、信号量、套接字

* 无名管道
  * 依靠fork函数, 实现`父子进程间`共用一个管道进行通信
  * 参数 filedis 返回两个文件描述符：filedes[0] 为读而打开
    ```c++
    int pipe(int filedis[2]) // 1. 创建无名管道(fork之前)
    close(file_descriptors[INPUT]); // 2. 关闭管道的读端
    write(file_descriptors[OUTPUT], "test data", strlen("test data") + 1); // 写入数据
    close(file_descriptors[OUTPUT]); // 关闭管道的写端
    read(file_descriptors[INPUT], buf, sizeof(buf)); // 读取数据
    ```

* 有名管道
  * 可以认为是通过文件来进行进程间通信, 写入读出的对象都是一个文件
  * 管道都有`同步和阻塞的问题(即自带同步互斥机制、而且是半双工通信)`, 读写有等待的情况; 而且当读写的数据大于`最大长度(管道通信消息有最大长度限制)`时会阻塞等待
    ```c++
    mkfifo(PIPENAME, 0666);    // 1. 创建管道
    open(PIPENAME, O_WRONLY);  // 2. 打开管道
    write(fd, &i, sizeof(i));  // 3. 写数据
    close(fd);                 // 4. 关闭管道
    ```

* 消息队列
  * **`和有名管道一样, 发送的数据都有一个最大长度限制`**
  * 生命周期随内核，消息队列会一直存在，需要我们显式的调用接口或使用命令删除
  * 消息队列`可以双向通信`，而且允许`一个或多个进程进行写入或读取消息`
  * 消息队列其实就是存消息的队列（链表实现的队列），消息有个字段是消息类型， 接收进程可以独立接收具有不同类型的数据块
  * 克服了管道只能承载无格式字节流的缺点
    ```c++
    #include<sys/msg.h>
    key_t key = ftok("./", 88);                  // 1. ftok 产生key
    int msgget(key_t key,int msgflg);            // 2. 建立消息队列
    int msgsnd(int msgid,void *msg_ptr,size_t msg_sz,int msgflag);
                                                 // 3.1 发送消息 0 阻塞 IPC_NOWAIT 非阻塞
    int msgrcv(int msgid,void *msg_ptr,size_t msg_sz,long int msg_type,int msgflag);
                                                 // 3.2.  接收消息类型为msgtype的消息
    int msgctl(int magid,int cmd,struct msgid_ds *buf);
                                                 // 4. 控制消息队列(也i可以删除)
    ```

* 共享内存
  * 不用从用户态到内核态的`频繁切换和拷贝数据，直接从内存中读取就可以`
  * 共享内存是临界资源，操作时必需保证原子性，可借助信号量或者互斥(linux锁机制)
    ```c++
    #include<sys/shm.h>
    key_t key = ftok("./", 88);                                 // 1. ftok 产生key
    int shmget(key_t key,size_t size,int shmflag);              // 2. 产生信号量ID
    void *shmat(int shm_id,const void *shm_addr,int shm_flag);  // 3. 映射共享内存地址，返回地址指针
    int shmctl(int shm_id,int cmd,struct shmid_ds *buf);        // 4. 控制共享内存(也可以删除)
    int shmdt(const void *shm_addr);                            // 5. 解除映射
    ```
* 以上通信机制的生命周期都随内核，`ipcs`可以查看到，如果不手动释放，就不会消失

* 信号量 Pv   
  对临界区资源进行保护， 解决进程间同步与互斥问题的一种进程间通讯机制
  ```c++
  #include<sys/sem.h>
  key_t key = ftok("./", 88);                                 // 1. ftok 产生key
  int semget(key_t key,int num_sems,int sem_flgs);            // 2. 产生信号量ID
  int semctl(int sem_id,int sem_num,int command...);          // 3. 控制信号量(也可以删除)
  int semop(int sem_id,struct sembuf *sem_ops,size_t num_sem_ops); // 解锁或锁定共享资源
  ```

* 基于套接字通信  
  所有的方法都是基于套接字通信的, 所以都有个套接字的入参
  * 服务器
    * 创建socket套接字
      ```c++
      int fd = socket(AF_INET, SOCK_STREAM, 0);
      AF_INET 表示使用TCP/IP协议族; SOCK_STREAM 表示使用TCP协议, SOCK_DGRAM 表示使用UDP协议;
      ```
     * `bind` 绑定地址和端口
     * `listen` 把套接字由默认的主动设置为被动连接状态，等待客户端链接
     * `accept` 接收到客户端连接进来, 返回新套接字与该客户端进行通信
     * 进行读`recv`写`send`通信
        ```c++
        int write(int fd, void *buf, size_t nbytes);
        int send (int sockfd, void *buf, int len, int flags)
        ```
     * 关闭套接字
       ```c++
       close(fd);
       ```
  * 客户端
    * 创建socket套接字
    * `connect`与服务器进行链接(三次握手)
    * 与服务器进行收recv发send通信
    * 关闭套接字


## 线程

### 多线程编程会带来什么问题

* 编写线程安全的函数、`调试`困难，比较难去重现bug、`同步互斥过程中造成死锁问题`

### 进程和线程的区别

> [线程和进程的区别](https://blog.csdn.net/lishenglong666/article/details/8557215)  
> 资源关系、切换开销、通信机制、数量关系

* `资源关系(数据和CPU)`  
  进程是资源分配的最小单位，线程是CPU调度的最小单位(拥有自己的栈空间)

* `内存地址`   
  * 进程在拥有`独立的内存单元`，而多个线程共享进程的地址空间  
  * 一个进程崩了不会对其他进程产生影响，而一个线程崩了，会导致整个进程都崩掉。

* `切换开销`   
  * `线程间彼此切换所需的时间也远远小于进程间切换所需要的时间`
  * 在Linux系统下，启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种"昂贵"的多任务工作方式  
  * 一个进程中的多个线程之间使用相同的地址空间，共享大部分的数据，启动一个线程所花费的空间远远小于启动一个进程所花费的空间  

* `通信机制`  
  * 进程间通过IPC进行数据共享, 不仅耗时而且很不方便
  * 线程是共用同一进程下的数据，更便捷（但是要注意多线程间锁的问题）

* `数量关系`  
  一个程序至少有一个进程，一个进程至少有一个线程，线程依赖于进程而存在;

* `使用场景`   
  * 对资源的管理和保护要求高，不限制开销和效率时，使用多进程   
  * 要求效率高，`频繁切换`，资源的保护管理要求不是很高时，使用多线程

### 线程状态

> [多线程—线程的5种状态](https://www.cnblogs.com/domi22/p/8046851.html)   
> [C++之多线程学习篇（3）之线程状态](https://blog.csdn.net/Jacoob1024/article/details/81097721)

* 新建状态   
  新创建一个线程对象时的状态

* 就绪状态  
  参与调度，等待被执行（即其他资源已获取，`就差CPU`了），一旦被调度选中，立即开始执行  

* 运行状态  
  获得CPU，正在运行中  

* 阻塞状态   
  因为某种原因`被迫交出CPU使用权`，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。

* 终止状态  
  已经运行完毕，等待回收线程资源

　　
### `Linux` 编程中的锁有哪些

> 信号量、互斥锁都是选择睡眠的方式来对共享工作停止访问的   
> 自旋锁不会引起调用者【睡眠】

* 互斥锁 `mutex`    
  当线程A先获取资源时，发现资源别的线程锁住了，CPU 进行上下文切换，`将线程挂起,置于等待队列，转而去执行别的任务，而不必进行忙等待`
  
* 自旋锁 `spin lock`    
  如果线程A是去请求锁，那么线程A就会一直在 CPU 上`进行忙等待并不停的进行锁请求，直到获得锁为止`
  * 自旋锁适合锁时间比较短的情况
  * 适合CPU是可抢占的情况 

* 信号量  
  * 就是一个`计数器`，通过`PV操作同步解决进程/线程对临界资源利用的冲突问题`  
    如果允许n个进程访问共享资源，信号量就设置为n，有进程进房子里P操作（py) 锁头就减 1，如果没有锁了（锁数量为0），还有进程想进来，那就挂起这个进程；进程访问完会把锁头交还给房管，此时锁头>0，刚才挂起的进程可以进来操作了


### 自旋锁和互斥锁的区别

* 自旋锁`不会引起调用者睡眠，执行效率比较高`

* 自旋锁会`一致占用 CPU` ，适合保持锁时间比较短的情况

* 自旋锁`很可能造成死锁`，比如递归地去调用


### 条件变量的使用

* 条件变量提供`信号机制`，所有等待该条件的线程同时阻塞，使用过程需要互斥量配合使用
  * 一个线程等待”条件变量的条件成立”而挂起
  * 另一个线程使”条件成立”（给出条件成立信号） 

* 条件变量是一个类，定义: `std::condition_variable iMsg;` 是【用来等待线程进行通知而不是上锁的】，是线程间`共享全局变量进行同步的一种机制` ，为了防止竞争，`条件变量的使用总是和一个互斥锁结合在一起` 

### 互斥锁

> 互斥锁、条件锁、自旋锁、读写锁


* `mutex`  
* `lock_guard`  
  类模板, 构造函数进行加锁, 析构函数进行解锁. 可以自己用大括号来限定作用域
* `unique_lock`  
  比lock_gurad灵活在会记住锁的状态,
* `condition_variable + unique_lock + notify_once + wait`
* `future、promise、async`

* `atomic`
* `协程`


### 死锁

* 四个**必要条件**
  * `互斥`  
    一个资源每次只能被一个进程使用
  * `占有且等待`(请求与保持)   
    进程因请求资源而阻塞时，对已获得的资源保持不放
  * `不可剥夺`  
    进程已获得资源，在使用完之前，不可强行剥夺
  * `循环等待`  
    A锁住了B需要的资源，B锁住了A需要的资源，导致A和B相互等待对方释放 

* 死锁的预防
  > 通过破除死锁四个必要条件之一，来防止死锁产生。
  * 破坏占有等待条件    
    进程在开始运行之前，一次性地申请其在整个运行过程中所需要的全部资源   
    我的 `parse_log` 就是这样的，创建线程前就分配好资源
  * 破坏不可剥夺条件   
    有进程申请被占用的资源时，占用资源的进程必须释放资源
  * 破坏循环等待条件  
    设置加锁顺序


### 线程死锁

* 产生原因  
  ```
  陷入互相等待的状态
  A线程锁住了mutex1, 在想用mutex2锁住的变量时尝试锁mutex2, 发现mutex2被锁了, 等待mutex2释放
  B线程锁住了mutex2, 在想用mutex1锁住的变量时尝试锁mutex1, 发现mutex1被锁了, 等待mutex1释放
  原因是A、B线程锁互斥量的顺序不一致, 解锁顺序倒是不影响
  ```

* 解决方法就是破坏几个条件中的一个
  ```
  c++11 thread 死锁解决

  1) std:lock() 函数模板
    std:lock(mutex1, mutex 2)
    解锁还是要手工unlock()，解锁顺序不影响
    可以一次锁住>=2个互斥量，不存在因锁的顺序问题而导致死锁的存在，会等所有都锁住才继续往下走
    原理:
      如果有一个互斥量没锁成功，则会释放掉已锁成功的互斥量，过段时间再去尝试，直到把所有互斥量都锁住为止
    缺点:
      lock()解决死锁的痛点在于存在忘记unlock的危险，而lock_guard刚好可以自动unlock，可否两者优点都有呢？

  2) lock() 和 lock_guard
    使用lock_guard的adopt_lock参数可以做到，让lock_guard构造的时候不lock, 但是必需在lock_guard之前加锁
    std:lock（mutex1,mutex2)
    lock_guard<mutex>lock_guard(mutex1, adopt_lock)

  3) atomic 原子操作
    类模板atomic声明的对象确保了该操作是原子性的, 不需要加锁
    std::atomic<int> g_atomic_counter(0); // atomic是一个类模板
    g_atomic_counter++;
  ```


### 生产者消费者问题
TODO

### 线程池

* 在程序开始就创建好线程待命，减少运行时线程创建的开销

<!-- ### 进程池、线程池、内存池 -->
TODO


## 协程

* 协程是`比线程更小`的执行单元。`拥有独立的寄存器、上下文、栈`

* 线程是抢占式、协程是`协作式`

* 协程的`调度完全由用户控制`（也就是说实在用户执行,所以比线程性能好，因为`不需要内核态用户态切换`）  

* `优点`  
  * `无需线程上下文切换的开销`
  * `无需原子操作锁定及同步的开销`
  * 方便切换控制流，简化编程模型
  * 高并发+高扩展性+低成本：一个CPU支持上万的协程都不是问题。所以很适合用于高并发处理。

* `缺点`
  * `无法利用多核资源`  
    协程的本质是个单线程,它不能同时将单个CPU 的多个核用上,协程需要和进程配合才能运行在多CPU；
  * `阻塞`操作（如IO时）会阻塞掉整个程序  
    这一点和事件驱动一样，可以使用异步IO操作来解决。

* 一个线程可以有多个协程，用户创建了几个线程，然后每个线程都是循环按照指定的任务清单顺序完成不同的任务，当任务被堵塞的时候执行下一个任务，当恢复的时候再回来执行这个任务，任务之间的切换只需要保存每个任务的上下文内容，就像直接操作栈一样的，这样就完全`没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快`；另外协程还需要保证是非堵塞的且没有相互依赖，协程基本上不能同步通讯，多采用异步的消息通讯，效率比较高。

## 大小端

> (高字节)  0x12345678 (【低字节】)  
> [低地址]: 12 34 56 78 (大端)  
> [低地址]: 78 56 34 12 (小端)  

* 大端  
  数据的`低字节保存在内存的高地址`中，数据的高字节保存在内存的低地址中
* 小端  
  数据的`低字节保存在内存的低地址`中，数据的高字节保存在内存的高地址中

* 利用`union`判断是大端还是小端
  ```
   由于union只存储一个成员，若一个union有一个int变量和一个char变量，那么若前一个int变量被赋值后 此时union存储的就是该int变量
   若此时读取char变量，由于char并没有被重写，所以读取的还是int变量的前8位
   根据读取的的8位字节判断是否=int的值, 如果相等，则证明int的值保存在低地址
              15       0        0        0
   [低地址->] 00001111 00000000 00000000 00000000[高地址] // 如果前8位=int的值, 则为小端
              0        0        0        15
   [高地址->] 00000000 00000000 00000000 00001111[低地址] // 如果后8位=int的值, 则为大端
  bool IsLittleEndian()
  {
      union
      {
        int a;
        char b;
      } u;
  
      int k = 15; //要在char范围内
      u.a = k;
      if ((int)u.b == k)
      {
          printf("小端\n");
          return true;
      }
      else
      {
          printf("大端\n");
          return false;
      }
  }
  ```


## 哈希

> 数组的特点: 查找容易, 插入删除困难  
> 链表特点:   查找困难, 插入删除容易

* 原理 
  * 哈希表（也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。
  * 它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度; 这个映射函数叫做散列函数，存放记录的数组叫做散列表。 `string --> key = hash(string)`
  
* 哈希表的应用
  * 安全领域  
    如md5、sha1等消息摘要算法, 用来判断文件完整
  * 查找  
    拿到string的key值后, 就能知道该string存储在哪了
  * 词频问题
  * top-k问题
  * 查找问题
  
  
### 解决哈希冲突的方法

> 不同的内容经过同一个散列函数后得到的key值可能是相同的, 这样叫发生冲突(碰撞)

* 缓冲区  
  把有冲突的数据都放到缓冲区, 如果在哈希表查不到就去缓冲区找
* 二次探测法  
  如果发现数组下标为hash(string)中已有值了, 就往右找(或者同时往左找)第一个没值的位置存放
* 再次哈希法   
  这种方法是同时构造多个不同的哈希函数： Hi=RH1（key）  i=1，2，…，k   
  当哈希地址Hi=RH1（key）发生冲突时，再计算Hi=RH2（key）……，直到冲突不再产生。这种方法不易产生聚集，但增加了计算时间。
* 拉链法  
  对于相同的key = hash(string)值的数据, 则以key为链表头结点, 往后拉出一条链表, 所有key相同的数据都插入到链表中


## 信号 

> [Linux 信号/软中断signal处理机制](https://blog.csdn.net/g1036583997/article/details/44935515)

* 什么是信号  
  软中断信号，又称为信号，Linux 提供的一种通知经常发生了异步事件的方法

* 信号处理函数
  * `SIGIGN`    
    忽略信号的处理程序
  * `SIG_DFL`  
    默认信号处理程序

* 怎么发信号？
  * 命令 `kill -s SIGCHLD pid`
  * 命令 `kill -9 pid`
  * 库函数 `kill(pid, SIGUSR1)`

* 注册信号处理函数对信号做出响应，用户注册的信号处理函数是在用户态下运行
  ```c++
  signal(SIGCHLD, SignalHandler);
  // SignalHandle 为信号处理函数, 收到SIGCHLD会调用该函数
  ```

* [可靠信号(实时信号)、不可靠信号(非实时信号)](https://www.cnblogs.com/shichuan/p/4448030.html)
  * linux信号机制基本上是从unix系统中继承过来的。早期unix系统中的信号机制比较简单和原始，后来在实践中暴露出一些问题，它的主要问题是：
  * 进程每次处理信号后，就将对信号的响应设置为默认动作。在某些情况下，将导致对信号的错误处理；因此，用户如果不希望这样的操作，那么就要在信号处理函数结尾再一次调用signal()，重新安装该信号。
  * 早期unix下的不可靠信号主要指的是进程可能对信号做出错误的反应以及信号可能丢失。
  * linux支持不可靠信号，但是对不可靠信号机制做了改进：在调用完信号处理函数后，不必重新调用该信号的安装函数（信号安装函数是在可靠机制上的实现）。因此，linux下的不可靠信号问题主要指的是信号可能丢失。
 
 
### 常见信号

> 可以通过 `kill -l` 查看系统支持哪些信号

* `SIGALRM`  
  定时信号, 计算的是实际的时间或时钟时间，alarm函数使用该信号.(alarm闹钟)
  ```c++
  signal(SIGALRM, SigHandler);
  alarm(30);  // 设置闹钟时间为30秒，30秒后触发信号，SigHandler处理信号
  ```
* `SIGHUP`  
  和控制台操作有关，`当控制台被关闭时`系统会向拥有控制台sessionID的所有进程发送HUP信号
* `SIGINT`  
  interrupt 终止进程，用户按下`Ctrl+C`时发送
* `SIGKILL`  
  消息编号为9，kill -9来`杀死进程时`发送
* `SIGSEGV`  
  `内存越界、权限问题`，试图访问未分配给内存, 或图往没有写权限的内存地址写数据
* `SIGIO`  
* `SIGSYS`  
 系统调用中参数错，如系统调用号非法
* `SIGCHLD`  
  通知父进程`处理僵尸进程`  
* `SIGPIPE`  
  这个是向一个`没有读进程的管道写数据`产生的错误  
  在网络编程中这个信号发生在如果客户端已经关闭了套接字, 而服务器调用了一次write，服务器就会收到一个RST segment，如果服务器再次调用write，这个时候就会产生SIGPIPE信号，系统默认的处理方式是关掉这个进程
* `SIGUSR1`  
  用户自定义信号 默认处理：进程终止

### 进程如何处理收到的信号

* `忽略信号`  
  即对信号不做任何处理，其中，有两个信号不能忽略：SIGKILL及SIGSTOP

* `捕捉信号`  
  定义信号处理函数, 当信号发生时, 执行相应的处理函数

* `缺省操作`  
  Linux进程对实时信号的缺省反应是`终止进程`


### 信号传递机制   

* 信号本质一个`软件模拟的中断`，或许是硬件中断Ctrl-C等操作，或许是软件kill函数等发送信号
* 进程注册信号，内核监控，`进程切换至内核，检测是否发生信号`，传递信号，进入进程的信号服务函数


### 系统如何将一个信号通知到进程？

> [`Linux` 下的进程信号处理过程](https://blog.csdn.net/h___q/article/details/84245317)  
> 内核在进程所在的【进程表项的信号域】设置对应的信号的位，进程`维护一个未决信号的【链表】`，处于【用户态】时就会处理信号   

* 进程维护着一个`未决信号的链表`。内核给进程发送信号，是在进程所在的`进程表项的信号域`设置对应的信号的位。   
  ![](https://s1.ax1x.com/2018/11/19/FSqxRH.png)

* 信号在进程中注册，其实就是把该信号加入到这个未决信号链表当中。

* `可靠信号` 不管链表中是否已经有这个信号了，都会加进去。  
  `不可靠信号` 如果链表中已经有这个信号了，就会忽略。

* `进程处理信号的时机` 是从内核态返回用户态时，会去检查是否有信号要处理

* 执行用户自定义的信号处理函数的方法    
  内核 【`把信号处理函数的地址放在用户栈栈顶`】 ，当进程从内核返回到用户态时（进入内核的方法就是异常、中断、系统调用），最先弹出信号处理函数地址，于是就去执行信号处理函数了，然后再弹出，才是返回进入内核时的状态

* 被屏蔽的信号，取消屏蔽后还会被检查


# 计算机网络和网络安全


## 分层模型

* 为什么要分层?
  * 层次之间`相互独立`。某一层并不需要知道它的下一层是如何实现的，而仅仅需要知道该层通过层间的接口所提供的服务。这样，整个问题的复杂程度就下降了。也就是说上一层的工作如何进行并不影响下一层的工作，这样我们在进行每一层的工作设计时只要保证接口不变可以随意调整层内的工作方式。

  * `灵活性好`。当任何一层发生变化时，只要层间接口关系保持不变，则在这层以上或以下层均不受影响。当某一层出现技术革新或者某一层在工作中出现问题时不会连累到其它层的工作，排除问题时也只需要考虑这一层单独的问题即可。

  * `易于实现和维护`。这种结构使得实现和调试一个庞大又复杂的系统变得易于处理，因为整个的系统已经被分解为若干个相对独立的子系统。进行调试和维护时，可以对每一层进行单独的调试，避免了出现找不到、解决错问题的情况。

  * 结构上可分割开。各层都可以采用最合适的技术来实现。技术的发展往往不对称的，层次化的划分有效避免了木桶效应，不会因为某一方面技术的不完善而影响整体的工作效率。

  * 能促进标准化工作。因为每一层的功能及其所提供的服务都已有了精确的说明。标准化的好处就是可以随意替换其中的某一层，对于使用和科研来说十分方便。

* 各层的作用
  ```
  应用层: 用户与网络间的接口    http
  运输层: 进程到进程间的接口    tcp/udp
  网络层: 主机到主机间的接口    ip
  数据链路层: 相邻结点间的接口  mac、以太网
  物理层: 物理介质间的接口
  ```

* 分层模型
  ```
  OSI
  应用层 -> 表示层 -> 会话层 -> 运输层 -> 网络层 -> 数据链路层 -> 物理层
  TCP/IP
  应用层 -> 运输层 -> 网际层 -> 网络接口层
  ```

* socket套接字接口就是七层模型中应用层以下封装的一个系统调用


## `ARP`

```
0. ARP是地址转换协议（Address Resolution Protocol）的英文缩写，它是一个`链路层协议`，工作在 OSI 模型的第二层

1：首先，每个主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址之间的对应关系。

2：当源主机要发送数据时，首先[检查ARP缓冲列表]中是否有对应IP地址的目的主机的MAC地址，如果有，则直接发送数据;
   如果没有，就向本网段(**局域网**)的所有主机[发送ARP数据包]，包括的内容有：源主机IP地址，源主机MAC地址，目的主机的IP地址。

3：当本网络的所有主机收到该ARP数据包时，首先检查数据包中的目的IP地址是否是自己的IP地址，如果不是，则忽略该数据包;
   如果是，则[更新自身Arp缓存]首先从数据包中取出源主机的IP和MAC地址写入到ARP列表中;
   如果已经存在，则覆盖，然后将自己的[MAC地址写入ARP响应包]中，告诉源主机自己是它想要找的MAC地址。

4：源主机收到ARP响应包后, [更新自身arp缓冲]将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据;
   如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。

0. A表示 IP地址, 电话号码表示Mac地址

1. 在公园里, A 想打电话给 B, 翻看通讯录[检查arp缓存]没发现B的号码; (如果有就直接打电话过去了)

2. 于是A在公园大喊一声[arp请求(广播)]:我是A,我号码是123, B你的电话号码是什么

3. 公园里其他人看到问的是B, 就没管它;
   B看到有人问自己号码, 于是就把对方存到通讯录[更新arp缓存], 然后打电话告诉对方:我就是B[arp响应(单播)]

4. A看到接到电话说他就是B, 于是就记录到自己通讯录中, 下次想找B直接从通讯录打电话过去
```

### `Arp`欺骗

* 有两个问题  
A不管谁打电话来说他是B, 他都认为是真的 B 打过来的  
B也不管谁说A的号码是什么, 他都认为这就是真的 A 的号码

* 假设有一个不规矩的C,电话号码是234  
  * A在公园喊：我是A, 我号码是123,  B你的电话是多少?  
   `单向欺骗` 这时候C就打电话给A, 说我就是B, 然后A就把234保存为B的号码, 这样以后A要联系B都会去通讯录找
   所以C就完全知道A想告诉B的内容了
  * `双向欺骗` C再可以假冒A, A虽然在公园喊谁是B的时候, C也在喊:我是A, 我的号码是234, B你的电话是多少?  
   这时候B会把234当作A的电话号码记到通讯录,.  
   之后, A要跟B交流会打234这个号码, C看到A发给B的内容后, 转手发给B, B看到是234发过来的, 就认为是A的内容, 然后继续通信下去...


## `TCP/UDP`的区别

> `TCP` 提供的是【面向连接的可靠的】传输服务，在传输数据之前会先发起三次握手建立连接，而且有【超时重传、滑动窗口、流量控制、拥塞控制】等机制来保证传输的可靠性，因此TCP的报文头20字节比UDP的报文头8字节大，所以TCP的【传输速度】没有UDP那么快。

* 用户数据包协议  
  UDP是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部）。

* 传输控制协议  
  TCP是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流  
  把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块

* TCP通过确认机制，丢包可以重发，保证数据的正确性;
  UDP不保证正确性，只是单纯的负责发送数据包；
  
* UDP是面向报文的。发送方的 UDP 对应用程序交下来的报文，在添加首部后就向下交付给 IP 层
  * 既不拆分，也不合并，而是保留这些报文的边界，因此，应用程序需要选择合适的报文大小；
* UDP的头部，只有 8 个字节，相对于TCP头部的 20 个字节信息包的额外开销很小。

* 连接性  
  TCP 是面向连接(Connection oriented)的协议，UDP是无连接(Connection less)协议
* 可靠性   
  TCP 可靠，UDP不可靠；TCP丢包会自动重传，UDP不会。
* 有序性  
  TCP有序，UDP无序；消息在传输过程中可能会乱序，后发送的消息可能会先到达，TCP会对其进行重排序，UDP不会进行重排序。
* 有界性  
  TCP无界，UDP有界； TCP通过字节流传输，UDP中每一个包都是单独的。
* 拥塞控制  
  TCP有流量控制（拥塞控制），UDP没有；TCP主要靠三次握手实现以及慢开始、拥塞避免、快重传、快恢复。
* 传输速度  
  TCP传输慢，UDP传输快； 因为TCP需要建立连接、保证可靠性和有序性，所以比较耗时。这就是为什么视频流、广播电视、在线多媒体游戏等选择使用UDP。
* 头部大小  
  TCP包头比较大。
* 应用场合  
  TCP一般应用在对可靠性要求比较高的场合，例如http，ftp等等。而UDP一般应用在对实时性要求较高场合，例如视频直播，大文件传输等等。

## 三次握手

> 目的是为了保证双方都能正常收发数据
> ![](http://blog.chinaunix.net/attachment/201304/8/22312037_1365405910EROI.png)

* 第一次握手   
  建立连接时,客户端发送syn包(syn=j)到服务器,并进入SYN_SEND状态,等待服务器确认;

* 第二次握手   
  服务器收到syn包,必须发送ACK来确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k);

* 第三次握手    
  客户端收到服务器的SYN＋ACK包,向服务器发送确认包ACK(ack=k+1);   
  此包发送完毕,客户端和服务器进入ESTABLISHED状态,完成三次握手.

* 解释
  ```
          你能听到我说话吗?
  A ---------------------------> B (A发完SYN进入SYN_SEND状态)
               SYN
  
         听到了,你能听到我吗?
  A <--------------------------- B (B发完ACK和SYN两个包后, 进入SYN_RECV状态) // 半连接
             SYN,ACK
  
              我听到了
  A ---------------------------> B (A发完ACK, A,B都进入ESTABLISHED状态) // 全连接
               ACK
  ```

* 前两次握手，C发了SYN，也受到了S的ACK，C知道它能连通S`（服务器在此时分配资源）`  
  最后一次握手收到C的ACK，S就知道它可以连通C`（客户端在此时分配资源）`


## 如果已经建立了连接，但是客户端突然出现故障了怎么办?

> 有保活计时器，如果过了保活时间还没反应，就会关闭连接    

* `TCP设有一个保活计时器`，显然，客户端如果出现故障，服务器不能一直等下去，服务器每收到一次客户端的请求后都会重新复位这个计时器，若发送探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。


## 三次握手过程网络中会发生什么错误

> 如第三次握手的ACK报文在网络中丢失   
> 发送`RST`给客户端然后关闭链接，防范 `SYN防洪`攻击

* [三次握手失败](https://blog.csdn.net/qq_26222859/article/details/60955713)

* 当失败时服务器并不会重传ack报文，而是直接发送RST报文段，然后进入CLOSED状态。这样做的目的是为了防止SYN洪泛攻击。

* 如果前两次握手都成功了，第三次握手client发送的 ACK 报文给服务器过程出现错误，过了超时时间后，服务器还没接收到，会重传，重传n次还没接收到，服务器会发送RST报文给客户端关闭这个链接


## 全连接、半连接

> 全连接保存`完成三次握手`的连接请求  
> 半连接保存`完成前两次握手`的连接请求 

* 完成三次握手的链接被放到到全连接队列, 只完成了两次握手的队列放在半链接队列

* Linux内核协议栈为一个tcp连接管理两个队列，一个是半链接队列（用来保存处于SYN_SENT和SYN_RECV状态的请求），一个是全连接队列（accpetd队列）（用来保存处于established状态，但是应用层尚未调用accept取走的请求）


## `SYN`攻击

> 拒绝服务(DDOS)攻击  
> 导致服务器响应缓慢，严重者导致网络堵塞甚至系统瘫痪


* 在三次握手过程中，服务器发送SYN、ACK后,收到客户端的ACK之前的TCP连接称为半连接.此时服务器处于Syn_RECV状态.当收到ACK后，服务器转入ESTABLISHED状态.
* Syn攻击  
  * 伪冒客户端, 在短时间内`伪造大量不存在的IP地址`, 不断往服务器发SYN包(`即第一次握手`), 服务器回复确认包并等待客户端的确认包(`即第二次握手`)，但是由于这些IP是伪造的,不会回复ACK包(`即不会有第三次握手`), 服务器会不断重发直到超时, `大量的SYN包会长时间占用半连接队列`, 导致正常的SYN请求被丢弃.  
  * 每收到一个SYN包, 就需要为该请求分配一个TCB（Transmission Control Block）, 通常一个TCB至少需要280个字节，在某些操作系统中TCB甚至需要1300个字节，并返回一个SYN ACK命令, 立即转为SYN-RECEIVED即半开连接状态
  * Syn攻击是一个典型的DDOS攻击。检测SYN攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击


## `SYN` 防洪防范措施   

> Syn Cache、Syn Cookie、 Syn Proxy、增大半连接队列

* 监测是否被攻击  
`netstat -n -p TCP | grep SYN_RECV`

* `SynCache技术`   
  这种技术是在收到SYN数据报文时不急于去分配TCB, 而是先回应一个SYN ACK报文, 并在一个专用HASH表（Cache）中保存这种半开连接信息，直到收到正确的回应ACK报文再分配TCB; 在FreeBSD系统中这种Cache每个半开连接只需使用160字节，远小于TCB所需的736个字节   
  * 旧逻辑   
    收到syn就分配TCB保存到半连接队列中
  * 现逻辑   
    **`收到syn先计算一个哈希值, 把哈希值保存到半连接队列, 等收到ack后才实际分配TCB`**, 并转入全连接队列   
    缺陷: 需要保存连接的序列号信息

* `SynCookie 技术`
  * **`完成三次握手前不分配资源`**    
   原理是，在TCP服务器接收到TCP SYN包并返回TCP SYN + ACK包时, 不分配一个专门的数据区，而是根据这个SYN包计算出一个cookie值，这个`cookie作为将要返回的SYN ACK包的初始序列号`。当客户端返回一个ACK包时，`根据包头信息重新计算cookie`，与返回的确认序列号(初始序列号 + 1)进行对比
   如果相同，则是一个正常连接，然后，分配资源，建立连接。

* `SYN proxy代理`  
  * 原理  
    作为server与client连接的代理，**`代替server与client建立三次握手的连接, 确保链接成功后proxy再与service连接`**

* 增大最大半连接队列

* 网关超时设置
  防火墙设置SYN转发超时参数, 该参数远小于服务器的timeout时间. 当客户端发送完SYN包，服务端发送确认包后（SYN＋ACK）
  防火墙如果在计数器到期时还未收到客户端的确认包(ACK)，则往服务器发送RST包，以使服务器从队列中删去该半连接。
  网关超时参数设置不宜过小也不宜过大，超时参数设置过小会影响正常的通讯，设置太大，又会影响防范SYN攻击的效果


## 四次挥手

> 目的是确保双方都把消息发送完了  
https://zhidao.baidu.com/question/518425014.html
![](https://gss0.baidu.com/-vo3dSag_xI4khGko9WTAnF6hhy/zhidao/wh%3D600%2C800/sign=2b294494c31b9d168a929267c3ee98b7/8644ebf81a4c510f841634516d59252dd52aa5af.jpg)

```
[主动方]                                  [被动方]
                        FIN1报文
FIN_WAIT1状态  C --------------------------> S  CLOSE_WAIT状态
                  我给你的消息发送完了, 你收到了吗?

                           ACK
FIN_WAIT2状态  C <-------------------------- S
                          收到了

                           FIN2
               C <-------------------------- S LAST_ACK状态
                  我给你的也发送完了, 你收到了吗?

                           ACK
TIME_WAIT状态  C --------------------------> S CLOSED状态
                          收到了
CLOSED状态
```

## 为什么握手三次, 而挥手要四次

* `建立连接时`   
  `Server`把响应客户端的请求和请求客户端的确认放在一起发送给客户端了,即第二次握手时有 `SYN + ACK`，ACK用来应答，SYN用来同步

* `断开连接时`  
  一个方向的断开，`只说明该方向数据已传输完毕` ,而另一个方向或许还有数据要发给对方,所以得等到另一个方向数据也全部传输完成后,才能执行第三次挥手
  
* 内核收到 FIN 后，由内核立即回复 ACK 对报文进行确认；而 FIN 报文则是应用层调用 close 函数的时候才发的


## 只有两次握手行不行?

* `情形一：第一次握手重传`  
  试想一下, C第一次发送SYN1请求连接, 但是在网络某节点滞留了, 然后C超时重传SYN2, 然后这一次一切正常, C跟S可以正常进行数据传输;    
  等到连接释放了以后, 那个SYN1请求突然到了Service那, 如果是两次握手的话, Service发送确认ACK2, 它们就算是建立起了连接了;    
  事实上C并不会理会这个ACK2确认, 因为我压根没有要传数据啊. 但是S却傻傻地以为有数据要来, 苦苦等待. `结果就是造成资源的浪费`.  
  ```
  C: 喂, 你听到了吗?
  C: 喂, 你听到了吗?(...那么久还没回应, 我再喊一次)
  S: 我听到了
  ......(交流)
  C: 喂, 你听到了吗?(就像回声, 会晚一点到达)
  S: 我听到了 (什么鬼?, 刚交流完, 又来?)
  C: 我没又要跟你聊天啊, 不管了
  S: 我都听到了, 怎么C还没说话?
  ```
  
* `情形二：第二次握手丢失`  
  假定C链接S, S发了syn+ack包给C; 此时S认为连接已经成功地建立了, 可以开始发送数据分组;
  但是如果syn+ack包丢失了, C不知道S是否准备好, `C一直在等待S的ack报, 将忽略一切S发过来的任何数据报文`, 而S发报文没收到C的回应, S就会一致超时重发
  ```
  C : 喂, 你听到了吗?
  S : 我听到了<由于网络原因, 这句话没有成功发给C>
  S ：(收了一大堆话)
  S : (不是连接好了吗，怎么没回应? 我重说一遍)
  C : ...(奇怪了, 怎么那么久还没回应, 也不知道他听到没有)
  ```


## `Time_Wait`为什么要等待`2MSL`

> 避免残余报文影响新连接、确保正常关闭

* TIME_WAIT状态有两种存在的理由：
  * 一个数据报在发送途中或者响应过程中有可能成为残余的数据报，因此必须等待足够长的时间`避免残余数据报影响新链接`.

  * `确保被动关闭方正常关闭`，比如主动关闭方发完ACK，但被动关闭方没收到，就会重发一个FIN之后，客户端等待2msl保证能对这个报文进行应答.

* 当TCP连接断开时候，执行主动关闭那一端在发完最后一个ACK报文后，会进入TIME_WAIT状态，等待2msl（每个分节最长生命期）

* 该状态存在于主动方`收到被动方的 Fin并返回ack包后`的状态 ，当处于time_wait状态时，我们无法创建新的连接，由于port被占用。


## 如何避免 Time_wait

* 设置套接字选项`SO_REUSEADDR`  
  服务器可以设置`SO_REUSEADDR`套接字选项来通知内核，如果端口忙，但TCP连接位于TIME_WAIT状态时可以重用端口


## TCP重传机制

* TCP`每发送一个报文段，就设置一次定时器`。只要定时器设置的重发时间到而还没有收到确认，就要重发这一报文段

* TCP 的可靠传输机制用字节的序号进行控制。TCP 所有的确认都是基于序号而不是基于报文段(UDP才是发报文段)。 `发送窗口没收到确认不动，和收到新的确认后前移`

## TCP确认机制

* TCP 要求接收方必须有`累积确认功能`，这样可以减小传输开销  

* 累积确认：一般地讲，如果发送方发了包1，包2，包3，包4；接受方成功收到包1，包2，包3。那么`接受方可以发回一个确认包，序号为4(4表示期望下一个收到的包的序号`；当然你约定好用3表示也可以)，那么发送方就知道包1到包3都发送接收成功，必要时重发包4。一个确认包确认了累积到某一序号的所有包。而不是对没个序号都发确认包。

* TCP 标准没有规定对不按序到达的数据应如何处理。通常是先临时存放在接收窗口中，等到字节流中所缺少的字节收到后，再按序交付上层的应用进程。  


## 滑动窗口机制

* TCP 采用大小可变的滑动窗口进行流量控制。窗口大小的单位是字节。其实就是`socket编程中讲的接收缓冲区、发送缓冲区`
  * TCP 连接的每一端都必须设有两个窗口, 一个`发送窗口`和一个`接收窗口`
  * `发送缓存`用来暂时存放：发送应用程序传送给发送方 TCP 准备发送的数据；TCP 已发送出但尚未收到确认的数据。
  * `接收缓存`用来暂时存放：按序到达的、但尚未被接收应用程序读取的数据； 不按序到达的数据。

* 在 TCP 报文段首部的窗口字段写入的数值就是当前`给对方设置的发送窗口数值的上限`。发送窗口在连接建立时由双方商定。但在通信的过程中，接收端可根据自己的资源情况，随时`动态地调整对方的发送窗口`上限值(可增大或减小)。 这样对方可以根据已发送的数据量来计算是否可以接着发送。在处理过程中，当接收缓冲池的大小发生变化时，要给对方发送更新窗口大小的通知，所以 A 的发送窗口并不总是和 B 的接收窗口一样大（因为有一定的时间滞后）。  


## 长连接、短链接

* 长连接  
  就是客户端发送连接请求，连接成功后就一直保持连接，直到客户端和服务端断开连接
* 短连接  
  就是客户端和服务端连接, 传输完数据之后，服务端再自动断开连接


## `GET`请求和`POST`请求的区别

* GET
  * 当客户端要从服务端读取数据时用GET，使用GET方法时，请求参数和对应的值 附加在URL后面
  * 利用问号?代表URL的结尾和请求参数的开始，传递参数长度受限制，例：/index.jsp?id=100&op=bind
* POST
  * 是向服务器提交数据，POST方法请求参数封装在HTTP请求数据中，可以传输大量数据，可用来传送文件。
* Get和Post请求的区别：
  * Get是向服务器索取数据的一种请求，而Post是向服务器提交数据的一种请求
  * [参数传递方式]Get请求的参数会跟在url后进行传递, POST请求的数据会放置在请求头内提交
  * [大小限制] Get对传输的数据有大小限制, POST没有
  * [安全性]Post比Get安全

## 浏览器输入地址后发生了什么

* 客户端[应用层]浏览器通过DNS解析到www.baidu.com的IP地址220.181.27.48，通过这个IP地址找到客户端到服务器的路径;
   客户端浏览器发起一个HTTP会话到220.161.27.48，然后通过TCP进行封装数据包，输入到网络层。
* 在客户端的[传输层]，把HTTP会话请求分成报文段，添加源和目的端口，如服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000，与服务器进行交换，服务器把相应的请求返回给客户端的5000端口。然后使用IP层的IP地址查找目的端。
* 客户端的[网络层]不用关心应用层或者传输层的东西，主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器，这些都是由路由器来完成的工作，无非就是通过查找路由表决定通过那个路径到达服务器。
* 客户端的[链路层]，包通过链路层发送到路由器，通过邻居协议查找给定IP地址的MAC地址，然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换的IP数据包现在就可以传输了，然后发送IP数据包到达服务器的地址。
1. [DNS]服务器(运行在应用层)把url转为ip地址
2. 浏览器发起一个http会话到这个ip地址, 进行[三次握手], 建立TCP连接, 通过TCP封装后, 进入到网络层
3. 浏览器发起HTTP的post请求, [传输数据]
4. 请求由应用层不断包装进入到数据链路层, 然后经过路由转发(拆解到网络层), 最终经过防火墙\NAT到达目的主机
5. 服务器处理该HTTP请求, 返回HTML文件
6. 浏览器解析HTML文件, 展示

## 常用端口

* 常用端口
  ```
  FTP      21
  TELNET   23
  SMTP     25
  POP3     110
  HTTP     80
  DNS      53
  SSL      443
  HTTPS    443
  ```


## 拥塞

* 采用滑动窗口机制还可对网络进行拥塞控制，将网络中的分组（TCP报文段作为其数据部分）数量维持在一定的数量之下，  
  当超过该数值时，网络的性能会急剧恶化。传输层的拥塞控制有慢开始（Slow-Start）、拥塞避免（Congestion Avoidance）、快重传（Fast Retransmit）和快恢复（Fast Recovery）四种算法。

* 拥塞  
  对资源的需求超过了可用的资源。若网络中许多资源同时供应不足，网络的性能就要明显变坏，网络的吞吐量随之负荷的增大而下降。  
  大量数据报涌入同一交换节点（如路由器），导致该节点资源耗尽而必须丢弃后面到达的数据报时，就是拥塞。


### 拥塞控制方法  

> [拥塞控制方法](https://www.cnblogs.com/losbyday/p/5847041.html)   
> 慢启动、拥塞避免、快重传、快恢复

* 慢启动
  * 新建立的连接不能够一开始就大量发送数据包，而只能`根据网络情况**逐步增加**每次发送的数据量`
  * 不能在TCP刚建立成功就向网络中发送大量的数据包，这样很容易导致网络中路由器缓存空间耗尽，从而发生拥塞。

* 拥塞避免   
  * 场景  
    慢启动之后的流量会`指数增长`，如果不适当地降下来，将会很快就占满网络资源。所以`设置了一个阈值`，一旦到达这个阈值，慢启动过程就结束，变为**加法增大**
  * 拥塞避免：  
    一旦出现网络拥塞，就立即把窗口`重置为1，把阈值降一半`，重新开始慢启动   
    ![](https://pic002.cnblogs.com/images/2010/125788/2010101120591634.jpg)

* 快重传 
  * 场景   
    如果接收端没有收到 A 报文，而先收到了 A+1 报文，按照快重传算法的规定，接收方应及时`再次发送对 A-1 的重复确认`，如果接收方还是没收到A报文，而是收到了后续的A+2,A+3报文，则接收方仍然是发送 A-1 的确认
  * 措施    
    `发送方收到连续三个对A报文的确认，就【立即重发A报文，而不会等待到超时才重发】`

* 快恢复     
  一般配合快重传使用，发生快重传后，就进入快恢复阶段，发送方会把自己的发送窗口减半，因为既然还可以发3个ack，说明网络并没那么糟糕，所以不会重置为1，而是执行拥塞避免算法    
  ![](https://pic002.cnblogs.com/images/2010/125788/2010101123101842.jpg)



## `TCP`的超时重传

* TCP中有四种计时器（Timer）
  * 重传计时器  
    对报文段确认的等待时间
  * 坚持计时器  
  * 保活计时器  
    用来探测对方是否还在连接
  * **时间等待计时器(Time_Wait)**  
    用来防止旧报文被新连接接收，确保被动方正常关闭

## 指数退避

## 对称加密、非对称加密

* 对称加密  
  * 加解密用的是同样的密钥  
    比如用123进行加密，解密时也要用123才能解密
  * 特点  
    密钥传递困难(不安全)  
    速度快，适合加密大量数据
  * 例子  
    DES、AES

* 非对称加密  
  * 使用了一对密钥，公钥（public key）和私钥（private key）。私钥只能由一方安全保管，不能外泄，而公钥则可以发给任何请求它的人。非对称加密使用这对密钥中的一个进行加密，而解密则需要另一个密钥
  * 特点  
    密钥要传递方便(安全)
    速度慢，适合加密少量数据
  * 例子  
   RSA、DSA
* 消息摘要算法
  * MD5、SHA1、SHA256

## `SSL`四次握手

* `SSL`中使用了非对称、对称加密，以及哈希算法
  ![](https://img-blog.csdnimg.cn/20190116143440926.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5ncWlhbmZlbmc=,size_16,color_FFFFFF,t_70)


## `HTTPS`

* 握手过程  
  ![](http://seo-1255598498.file.myqcloud.com/full/998866f5946d50c6c989443edbf90d5b8494fd34.jpg)
  * 浏览器把自己支持的加密算法告诉服务器
  * 服务器选一个`加密算法`和`哈希算法`以及自己的`证书（私钥）`发给浏览器
  * 浏览器`校验证书`是否合法，`生成随机密码`（对称加密的密钥），并用证书进行加密;  
    使用约定的哈希算法生成`握手消息的摘要`，并用生成的`随机密码加密摘要`   
    最后把【对称加密的握手消息】 + 【对称加密的摘要】 + 【公钥加密的随机数（对称加密密钥）】发给服务器
  * 服务器用自己的私钥解密得到对称加密的密钥，用对称密钥对信息进行解密，也对消息摘要进行解密，得到消息摘要，然后计算一次消息摘要，比较是否和报文中的相等

  * 至此，浏览器验证过后，握手完成，以后的通信过程就用浏览器生成的随机密码（对称加密密钥）进行加密传输

* 通信过程
  * 用对称密钥进行加密（因为握手过程已告知对方对称密钥），对方收到后可以方便地用对称密钥进行解密

## `HTTP` 和 `HTTPS` 的区别

* https协议需要到ca`申请证书`，一般免费证书很少，需要交费。
* http是超文本传输协议，信息是明文传输，https 则是具有安全性的`ssl加密传输协议`。
* http和https使用的端口不同
* http的握手过程和tcp三次握手一样，https握手过程和ssl握手过程一样
* http的连接很简单,是无状态的 。
* HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议， 要比http协议安全。


## 挑战响应认证

* 一种客户端认证机制，挑战相当于咨询，应答相当于回答。

* 特点是`密码不在网络上传输`  
   该认证机制中认证者每次向被认证者发送一个随机挑战字串，客户端收到这个挑战字串后，按照双方事先协商好的方法应答;
   ```
   C ---------- 认证请求 ----------→ S
      # Client发出认证请求，进行身份认证，发送Client的id
   C <---------- 挑战 -------------- S
      # 发送Server产生的Random_s
   C ----------  响应 -------------→ S
      # 发送用提供的加密算法加密的(Random_s + id)
   C <---------- 验证结果 ---------→ S
      # S用服务器保存的C的密钥加密(Random_s + id)，和C发过来的做比较，返回认证结果。
   ```

## `socket`

* socket可以看作是`用户进程`与`内核`网络协议栈之间的编程接口, 所有的bind, listen, accept, send等都是内核函数  
所以应用层是通过socket来与其他几层进行交互的(socket是对其他几层的封装)  
socket不仅能在本机间进行进程通信, 还可以在异构系统(即硬件可以不同)中进行
  > 虚线框中为内核空间
  ```
  [Application]                                          [Application]
        ↓                                                      ↓
        ↓ (socket)                                             ↓ (socket)
        ↓                                                      ↓
   - - - - - - - - - - - - - - - -  - - - - - - - -  - - - - - - - - - - 
  |  [TCP / UDP]                                           [TCP / UDP]  |
  |     ↓                                                      ↓        |
  |     ↓                                                      ↓        |
  |   [IP]                                                    [IP]      |
  |     ↓                                                      ↓        |
  |     ↓                                                      ↓        |
  |       --> --> --> --> --> [网络接口层] --> --> --> --> -->           |
  | - - - - - - - - - - - - - - - -  - - - - - - - -  - - - - - - -  - -|
  ```

* 三次握手  
  ![](http://images.cnblogs.com/cnblogs_com/skynet/201012/201012122157467258.png)

### `socket`在什么情况下可读

> socket可读其实就是read / recv有返回  
> 下列四个条件中的任何一个满足时,socket准备好读: 
> [`socket`在什么情况下可读](https://blog.csdn.net/szcarewell/article/details/51227540)

* 接收到数据  
  socket的`接收缓冲区中的数据字节大`于等于该socket的接收缓冲区低水位标记的当前大小
* 对方关闭连接  
  连接的`读这一半关闭(也就是接收了FIN的TCP连接)`。对这样的socket的读操作将不阻塞并返回0(所以read会读到0个字节)
* socket是一个用于监听的socket,并且`已完成的连接数非0`
* 函数调用异常  
  有一个`socket有异常`错误条件待处理.对于这样的socket的读操作将不会阻塞,并且返回一个错误(-1)


### `socket`在什么情况下可写

> 下列三个条件中的任何一个满足时,socket准备好写: 

* socket的`发送缓冲区中的数据字节大`于等于该socket的发送缓冲区低水位标记的当前大小
* 该连接的`写这一半关闭`。对这样的socket的写操作将产生SIGPIPE信号，该信号的缺省行为是终止进程
* 有一个`socket异常`错误条件待处理.对于这样的socket的写操作将不会阻塞并且返回一个错误(-1)


### `connect` 会阻塞，怎么解决

> 调用connect函数，如果服务端已关闭，则客户端会一直阻塞在connect那里

* 加定时器
* 使用非阻塞模式


### `send 和 recv` 阻塞和非阻塞模式

> socket 默认是阻塞的， `fcntl()`函数或者send、read最后一个参数可以设置为非阻塞模式  
> 阻塞与非阻塞 **返回值没有区分，都是 `<0 出错 =0 对方连接关闭 >0 数据大小`**
> `send/recv`只是把应用层的数据拷贝到内核发送缓冲区，真正执行发送以及什么时候发送是由系统(协议栈)决定的，所以函数返回成功，只能说明拷贝成功了，如果在还未发送之前网络断开，则发送失败。

* `send / sendto`  
  > 阻塞非阻塞就是当 `缓冲区大小buff < 要发送大小len` 时，是否等待
  * 阻塞模式  
    `buff < len`，则会阻塞，直到发送缓冲区里的数据被系统发送后，可用缓冲区大小比要发送的数据长度大时，send返回成功  

  * 非阻塞模式  
    `buff = 0`，则会立即返回 `EWOULDBLOCK` 错误，表示无法拷贝任何数据到发送缓冲区  
    `buff: (0, len)` 发送缓冲区有数据但是还未发送，则拷贝尽可能多的数据到缓冲区，所以存在非阻塞send返回的大小比发送数据的长度要小的情况，此时要轮询，直到要发送的大小等于已发送大小

* `recv / recvfrom`  
  > 从接收缓冲区拷贝数据。成功时，返回拷贝的字节数，失败返回-1  
  * 阻塞模式下`recv会一直阻塞直到缓冲区至少有一个字节（TCP) / 至少有一个完整的数据包(UDP) 才返回`
  * 非阻塞模式下如果没有数据就会返回，不会阻塞着读，有数据返回大小，无数据置erno为`EWOULDBLOCK`因此需要循环读取。 

* 返回值的意义
  > 阻塞与非阻塞`recv`返回值没有区别
  * `> 0`  
    表示成功发送n个字节, 如果n不等于buff的长度, 则不能表示发送完毕  
    实际情形下，由于对端的 TCP 窗口可能因为缺少一部分字节就满了，所以返回值 n 的值可能在 (0, buf_len] 之间, 所以要把剩下的(buf_len,n]继续发
  * `= 0`  
    对方如果 send 或者 recv 函数返回 0，我们就认为对端关闭了连接，我们这端也关闭连接即可  
    但是，现在还有一种情形就是，假设调用 send 函数传递的数据长度就是0的时候  
    send 发送 0 字节数据，client 的协议栈并不会把这些数据发出去,  server 端由于没有数据会一直阻塞在 recv 函数调用处
  * `< 0`  
    调用出错, 并设置错误码errno
    ```c++
    (errno == EAGAIN || errno == EWOULDBLOCK || errno == EINTR)) 
    //这几种错误码，认为连接是正常的，可以忽略继续接收
    ```

### read 常见错误码

  * `EINTR`
    中断错误  
    阻塞操作被取消阻塞的调用打断
  * `EWOULDBLOCK`  
    资源暂时不可用,表示无法拷贝数据到缓冲区
  * `EAGAIN`  
    send返回值小于要发送的数据数目  
    recv返回值小于请求的长度时说明缓冲区已经没有可读数据  
    当socket是非阻塞时,如返回此错误,表示写缓冲队列已满,可以做延时后再重试
  * `EPIPE`  
    socket关闭


### send/recv 和 write/read的区别

> [send/recv 和 write/read的区别](https://blog.csdn.net/petershina/article/details/7946615)

* 在功能上，read/write是recv/send的子集。read/wirte是更通用的文件描述符操作，而recv/send在socket领域则更“专业”一些多一个参数用来进行socket控制  
  如: 为接收和发送进行一些选项设置;从多个客户端中接收报文等




# 设计模式
TODO

## 单例模式





# 数据结构

> 每一句代码都要清晰明了

* TODO 所有的递归算法都可以借助栈或队列来实现非递归

## 排序

* `swap` 尽量使用变量交换的方法，要不然容易出问题

* 冒泡
  ```c++
  for (i = 0; i < len; i++)
  {
    for (j = 0; j < len - i - 1; j++)
    {
      if(s[j] < s[j+1])
        swap(s[j], s[j+1]);
    }
  }
  ```

* 快排
  ```c++
  void quickSort(int *a, int left, int right)
  {
    int i = left, j = right;
    int key = a[left];
    if (left > right) // 递归退出条件
      return;
    while (i < j)
    {
      while (a[j] >= key && i < j)
        j--;
      while (a[i] <= key && i < j)
        i++;
      if (i < j) 
        swap(a[i], a[j]);
    }
    swap(a[left], a[j]); // 因为循环退出s[j]是比key小的值，所以交换的是s[j]
    quickSort(a, left, j - 1);
    quickSort(a, j + 1, right);
  }
  ```

* 二分查找
  ```c++
  int BinSearch(int array[], int target, int len)
  {
    int low = 0;
    int hight = len - 1;
    while (low <= hight) // 要=
    {
        int mid = (low + hight) / 2;
        if (array[mid] == target)
            return mid;
        if (array[mid] > target)
            hight = mid - 1;
        if (array[mid] < target)
            low = mid + 1;
    }
    return 0;
  }
  ```

* 选择
  ```c++
  for (i = 0; i < len; i++)
  {
    minIndex = i;
    for (j = i + 1; j < len; j++)
    {
      if(s[j] < s[minIndex])
        minIndex = j;
    }
    if(i!=minIndex)
      swap(s[i], s[minIindex]);
  }
  ```

* `插入`
  ```c++
  void insertSort(int s[], int len)
  {
    int i,j,tmp;
    for (i = 0; i < len; i++)
    {
      tmp = s[i]; // 因为将要插入的值 s[i] 在后面移动中会被 s[i-1]覆盖掉,所以要暂存
      for (j = i - 1; j >= 0; j--)
      {
        if(s[j] > tmp)
          s[j+1] = s[j]; // 从后往前,把大于tmp的值往后挪
        else
          break;
      }
      // 循环退出的时候, j指向小于tmp的值的下标, 因为把元素复制后移了, 所以s[j+1]就是腾给tmp的
      s[j+1] = tmp; // 注意j要在for外定义
    }
  }
  ```

* 希尔排序

* 堆排
  > 去看父节点和子节点下标关系
  ```c++
  // 下标从0开始
  void sink(int *s, int len, int k)
  {
    while (2 * k + 1 <= len) // 判断的是【左儿子】，等于不能少，否则最后一个节点将无法参与排序
    {
      int j = 2 * k + 1;  //
      if (j < len && s[j] < s[j + 1]) // 【找大儿子】如果=，则j++就超过结点数了
        j++;
      if (s[k] > s[j])
        break;
      swap(s[j], s[k]);
      k = j;
    }
  }
  void heapSort(int *s, int len)
  {
    len -= 1; // 下标从0开始
    for (int k = len / 2; k >= 0; k--)
      sink2(s, len, k);
    for (; len > 0;)
    {
      swap(s[0], s[len]);
      len--;
      sink2(s, len, 0);
    }
  }
  ```


### 写个快排看看、如何优化？不用递归怎么写
TODO


## 队列和栈

### 用栈来判断括号是否匹配

* 描述  
  给定一个只包括 `'('，')'，'{'，'}'，'['，']' `的字符串，判断字符串是否有效(如`{[]}`有效，但`{[}]无效`)

* 思路  
  遇到左括号就入栈，遇到右括号就判断栈顶是否是对应的左括号, 是则出栈，最后剩下的是没右括号匹配的数据，看一下栈是否空就行了

### 用两个栈实现一个队列

* 思路  
  已知栈是先进后出，队列则反过来，先进先出，则把栈A的数据弹出依次压入栈B，顺序就颠倒过来，此时栈B的出栈顺序就是队的出队顺序   
  出队操作是先进先出，但是栈是先进后出的，如果把栈的元素颠倒一下，再出栈就是实际出队的顺序了

* 入队操作  
  数据全部存放在栈A，比如入队顺序为：`1,2,3,4,5,6`

* 出队操作  
  把栈A的数据依次出栈，则栈A为：`1,2,3,4,5,6 [top]`，然后把出栈的数据依次弹出全部压入栈B，则栈B为：`6,5,4,3,2,1 [top]`
  因此，出队顺序就是栈B的出栈顺序

* 缺点和改进
  * 问题  
    如果是全入队，出队是全出队则上诉思路没问题，但是如果是入队: `1,2,3,4,5,6 [top]` 出队: `1,2,3` 再入队 `7,8`  
    此时栈A为:`7,8 [top]`，栈B为：`6,5,4 [top]`，如果继续出队的话，栈A数据会全倒入栈B，则栈B为：`6,5,4,8,7 [top]`，  
    出队为：`7,8,4,5,6`，不是我们期望的 1~8
    问题就在于每次出队都是直接把栈A的数据倒入栈B再从栈B弹出数据，这样，如果栈B非空的话，数据顺序就会有问题
  * 改进  
    因此，在出队操作的时候，应该是先判断栈B是否还有数据，如果还有则应该先把栈B数据弹，直到栈B为空才把栈A倒入栈B  
    所以队列长度和是否为空都要判断两个栈的长度和是否为空

### 用两个队列实现一个栈

* 分析  
  已知队列是先进先出，因此按照两个栈实现队列的方法没用，因为队A倒入队B的顺序还是和队A一样  
  出栈的操作是先进后出，也就是后进先出，所以出栈就是把最上面的元素弹出

* 思路  
  队B作为队A的缓存，用来保存到队A里的 `size()-1`个元素，则最后留在队A的就是最上面的元素了，每次把最上面的元素弹出后，把保存在队B中的元素返回队A，因为入队的元素都是保存在队A的


## 链表

* 结点结构
  ```c++
  typedef struct ListNode
  {
     DataType info;
     struct ListNode *link;
  }Node, *PNode, *LinkList;
  ```

* **总结一下遍历链表的`while`循环退出条件**  

  * 如果需要遍历链表，且是从头结点开始`head = llist;` 则循环条件是`head->link != NULL`

  * 如果是用快慢指针，而且循环中 fast 比 low 走的快，则循环条件是`fast && fast->link`


### 构造带头结点链表和插入

* 定义头指针，创建头结点，把头指针指向头结点，并且初始化link域
* 代码
  ```c++
  void createNullLinkList()
  {
    LinkList llist = NULL; // 头指针
    PNode head = (PNode)malloc(sizeof(struct Node)); // 指向结点的指针
    llist = head;  // 把指向头结点的指针赋值给头指针
    if(llist == NULL)
      perror("malloc");
    else
      head->link = NULL; // 初始化link域
    return llist;
  }
  ```

* 插入
  ```c++
  void insertLinkList(LinkList llist, DataType x)
  {
    PNode newNode = (PNode)malloc(sizeof(struct Node)); // 申请结点
    if(newNode != NULL) // 结点插入到head后
    {
      newNode->info = x;
      newNode->link = llist->link;
      llist->link = newNode;
    }
  }
  ```

### 冒泡排序

* 需要注意的点  
  * 原本的冒泡中是判断 `s[j] s[j+1]`的大小来做交换，那在链表中怎么获取当前结点值和下一节点值呢？
  * 原本冒泡中会做swap交换数组值，那么在链表中是否要将两个结点交换呢？
    不需要。。。只要把值换了就行了
* 代码
  ```c++
  void LinkListBubbleSort(LinkList llist)
  {
    int len = GetLinkListLen(llist);
    for(int i = 0; i < len; i++)
    {
      PNode p = llist->link; // 注意点
      for(int j = 0; j < len-i-1; i++)
      {
        if(p->info < p->link->info)
        {
          DataType tmp = p->info;
          p->inf = p->link->info;
          p->link->info = tmp;
        }
        p = p->link; // 注意点
      }
    }
  }
  ```

### 翻转链表

* `思路`  
  把头结点后面的结点一个个插入到头结点和第一个结点之间， 指针修改按从后往前的顺序
* 代码
  ```c++
  LinkList reverLinkList(LinkList llist)
  {
      PNode pPreIns = llist->link;
      while (pPreIns->link != NULL)
      {
          PNode pInsert = pPreIns->link;
          // 指针调整(从后往前)
          pPreIns->link = pInsert->link;
          pInsert->link = llist->link; // 这里不能用pPreIns，因为新节点需要插入到最前面
          llist->link = pInsert;
      }
      return llist;
  }
  ```

### 输出倒数第k个结点

* `思路`
  * 快慢指针都从第一个结点出发, fast先走k个结点, 然后一起走（low指针应该从第一个结点和fast一起走,即初始化时low=llist->link），直到fast走完
  * 因为fast走了k之后low才开始走, 而且fast走完全程, 所有low只走了n-k（就是倒数第k个）
  * 其实和先计算链表结点数再走n-k是一个道理
* `代码`
  ```c++
  DataType LastKNode2(LinkList llist, int k)
  {
      LinkList fast, low;
      fast = llist;
      low = llist->link; // 关注点
      while (k--)
          fast = fast->link; // fast先走k个节点
      if (!fast)
          cout << "不存在" << endl;
      while (fast->link != NULL)
      {
          fast = fast->link;
          low = low->link;
      }
      return low->info;
  }
  ```

### 输出链表中间结点

* `思路`
  * 快慢指针都从第一个结点出发, fast和low同时前进，fast一次走两步, low一次只走一步
  * 因为fast走的路程是low的两倍, 所以fast走完的时候low刚好是走到n/2
* `代码`
  ```c++
  DataType MiddleNode(LinkList llist)
  {
      LinkList fast, low;
      fast = llist;
      low = llist;
      while (fast && fast->link)
      {
          fast = fast->link->link; // 一次走两步
          low = low->link;
      }
      return low->info; // 
  }
  ```



### 判断链表是否有环

* `思路`
  * 思路同上，只是当low==fast的时候就可以判定有环了
  * 这里其实快指针走3步4步都可以，只要比慢指针快就行

* `代码`
  ```c++
  bool IsCircle(LinkList llist)
  {
    LinkList fast, low;
    fast = llist;
    low = llist;
  
    while (fast && fast->link)
    {
      fast = fast->link->link;
      low = low->link;
      if (fast == low)
        return true; // 有环必定会相遇
    }
    return false;
  }
  ```

### 求单向局部循环链表的环入口

* `前提`  
  假如有快慢指针判断一个链表有局部环，链表起点是A，环的入口是B，快慢指针在环中的相遇点是C。那么按照原来的运动方向，有AB=CB，这是可以证明的结论
  ![](https://img-blog.csdn.net/20170713202226200?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlvbmdjaGFvOTk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
* `思路`  
  做法就是先找到`相遇点`（在判断是否有环的时候就写过了），然后把快指针重置会头结点，快慢指针继续同步走，如果再次相遇，则相遇点就是环的入口
* `代码`
  ```c++
  DataType GetCircleNode(LinkList llist)
  {
      PNode fast = llist;
      PNode slow = llist;
      // 和判断是否有环一样
      while(fast && fast->link)
      {
          fast = fast->link->link;
          slow = slow->link;
          if (fast == slow)
          {
              fast = llist; // 相遇点: fast->info
              break;
          }
      }
      // 同步走 AB = CB
      while (fast->link != NULL)
      {
          fast = fast->link;
          slow = slow->link;
          if (fast == slow)
              return fast->info;
      }
      return -1;
  }
  ```


### 判断链表是否相交

* `思路`  
  如果相交, 则从相交结点开始到末尾结点肯定都是相同的，(相交节点的data和link域都一样，所以后面的节点肯定也一样），所以只要判断两条链表最末尾的结点是否相等就行了

* `输出相交结点`  
  计算两条链表的长度差len, 然后长链表先走len步（`与短链表对齐`）  
  长短链表再一起走, 直到遇到第一个相等的结点

* 代码
  ```c++
  DataType GetYNode(LinkList llist1, LinkList llist2)
  {
      if (!IsY(llist1, llist2))
          return -1;
      int len1 = ListNodeNum(llist1);
      int len2 = ListNodeNum(llist2);
      PNode head1 = llist1;
      PNode head2 = llist2;
      while (len1 > len2 && head1->link != NULL && --len1)
          head1 = head1->link;
      while (len2 > len1 && head2->link != NULL && --len2)
          head2 = head2->link;
      // 以上两个循环表示[长链表]先走n步(n为差值), 以下循环表示两链表一起走, 直到相等
      // 我写得真妙啊
  
      while (head1->link != NULL && head2->link != NULL)
      {
          head1 = head1->link;
          head2 = head2->link;
          if (head1 == head2)
          {
              return head1->info;
          }
      }
  }
  ```


### 有序链表合并
TODO

## 二叉树

* 结点结构
  ```c++
  typedef char DataType;
  typedef struct TreeNode
  {
     DataType data;
     struct TreeNode *lchild;
     struct TreeNode *rchild;
  }TreeNode, *pTreeNode;
  ```

### 父节点和子节点下标关系

> [父节点和子节点间关系](https://blog.csdn.net/lanchunhui/article/details/52663514)

* 如果根节点标记为0
  ```
  · 第 i 个结点的左右孩子分别为：
  2i + 1
  2i + 2

  · 结点i的父节点为:
  i/2       当i 为左孩子结点；
  i/2-1     当i 为右孩子结点；

* 如果根节点标记为1
  ```
  · 结点 i 的左右孩子分别为：
  2*i
  2*i + 1

  · 结点 i (不论为左还是右孩子结点)
  其父节点都是 i/2
  ```


### 概念

* 性质
  * 非空二叉树第k层结点最多为**2^(k-1)** 个结点
  * 高度为 K 的二叉树中，总共最多有 **2^k - 1** 个结点
  * 非空二叉树普遍情况下,**n0 = n2 + 1**

* 完全二叉树
  * 只有最下面两层结点度<2,也就是：如果没有最后一层，那么它将是一个满二叉树
  * 最后一层结点都分布在左边
  * 共有n个结点，则深度为**log2(n)+1**
  * 深度为k的完全二叉树，至少有**2^(k-1)**,至多有**2^k-1** so,满二叉树是完全二叉树
  ![](https://images2015.cnblogs.com/blog/818487/201510/818487-20151007234152284-380514952.jpg)

* 满二叉树
  * 深度为k，且最多有2^k-1个结点,可以知道，其每一层节点数都是最大节点数
  * 深度为 k 的完全二叉树去掉第K层就变为满二叉树了  
    可以看出完全二叉树和满二叉树的关系

* 扩充二叉树
  * 添加外层结点，把原树中度数<2的结点都补为2
  * 外部结点个数 N 内部结点个数 n     **N - n = 1**
  * 外部路径 E 内部路径 I             **E - I = 2n**

* 平衡二叉树
  * 其左右子树都是平衡二叉树，左右子树的高度的绝对值<=1


### 二叉树还原

* 先+中
    根据终先序找到第一个根后，就可以在中序中将序列分成左右两部分,对分开后的两部分也这样分析就可以还原了
* 中+后
    方法和上面差不多，后序中最后一个元素就是根,倒数第二个就是根右边的儿子
* 先+后
   无解,只能确定父子关系而已

### 二叉树的存储

1. 数组  
   如果用数组来存储的话，可以根据父子结点的位置关系来确定一颗二叉树<如果子节点为i则富结点为i/2>
   但是无论如何都得按照完全二叉树的空间来分配即:2^k-1,很明显太浪费
   . 如果将一个算式存到二叉树那么先中后序遍历得到的式子刚好就是前缀中缀后缀

2. 链式存储  
   [data][llink][rlink]


### 二叉排序树

* 结点间是左小右大，子树也是二叉排序树, 结点元素是唯一的
* 插入删除都不改变树的结构
* 经过中序遍历后得到的是递增的序列(所以插入的时候，不可以在中间插入，必须遍历完,找到的位置一般都是末尾)
* 根始终大于左子树，小于右子树
* 子树也是二叉排序树

删除
三种情况:
* 所删结点为叶节点
* 所删结点左/右子树空
* 所删结点左右子树都非空

### 优先队列（堆）

* 和队列一样，队尾进,队头出。不同的是优先队列中的`最大/小元素总是位于队首`，所以并非先进先出，而是最大/小的元素先出。

堆
* 特点:  
  大/小根堆:  每个子二叉树的根均大/小于其左右子树

* 构建堆:  
  当新增加一个数被放置到堆顶时, 如果此时不符合最小堆的特性,则将需要将这个数向下调整`与左右儿子作比较, 与小儿子做交换(小根堆)`直到找到合适的位置为止,使其重新符合最小堆的特性。


### 线索二叉树

* 为了充分利用空指针,如果有儿子，指针就指向儿子,否则，作为线索只想前驱或后继结点。

### 最优二叉树

* 哈夫曼树 `WPL`

### 红黑树

TODO


### 二叉树计算

> 为了控制篇幅，具体看tree.cpp的具体实现，包含递归、非递归两种

* 节点定义
  ```c++
  typedef int DataType;
  typedef struct Node
  {
    DataType info;
    struct Node *lchild, *rchild;
  }*BiTree, *PNode;
  ```

* 创建

## 树的遍历

* 遍历
  ![](https://img-blog.csdn.net/20181017202631143?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hhcHB5amFjb2I=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

* 先序遍历   

  > 栈的特点是先进后出，可以保存节点的父节点

  * 入栈  
    遍历左子树，并访问，非空就入栈
  * 出栈  
    左子树为空则出栈，出完栈之后栈定就是上一个左结点，即已出栈结点的父节点，然后访问右子树，右子树进栈 
  * 图解  
  ![](https://pic1.zhimg.com/50/v2-3887e4fa2395c3408d20834bbf1fb921_hd.gif)

  * 代码  
    ```c++
    void PreOrder2(BiTree T)
    {
        stack<BiTree> stack;
        BiTree p = T;
        while (p || !stack.empty())
        {
            if (p != NULL) // 一直遍历到左边最小的那棵树
            {
                stack.push(p);
                printf("%c ", p->data); //访问根节点
                p = p->lchild;
            }
            else // 此时栈定,结点p指向左边最小那棵树的左结点
            {
                p = stack.top();
                stack.pop();
                p = p->rchild; //访问右子树
            }
        }
    }
    ```

* 中序遍历
  * 图解  
    ![](https://pic3.zhimg.com/50/v2-61c78e8d574efce6be7fb073b93b918b_hd.gif)
  * 代码
    ```c++
    void InOrder(BiTree T)
    {
        stack<BiTree> stack;
        BiTree p = T;
        while (p || !stack.empty())
        {
            if (p != NULL)
            {
            {
                stack.push(p);
                p = p->lchild;
            }
            else
            {
                p = stack.top();
                printf("%c ", p->data);
                stack.pop();
                p = p->rchild;
            }
        }
    }
    ```

* 后序遍历
  * 图解  
    ![](https://pic3.zhimg.com/50/v2-1765a07d58c5c572c691ee491bb5fa18_hd.gif)

* 层次遍历
  * 图解
  * 代码
    ```c++
    void LevelOrder(BiTree T)
    {
        BiTree p = T;
        queue<BiTree> queue;
        queue.push(p);
        while (!queue.empty())
        {
            // 访问头结点
            p = queue.front();
            printf("%c ", p->data);
            queue.pop();
            //左子树不空，将左子树入队
            if (p->lchild != NULL)
            {
                queue.push(p->lchild);
            }
            //右子树不空，将右子树入队
            if (p->rchild != NULL)
            {
                queue.push(p->rchild);
            }
        }
    }
    ```


* 翻转二叉树

* 输出树的高度/深度

* 计算二叉树结点数

* 二叉树的所有叶子结点

* 二叉树第K层的节点个数

* 二叉树中叶子节点的个数

* 二叉树中节点的最大距离

* 二叉树两结点最低公共祖先

* 判断是否是平衡二叉树



## 图

### 图的遍历

*  中国象棋中马走日字, 给定棋盘上两个点A、B, 马从A到B最短走几步

#### DFS

  深度优先搜索是类似于树的一种先序遍历，利用栈，：V1，V2，V4，V8，V5，V3，V6，V7.
![](http://img.blog.csdn.net/20130603151418281)

#### BFS  

广度优先搜索类似于树的层次遍历，利用队列，广度优先搜索次序为：V1，V2，V3，V4，V5，V6，V7，V8.  
![](http://img.blog.csdn.net/20130603151426015)


# 综合题

## 100层楼和两个玻璃球

> [100层楼和两个玻璃球](https://mp.weixin.qq.com/s?__biz=MzUyNjQxNjYyMg==&mid=2247484557&idx=1&sn=739d80488fe1169a9c9ca26ecfcdfba6&chksm=fa0e6b0ccd79e21a1c2b0d99db69f6206cddddfe2367742e9de1d7d17ec35a5ce29fa4e30d63&scene=21#wechat_redirect)   
> [100层楼和两个玻璃球](https://blog.csdn.net/JIEJINQUANIL/article/details/52344857)

* 描述  
  有一栋100层高的大楼，给你两个完全相同的玻璃球;
  假设从某一层开始, 丢下玻璃球会摔碎. 那么怎么利用手中的两个球, 用什么最优策略知道这个临界的层是第几层？？？
* 一颗球:
  * 想法一：逐层扔  
    如果只有一个球, 那只能一层一层试, 从第2层~第99层,因为如果第二层没碎, 那第一层肯定也不会碎, 如果第99层没碎, 那肯定第100层会碎  
    所以需要尝试98次
  * 想法二：隔层扔  
    既然一层一层扔太慢, 那可不可以隔一层扔一次? 比如从第2层扔没碎, 下一次就从第4层扔, 因为如果第4层碎了, 那临界层肯定就是第3层了...  
    所以最少需要 n/2 (100层则需要100/2次)
* 两颗球:  
  现在多了一个球, 可以借助这个球来划定区间, 就像二分查找, 也是在一个个区间中去找答案  
  * 想法一：`二分法`  
    如果第一个球在50层扔下没碎, 那扔下会碎的层肯定在(50, 100]之间, 那怎么划分这个区间更合理呢?
    是不是可以用二分查找的方法来做? 不行的, 比如在50层扔没碎, 按照二分法, 下一次从50到100的一半75层开始扔, 如果这时候碎了, 碎了这个球就不能再用了那能确定的是临界层是在50到75之间, 最坏的情况下还需要扔51、52、53...74 = 24, 也就是说总共需要扔1(50层) + 1(75层) + 24 = 26次
  * 想法二：`逐层递减`  
    既然第一步（确定临界段）的投掷数增加不可避免, 我们就让`第二步（确定临界层）的投掷数随着第一步的次数增加而减少一层`. 第一步的投掷数是一次一次增加的, 那就让第二步的投掷数一次一次减少，`设第一次抛下的层数为f，第二次从f-2开始抛，第三次从f-3开始，累加的和的意义就是楼的层数`。转化为数学模型就是: f+(f-1)+…+2+1>=99,
    即f(f+1)/2>=99, 解出结果是14(以下均为最坏的情况时的次数)  
    实际操作就是：从14开始扔, 如果碎了, 另一颗球就从[1,13], 一共 1 + 13 = 14 次
    如果14层扔没碎, 下一步从14+13=27层开始扔, 如果碎了, 一共就是 1 + 1 + [15, 26] = 14
    ...依此类推  
* 扩展   
  其实只需要13次就好了, 比如第一次从14楼扔下, 球碎了, 那第二颗球就从[2,13]区间扔就行了, 一共是 1 + 12 = 13次, 因为如果在第二层扔没碎, 那第一层肯定没碎, 如果在第二层扔下就碎了, 那第一层肯定就是临界层了)


## 4亿个数，你只有1G内存，你怎么判断某个数已经出现？

* 位图法: int的取值范围是`−2^31至2^31−1`, 我们可以连续申请`2^32 bit = 2^30 byte = 1G`的内存, 这样，每个bit都可以对应一个int数字，将这1G内存初始化为0
  接下来每次处理一个数字，就给它所对应的bit设为1，查询时就只要看其对应的bit值，当然0会有两个bit对应所以特殊处理一下。

* 位图法的基本原理是：使用位数组来表示某些元素是否存在，每一个bit位可以标记一个元素对应的Value。


## 有n级台阶，一个人每次上一级或者两级，问有多少种走完n级台阶的方法。

* 用动态规划表来抽象出实际问题  
  在这个问题上，我们让f(n)表示走上n级台阶的方法数。
  那么当n为1时，f(n)= 1,n为2时，f(n)=2,就是说当台阶只有一级的时候，方法数是一种，台阶有两级的时候，方法数为2。
  那么当我们要走上n级台阶，必然是从n-1级台阶迈一步或者是从n-2级台阶迈两步,
  所以到达n级台阶的方法数必然是到达n-1级台阶的方法数加上到达n-2级台阶的`方法数之和`。即f(n)= f(n-1)+f(n-2)


## 一个公交站在1分钟内有车经过概率是p，问3分钟内有车经过概率
 
* 正向考虑  
  `P = p+(1−p)∗p+(1−p)∗(1−p)∗p`
* 反向考虑   
  `P = 1−(1−p)^3`


# 数据库


## 连接查询

> 外连接查询 `table_a left join table_b ... on xxx where...`    
> 内查询 `inner join ...on ... 相当于 ：table_a, table_b where xxx`   
> 左连接：就是指依附左表，左表数据全查出来，右表只有符合条件的数据   
> [图解 SQL 里的各种 JOIN](https://blog.csdn.net/moakun/article/details/80429267)   

* 外连接    
  `left outer join` 就是外连接 ，加不加 `outer` 都一样

  * `left  join`(左联接)
    ```sql
    -- 返回包括左表 users 中的所有的记录,右表显示满足联接条件的记录, 没有则显示null
    select * from kbssuser.users a left join kbssuser.customer b on a.user_code=b.cust_code and b.cust_code=181920761; 
    ```

  * `right join`(右联接)
    ```sql
    -- 返回包括右表 customer 中的所有记录, 左表显示满足联接条件的记录, 没有则显示null
    select * from kbssuser.users a right join kbssuser.customer b on a.user_code=b.cust_code and a.user_code=180000016; 
    ```
  
  * `full join`(全连接)   
    全连接，显示两个表所有的信息
    ```
    ```

* 内连接   
  > where查询就是内连接
  ```sql
  -- inner join(等值连接)    
  -- 只返回两个表中满足联结条件的记录
  select * from kbssuser.users a inner join kbssuser.customer b on a.user_code=b.cust_code 
  ```

* oracle中的`(+)`相当于是一种语法糖     
  > 哪个表有加号，这个表的数据就是附加，另一个表则是全部的数据    
  ```sql
  -- 加号写在右表，则左表就全部显示，右表满足条件的才能显示，故以下语句左连接
  -- 这里用 `(+)` 后用的是`table_a, table_b(+) where xxx`，而不是 `table_a left join table_b on`  
  select * from kbssuser.users a, kbssuser.customer b where b.cust_code(+) = 170006465 and a.user_code = b.cust_code(+);
  ```

* 图解  
  ![](https://img-blog.csdn.net/20180922120245376?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21vYWt1bg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)


## 关系数据库的三大范式

> [第一、第二、第三范式之间的理解和比较](https://www.cnblogs.com/ktao/p/7775100.html)

* 第一范式   
  列是原子性的，不可再拆分  
  比如用户表里存储一个电话的字段，但是如果电话还有移动电话、家庭电话这两种，那就不应该把这些电话都存在一个字段
  
* 第二范式
  表的每一行记录是唯一的，即属性完全依赖于主键   
  也就是说可以根据主键定位到一条唯一的记录

* 第三范式
  如果表中有重复冗余的数据，应该单独设计一个表来存放   
  比如员工表里存放了部门编号，就不要再存部门名称等信息了，否则表里同一部门的数据就会出现大量冗余


## MySql性能调优

> [数据库优化面试题](https://blog.csdn.net/u010796790/article/details/52194850)  
> [`MySQL`优化思想](https://mp.weixin.qq.com/s?__biz=MzAwMDM2NzUxMg==&mid=2247488516&idx=4&sn=ad96d3cfdd6060c2166f64fd743aa05a&chksm=9aeb5af3ad9cd3e5a765266b8ecdfd5ed6a208e9de13792f360eb32c58f72554c5742985fa27&mpshare=1&scene=1&srcid=#rd)  

* 概览    
  ![](https://mmbiz.qpic.cn/mmbiz_jpg/tibrg3AoIJTtyNLZI14u9bf9jdcVFX7icZUib3hhCvWTTY8eWc4zIRxf4DaUS9Dxkaico2JeUL21C6MNnrgqSyQoIA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

* SQL语句及索引的优化 
  * 尽量不使用 `select * `，而是只查询需要的字段
  * 尽量避免全表扫描
  * 正确使用索引，避免在索引上进行计算（见 什么情况下设置了索引但无法使用 ）

* 数据库表结构的优化    
  表设计尽量符合`三范式`

* 系统配置的优化   
  MySQL集群、负债均衡、读写分离、分库分表

* 硬件的优化   
  加大内存、CPU、磁盘

* 缓存系统
  `redis 缓存`


## 什么情况下设置了索引但无法使用

* `条件中有or`，即使其中有部分条件带索引也不会使用

* 对于`多列索引`，不是使用的第一部分，则不会使用索引

* like查询是以 `% 开头`

* 存在索引列的 `数据类型隐形转换` ，则用不上索引，比如列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引

* where 子句里对 `索引列上有数学运算` ，用不上索引, 如 where id =  id+1;

* where 子句里对有 `索引列使用函数` ，用不上索引，如 where abs(id) = 11;


# 项目


## 一篇英文文章，求找出出现频率最多的单词(双缓存多线程分析大文件词频)

* 用流的方式打开文件, 读入指定大小的字节到内存中, 注意要进行截断检查
* 词频统计, 那怎么处理非英文的字符?   
  维护一个word数组, memset初始化为false, 下标在大小写字母和数字之间的ascii码为true;
  所以, word[i]为false的字符则不读入
* 利用两个缓存, 读入数据到buff[0]后就开多线程去处理buff[0], 然后切换buff, 读入数据到buff[1].  
  实现IO分离; 多线程在创建开始之前, 就计算好了开始处理的位置和处理结束的位置,所以不会发生冲突.
* 怎么分析  
  定义一个word字符数组来装单词,读入内存的数据一个个判断是否是有效的字符(用第2步的方法, 把字符作为下标,
  判断是否为true), 知道发现第一个不在word中字符(比如空格), 则word[128]中保存的就是一个有效的单词.
  然后去<char *, unsigned int>map中find, 看是否以该单词为key值的map, 有则+1(map中的key为单词, value为数目)
* 最后把所有的子map合并在一起, 然后遍历一遍总的map就知道了


## 探针

1. 需求  
   通过实时分析生产环境后台产生的业务日志, 一旦发现超时请求串就及时发送给对接系统进行处理, 减少人工干预, 保证业务办理顺畅

2. 须知  
   请求串和应答串有唯一msgid值来确定对应关系

3. 技术
4. 概述
```
系统使用双缓存多线程的方式, 把指定量的日志通过fstream读入到内存中,（如果读入的数据不是行尾, 则会继续往后读, 知道是行尾为止, 一面请求串被截断);
读取完后切换缓存, 这样可以继续分析处理已读入的文件;
具体处理方法是: 开多线程把已读入到内存的数据按照行尾分割到vector中, 然后再把这个vector按照msgid为key处理到unorder_multimap中;
   Q1: `既然使用多线程处理一个文件, 那你处理过程中有没有加锁呢？`
   A1: 第一步处理到vector是通过for循环来创建线程, 而且是指定了该线程需要处理的文件长度(也会做防截位处理)才开始创建;
       所以, 新线程处理的开始位置和处理大小都是确定的, 每个线程处理的位置不一样, 不会发生冲突
       但是确实是操作着同一块缓冲, 为什么就没发生多线程问题呢?
   A1: 创建线程代码如下, 其实是先计算线程1需要处理的 vecThreadLines, 然后让线程去吧这个 vector里的行映射到 map1 中,
       创建线程2的时候又计算了线程2需要处理的 vecThreadLines, 所以线程2处理的是这个新计算出来的vector, 处理到 map2 中
       也就是说不存在多线程同时处理一个文件的问题, 这个文件先被切割到不同的vec中了,各个线程处理的是各个vector
      for (int i = 1; i < iThreadCount; ++i)
		{
			if (llThreadIndex != llRealSize) // 避免文件只有一行时 getBlockSize 报错
			{
				llFileLen = getBlockSize(bBufferIndex, llThreadIndex, llThreadPart);
			}

			// 若剩余行数少于线程数,还需要判断一下线程已处理的字符和该块数据的大小
			if (llFileLen + llThreadIndex < llRealSize)
			{
				vecThreadLines = ReadLineToVec(bBufferIndex, llThreadIndex, llFileLen);
				threads[i] = thread(&CLbmRiskWarning::ParseMsgLine, this, vecThreadLines, i, strMsgKey);
				llThreadIndex += llFileLen;
			}
			else
			{
				break;
			}
		}

   Q2: 那你不是要处理到一个map中吗? 又开多线程, 怎么会没有多线程问题?
   A2: 如果是多个线程同时去写一个map, 那肯定是会有多线程问题的; 我的做法是: 每个线程从vector处理到map时, 都是处理到自己的那个map;
       比如1号线程解析数据到map1, 2号到map2; 这样各自线程都是解析到自己的那个map上, 不会冲突, 最后再把几个map合并到一起继续做后面的处理
   Q3:为什么不用锁呢?
   A3: 用锁可以保证最终处理到一个map上, 避免使用锁是因为在数据产生很快的情况下, 每条数据都要插入到map中, 这明显会把处理这一步拖慢;
       所以我就采用分map的方法, 最后合并实在处理线程外合并的, 不会影响处理速度.
处理完毕后扫描逻辑会去扫描unorder_multimap，找出一个key值只有一条记录的串, 然后判断如果是req串而且已经超时了, 那么就把它删除, 如果是ans串也把它删除; 如果只有req串但没超时则保留
   Q4: 既然你是一次读入n大小的内存, 那万一你的req串在内存A, ans串在内存B呢? 怎么处理?
   A4: 如果是这样, 如果扫描发现这个req串没有超时, 则保留在map中, 如果已超时则删除, 因为已超时了, 没必要去等ans串了
对于扫描发现超时的请求会异步发送给webservice, 并查看返回结果, 看是否发送成功, 如果没发送成功则继续发送, 发送成功则获取返回的json串做展示
   Q5: **异步发送?**
   A5: 因为扫描的时候发送webservice不可能阻塞在那里等它返回结果再扫描下一条, 所以这里是用c++11的future、promise来异步发送数据, 并开了一个监视线程来轮询监视future的结果;
      这样就可以保证接收端一有结果返回，本程序就能知道, 并作出相应的动作, 因为future对象是放在一个vector中, 所以对于因客观原因比如断网没有发送成功的记录会继续发送, 知道发送成功为止, 发送成功则从vector中删除记录.
   Q6: 为什么不直接用getline()来获取?
   A6：我的实现中是读入内存,然后按照\n分割到vec, 然后遍历vec映射到map中, 前面那两步明显可以用getline来直接从文件中获取一行数据啊
   Q7: 你的这个系统在分布式架构中适用吗？
   A7：不适用, 这个系统须放在服务器上, 如果是分布式架构, 每台服务器都要部署一个这样的程序, 程序后续的更新维护很不方便;
       (而且有的请求的请求串在服务器1, 应答串在服务器2上,金正的框架实际上不会这样)
       更好的做法是用 C/S架构, customer的职责是实时获取log日志的最新行, 并通过socket发送给service, 把这么一个customer程序部署到所有服务器中;
       这样所有的日志最终都是在service端做分析处理, 解决了req串在服务器A, ans串在服务器B的问题
```


## dbf提交到oracle的工具

* 需求 
   把dbf文件插入到数据库中, dbf文件很大(有一两g), 记录数有两千多万

* 技术方案
  ```
   使用[mmap]把dbf文件读到内存中, 提高处理效率
   dbfread 知道了dbf的二进制格式,就可以根据格式来进行解包了, 先把文件头去掉, 然后根据长度使用memcpy来进行内存拷贝
   Q1: mmap提高处理效率? 那你说说你对mmap的理解
   A1: mmp 
   Q2: 说说系统调用和库函数的区别
   A2: xxxxxxxxxxxxxxxxxx
  ```


## 中登账户数据核对

> [参考方案](https://mp.weixin.qq.com/s?__biz=MzI4NDMyNzA4NQ==&idx=1&mid=2247483816&sn=9c60561b82c016ed8be741260bc5b157)

* 需求    
  DBF文件中保存着客户的信息资料, 需要用该信息和系统内数据表的客户信息做比对，找出系统内数据库数据和文件数据不一致的数据

* 实行方案   
  将数据插入哈希表的之前进行一次查询操作，如果插入位置已经有数据了，且恰好不是本端的数据，ok，直接删掉原有的数据，分析下一条结果就行了; 这样，最后两端的数据插入完后，哈希表为空，说明比对结果正常。

* 比对其他字段一致, 但客户全称是否一致的例子
  * 基于股东号维度, 把股东号、一码通号、客户证件类型、客户证件号码、客户全称 从数据库中导出到txt文件
  
  * 解析dbf文件, 按顺序组装, 比如 string strCmpDbf = 股东号+证件类型+证件号码+客户全称; 这样的话dbf文件每一行记录就对应一个字符串, 然后把这些字符串哈希到文件中, 用hash(strCmpDbf)的值作为文件名, 值相同的会保存到同一文件中
  
  * 把第1步导出的数据做同样处理, 按照同样的顺序组装成字符串 string strCmpDb;  
    然后计算该字符串的哈希值, 用该哈希值与第2步的文件做碰撞(与第2步中的做比较) 如果存在hash值相同的文件, 则从该文件中查找是否存在字符串strCmpDb, 存在则删除;
  * 如果文件没有字符串了则删除该文件, 这样的话,最终剩下来的文件就是不一致的记录了, 由于是基与股东号维度, 所以可以确保这个记录是客户全称不一致的记录.


# 架构


## 如何设计一个高并发的系统

* `SQL优化`，包括合理的事务隔离级别、SQL语句优化、索引的优化；
* 使用缓存，尽量`减少数据库 IO`
* `分布式`数据库、分布式缓存
* 服务器的`负载均衡`


## 分布式


## 缓存系统

> [缓存与数据库](https://www.cnblogs.com/duanxz/p/3788366.html)

* 用过 `mysql + redis` 的模式，redis作为数据库的缓存，查询过的数据会存放到缓存中，如果下次再来查就先检查缓冲，缓存不存在再去查数据库, 缓存中找到数据，就直接从缓存返回；每次修改数据都要持久化到数据库
  ![](https://user-gold-cdn.xitu.io/2018/3/14/162237b7c0c5296d?imageslim)


### 缓存穿透

* 现象   
  当业务系统需要`查询数据库不存在的数据时，每一次求最终都要访问一次数据库`，即业务访问根本不存在的数据。
* 危害  
  大量这种根本查询不到数据的请求会对数据库造成冲击，拖慢数据库性能，甚至导致数据库崩溃
* 解决方案  
  * 缓存空数据   
    即将空数据null也做成一个缓存结果，这样在下次有相同请求到来时，缓存可以拦截该请求，返回缓存中的结果。
  * `BloomFilter(布隆过滤器)`  
    它需要在缓存之前再加一道屏障，里面存储目前数据库中存在的所有key。当业务系统有查询请求的时候，首先去BloomFilter中查询该key是否存在。若不存在，则说明数据库中也不存在该数据，因此缓存都不要查了，直接返回null。若存在，则继续执行后续的流程，先前往缓存中查询，缓存中没有的话再前往数据库中的查询。

### 缓存雪崩

* 现象  
  如果缓存在某个时刻挂了，那么大量的请求也将会直接访问数据库，造成很大压力。
* 危害  
  如果缓存因某种原因宕机，那原本被缓存抵挡的海量查询请求就会像疯狗一样涌向数据库。此时数据库如果抵挡不了这巨大的压力，它就会崩溃。
* 解决方案  
  * 使用`缓存集群`，增大可用性，当一个缓存挂了还有其他的缓存跟上。
  * 使用`Hystrix`，它是一款开源的“防雪崩工具”，它通过 熔断、降级、限流三个手段来降低雪崩发生后的损失。

### 缓存击穿

* 现象  
  指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，`当key失效的瞬间，且key值还没更新，持续的大并发就穿破缓存，直接请求数据库`，就像在一个屏障上凿开了一个洞。
* 危害    
  对于一些请求量极高的热点数据而言，一旦过了有效时间，此刻将会有大量请求落在数据库上，从而可能会导致数据库崩溃。
* 解决方案  
  * 使用`互斥锁`  
    上锁的对象为key，当失效后的第一个查询请求到来时，就会对缓存上锁，这时其他的查询请求就会被挡在外面，只有一个查询请求去访问数据库，直到缓存中更新了这个结果之后，剩余的查询请求才可查询缓存。
  * 对于很多热点数据集中失效，可以`设置不同的失效时间`，这样可以错开一部分热点数据的更新时间


## 消息队列

* 当【不需要立即获得结果】，但是【并发量又需要控制】的时候，差不多就是需要使用消息队列的时候。

* 使用较多的消息队列有 `ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ`

### 消息队列主要解决了什么问题

> [关于消息队列的使用场景](https://www.cnblogs.com/linjiqin/p/5720865.html)  
> 这篇文章已经总结得很好了

* `异步处理`   
  * 原本  
    完成流程A后才能接着流程B(发邮件)、流程C(发短信)，正常要等全部完成才返回成功    
  * 消息队列  
    完成流程A，就认为成功了，写入消息队列，后续B、C流程读取消息队列，知道A完成了，然后执行自己的流程

* `应用耦合`
  * 原本  
    A调用B，如果B挂掉了，则A也就没返回，无法继续   
  * 消息队列   
    A把消息写到消息队列就完事了，B从消息队列中取消息进行处理
  
* `流量削锋` 
  * 原本  
    业务系统直接请求服务器，会对服务器产生冲击
  * 消息队列   
    业务系统把请求写入到消息队列，由消息队列去请求服务器

* `日志处理` 
  日志采集系统采集日志后写入到消息队列，日志处理系统订阅并消费队列中的日志数据


# Linux


## `netstat`

* ps

* 对 `find` 到的文件进行 `command` 操作
  ```sh
  find /your/path -type f -name "*.swf" -exec cp {} dest_path \;
  find . -name "*log" -print -exec rm -rf {} \;
  ```


## `grep / sed / awk`

