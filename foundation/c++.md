
[TOC]

# C++

## make、gdb、动态静态库

## Linux网络编程


## 内核态和用户态区别

* 用户态切换到内核态:  
   系统调用、 异常、中断
* 当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）  
   *  此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈
* 当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）  
   * 此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。这与处于内核态的进程的状态有些类似。
* 既然库函数是调用系统函数, 那为什么不所有代码都放在内核中执行?  
   * 虽然内核执行高效, 但是放内核中执行太危险了, 一旦发生问题就会有宕机的风险; 所以要把有风险的程序放到用户态下执行


## 系统调用和函数调用

* 函数库调用是语言或应用程序的一部分，而系统调用是操作系统的一部分。
* 用户应用程序访问并使用内核所提供的各种服务的途径即是系统调用
  在内核和用户应用程序相交界的地方,内核提供了一组系统调用接口，通过这组接口，应用程序可以访问系统硬件和各种操作系统资源。
* 系统调用是为了方便应用使用操作系统的接口  
 而库函数是为了方便人们编写应用程序而引出的，比如你自己编写一个函数其实也可以说就是一个库函数。
* 系统调用可以理解为内核提供给我们在用户态用的接口函数，可以认为是某种内核的库函数; 系统调用比库函数调用更耗时  
   read就是系统调用,而fread就是C标准库函数.


## 为什么系统调用比库函数调用更耗时?

* 系统调用一般都需要保存用户程序的上下文(context) ,在进入内核得时候需要保存用户态的寄存器，在内核态返回用户态得时候会恢复这些寄存器得内容, 这是一个开销的地方
* 当程序中有系统调用语句，程序执行到系统调用时，首先使用类似int 80H的软中断指令，保存现场;去调系统调用号, 在内核态执行，然后恢复现场.
* 每个进程都会有两个栈，一个内核态栈和一个用户态栈。当执行int中断执行时就会由用户态，栈转向内核栈;
   * 系统调用时需要进行栈的切换。而且内核代码对用户不信任，需要进行额外的检查。系统调用的返回过程有很多额外工作; 比如检查是否需要调度等。


## 说一说 static

* `内存分配、生命周期`  
   static修饰的变量在编译阶段被分配在全局区, 其生命周期随程序的结束而结束
* `静态局部变量`  
   static修饰局部变量时，使得被修饰的变量成为静态变量，存储在静态区。存储在静态区的数据生命周期与程序相同;
   但是作用域只限制于其所在的函数中。 main函数执行之前初始化，程序退出时销毁。（无论是局部静态还是全局静态）
* `静态全局变量`  
   全局变量本来就存储在静态区，因此static并没有改变其存储位置。但是，static限制了其链接属性;
   被static修饰的全局变量只能被该包含该定义的文件访问（即改变了作用域）。
* `修饰函数`  
   static修饰函数使得函数只能在包含该函数定义的文件中被调用。对于静态函数，声明和定义需要放在同一个文件夹中。
* `类static成员变量`  
   用static修饰类的数据成员变量使其成为类的全局变量，会被类的所有对象共享(包括派生类的对象), 所有的对象都只维持
   同一个实例。 因此，static成员必须在类外进行初始化(初始化格式：intse::var=10;)，而不能在构造函数内进行初始化
   不过也可以用const修饰static数据成员在类内初始化。 静态成员变量在构造类之前就存在了，所有类对象只有一份拷贝
* `static成员函数`  
   用static修饰成员函数，使这个类只存在这一份函数，所有对象共享该函数，不含this指针，因而只能访问类的static成员变量
   只可以访问static成员，因为没有this指针(所以也不能声明为虚函数)
* `隐藏`  
   用static修饰的变量或函数仅在本文件内有效， 所以用static可以在不同文件中定义相同名称的变量或函数

## 说一说 extern

* `extern int g_Int;`  
   它的作用就是声明函数或全局变量的作用范围的关键字, 其声明的函数和变量可以在本模块或其他模块中使用,不能重复初始化
* 声明函数的时候使用`extern "C" {void fun(int a,int b);}` 可以让编译器按照C语言的方式生成函数的符号


## 说一说 const

* const修饰变量(包括指针)
   ```
   const int a = 10;
   const int *p = 10; // 表示*p的值不允许改变，*p = 100;// error; int b = 20; p = &b; // ok
   int c = 10;
   int * const p = &c; // p存放了一个固定的地址，所以初始化的时候要给他一个初值，表示p的地址不允许改变
   					   // int d = 20; p = &d // error; c = 20; //ok
   ```
* const修饰函数参数
   ```
   char* strcpy(char* dst, const char* src); // 防止src在strcpy函数内部被改变
   ```
* const修饰函数返回值
   ```
   const int get(); // 防止get() 函数返回值被改变
   ```
* const修饰函数
   ```
   int get() const;
   // 只可以用于类成员函数, 表示get()函数仅可访问类成员变量, 但是不可以改变类成员变量;
   // 只能调用const 成员函数，因为get()函数隐含了一个const this*指针
   ```

## const和#define的区别

* const 常量有数据类型, 而宏常量没有数据类型。编译器可以对前者进行类型安全检查。 而define只进行字符替换，没有类型安全检查，并且在字符替换可能会产生意料不到的错误。
* 有些集成化的调试工具可以对const 常量进行调试，但是不能对宏常量进行调试。
* #define 是在预处理阶段进行替换  
   const会在编译阶段替换, 会做安全检查, define只是简单地做替换;  
   const会报错, 便于调试

## typedef和#define的区别

> 类型别名与宏的三点区别，如`typedef char *String_t; 和#define String_d char *`两句：

* 前者是类型别名，要做类型检查，后者只是一个替换，不做类型检查；
* 前者编译时处理，后者预编译时处理，即预编译期间替换掉宏；
* 前者能保证定义的全都是char* 类型，String_d却不能;


## new和malloc的区别

* `性质`  
   new是操作符，操作符可以进行重载，malloc是库函数
* `使用`  
   new使用的时候会自动计算大小，malloc则要指定大小
   new/delete在对象(如类对象)创建的同时会自动执行构造函数做初始化，在对象在消亡时会自动执行析构函数
   而malloc只管分配内存，并不能对所得的内存进行初始化，所以得到的一片新内存中，其值将是随机的；
* `成功`  
   new成功后返回对象类型的指针，malloc返回void* 指针，需要自己做类型转换
* `失败`  
   new抛出异常，malloc返回会NULL，所以用new之后在判断是否为NULL没什么意义
* `扩容`  
   new不支持扩容, malloc在使用过程中发现内存不够可以使用realloc来进行扩容
* 既然有了malloc为什么还要new呢？

## string.h

* strcpy
```
char* strcpy(char* dst, const char* src)
{
	assert(dst!=NULL);
	assert(src!=NULL);
	while((*dst++ = *src++)!= '\0');
	return dst;
}
```

* memcpy
```
char* memcpy(char* dst, const char* src, size_t n)
{
	assert((dst!=NULL) && (src!=NULL));
	while((*dst++ = *src++) != '\0' && --n);
}
```

* strcmp
```
int MyStrcmp(const char* str1, const char* str2)
{
	assert((dst!=NULL) && (src!=NULL));
    while ((*str1++ == *str2++)!='\0' && *str1 && *str2);
    int result = *(--str1) == *(--str2) ? 0 : (*(--str1) > *(--str2) ? 1 : -1);
}
```

* strstr
```
char* MyStrstr(char* str1, const char* str2)
{
    assert(str1 != NULL);
    assert(str2 != NULL);

    if (*str2 == '\0')
        return str1;

    while(str1)
    {
        const char *cur = str2; // 每次不相等都从第一个字符重新开始
        while ((*str1++ == *cur++) && *str1 && *cur)
            ;
        // 循环退出, 指针指向不相等的字符的下一个字符
        if (*(--cur) == *(--str1))
            return str1 - strlen(str2) + 1;
        str1++;

        if (*str1 == '\0')
            return NULL;

    }
    return NULL;
}
```

## 虚函数表

* 编译器为每一个类维护一个虚函数表(本质是一个函数指针数组,数组里面存放了一系列函数地址);  
   每个对象的首地址保存着该虚函数表的指针, 同一个类的不同对象实际上指向同一张虚函数表。  
   对象不包含虚函数表，只有虚指针，类才包含虚函数表，派生类会生成一个兼容基类的虚函数表
* 在单继承形式下, 子类的完全获得父类的虚函数表和数据; 子类的虚函数表包含父类的虚函数地址, 且子类虚函数地址在后面  
   子类如果重写了父类的虚函数fun;就会把虚函数表原本fun对应的记录（内容BaseClass::fun）  
   覆盖为新的函数地址（内容SonClass::fun）  
* 纯虚函数相当于占位符, 先在虚函数表中占一个位置由派生类实现后再把真正的函数指针填进去;  
   除此之外和普通的虚函数没什么区别


## 什么时候要用虚析构函数

* 虚函数是动态绑定的基础  
   假如析构函数不是virtual的，就不会发生动态绑定，而是静态绑定，指针的静态类型为基类指针;  
   因此在delete时候只会调用基类的析构函数,而不会调用派生类的析构函数;
   这样, 在派生类中申请的资源就不会得到释放，就会造成内存泄漏
* 由于基类函数是虚函数  
   派生类相同函数就自动变虚函数，所以派生类同名函数可以不指定为虚函数


## 对内存的理解

* `内存分配方式`  
   静态存储连续性: 函数外定义的变量(全局变量)和使用satic定义的变量, 他们在整个程序运行过程中都存在  
   自动存储连续性: 函数内定义的局部变量(包括函数参数), 他们在开始执行所属函数时被创建, 执行完函数后被释放  
   线程存储连续性: 用thread_local定义的变量, 其声明周期和所属线程一样  
   动态存储连续性: 用new/malloc动态申请的变量, 申请时被创建, 直到用delete/free将其释放

* `内存分配时期`  
   编译时不分配内存  
      编译时是不分配内存的。此时只是根据声明时的类型进行占位，到以后程序执行时分配内存才会正确;
      所以声明是给编译器看的，聪明的编译器能根据声明帮你识别错误；  
   运行时必分配内存    
      运行时程序是必须调到“内存”的。因为CPU（其中有多个寄存器）只与内存打交道的。程序在进入实际内存之前要首先分配物理内存;  
      注意，涉及到内存分配的都是在运行阶段分配才有意义。

* `内存分区`  
   栈区: 由编译器自动分配释放, 存放函数参数值和局部变量值等  
   堆区: 由程序员动态申请释放, 存放用new/malloc等申请的变量  
   代码区: 存放二进制代码  
   全局区/静态存储区: 这块内存在程序编译的时候就已经分配好了, 存放全局变量和静态变量  
   文字常量区: 存放字符串常量, 程序结后由系统释放

* `内存碎片`  
  * 内部碎片(操作系统导致)  
    * 已经被分配出去(能明确指出属于哪个进程)却不能被利用的内存空间;
    * 如某一数组容量为90，但实际只可以分配8字节的倍数大小的容量即96, 也就是说会分配比实际需要稍微大一点的空间,
    * 剩下的6个字节内存在当前程序中得不到利用也不能再次分配给其他程序，所以成为了碎片。  
  * 外部碎片(程序员导致)  
    * 频繁的分配与回收物理页面会导致大量的、连续且小的页面块夹杂在已分配的页面中间，就会产生外部碎片。  
    * 例如:  
      > 有连续空闲字节空间0~99, 刚开始申请了10个字节(占用0~9), 接着申请了5个字节(10~14);  
         把刚才0~9的那10个字节释放, 然后需要申请20个字节, 此时, 刚释放掉的空间不满足大小, 所以分配在了15~34了;  
         0 --- 9 10 +++ 14 15 +++ 34 35 --- 99 (--表示空闲, ++表示占用)  
         所以, 如果10~14的空间一直占用着, 而往后申请的空间都大于10字节, 那么0~9的空间就一直用不上了
* `段页式存储管理`  


## 访问权限和继承权限

* **三种继承方式**
  * 继承方式是为了控制子类的调用方(也叫用户)对父类的访问权限。
意思就相当于你怎么继承你祖先的东西,想把父类的东西变为自己的东西，你要给这些东西加个属性啊
  * 比如你不想让所有人知道，私下继承，那你祖先原本公开（public属性)或者只允许子孙知道的(protected)东西到了你这儿就都变成私有的了。
  * 如果你继承了你祖先的东西，而这些你继承来的东西你不想别人知道，但你的子孙可以知道，那就用protected方式，这样的话，你祖先原本公开的物资, 到了你这儿也都变成自由子孙可以知道了
  * 如果你大大方方地继承你父类的东西，父类是怎么样的别人看到的就是怎么样

* 继承方式不影响子类对父类的访问权限

* 子类对父类只看父类的访问控制权，即不可能通过public继承来让子类看到父类的private变量;子类仍然能访问 public 和 protected 权限的父类成员

## 多态实现方式

* 编译时多态  
  * `重载`  
    * 同一类中的同名函数是重载, 这些方法的名称相同, 但是参数类型或个数不同, virtual关键字可有可无
    * 不同类中同名函数可能是覆盖，也可能是隐藏。根据是否有virtual以及函数参数是否相同区分；
  * `隐藏`
    * 指派生类的函数屏蔽了与其同名的基类函数，派生对象都是调用派生类的同名函数。
    * 如果子类的函数与父类同名，但是参数不同，此时不论有**无virtual**关键字、基类的函数都将被隐藏;
    * 如果子类的函数与父类同名，且参数也相同，但是基类函数无**virtual**关键字，此时基类的函数被隐藏
      别和覆盖混淆了,覆盖是必须有virtual关键字

* 运行时多态
  * `重写(覆盖)`  
   是指子类重新定义父类虚函数的方法, 以实现不同的功能; 函数体特征相同(函数名、参数类型个数),基类要是虚函数

## 对象三种创建方式
```
A a(1);           //栈中分配
A b = A(1);       //栈中分配
A* c = new A(1);  //堆中分配 1. 内存分配在堆中; 2. 用new会自动调用构造函数
```


## 指针

### `printf`输出字符串指针

* 定义一个字符串指针, 并输出
   ```
   char* p_buff = "asdf";
   printf("%s", p_buff);
   Q1: 可不可以去掉`"%s"`  
   A1: 字符串是可以的, 如果printf一个非字符串不加字符格式是不行的
       如: `printf("hello world");`可以打印,  
       `"hell world"`是一个字符串常量, 和`printf(p_buff)` 一样, 传入了一个地址`char*`, 所以可以不需要`%s`
   ```

### 数据和指针的区别

* 修改内容上的差别(比如++运算和字符常量)
* sizeof的差别
* 数组名的作用以及数组名前面添加取地址符的作用  
   * 数组名是数组首地址，是一个常量，不可以当作指针变量用，如：若str为数组名，str++就不合法，相当于常量自增。再次注意：数组名是常量！常量！常量！常量就不可被赋值
      ```
      char s[10];
      char *pt, s="hello"；//将常量赋给s，实质就是将常量首地址赋值给s；
      s=pt; // 错误的，s是数组名不可被赋值，任何形式的赋值都不可以。
      ```
   * 同时，一维数组名当被直接使用时，是一个指向数组首地址的指针。  
   * 数组名表示首地址，那么数组名前有取地址符是什么意思？
      例如：数组a[]，a表示数组首元素地址，&a表示数组整体地址，&a+1就是该数组末尾后一个地址

### 数组指针、指针数组、函数指针

* 数组指针：`int (*p)[n];`  
   其中()优先级高，首先说明p是一个指针，指向一个整型的一维数组（或二维数组的某一行）
* 指针数组: `int *p[n];`  
   * 其中[]优先级高，先与p结合成为一个数组，再由`int*`说明这是一个整型指针数组，它有n个指针类型的数组元素。
   * `int *p=new int(12)与int *p=new int[12]`的区别  
      前者表示创建一个指针变量; 其指向一个存储数字12的地址; 后者表示创建一个长度为12的数组。
* 函数指针: `int (*pf)(int *)`  
   为一个返回值为int，参数为`int*`的函数指针;

### 引用和指针的区别

* `内存`   
引用只是个符号，不占用空间; 指针则要分配空间;
```
占内存大小:
sizeof(引用) = sizeof(原变量);
sizeof(指针) = 4 (32位机器上)
 ```
* `初始化`  
指针可以为空，但是引用不可以为空;

* `使用`  
引用在定义的时候就要初始化, 而且初始化之后就不许修改了，指针则可以随时改变指向;


### 野指针

* `产生`
  * `声明`  
  指针的时候, 没有初始化为NULL, 这样的话这个指针指向什么地方都是不确定的
  * `释放`  
  动态申请的内存时, 只delete或free了, delete只是表示程序释放  
  delete 释放空间，只是做个标志，表示p所在的内存空间可以被其他进程使用了  
  没释放之前，使用权是当前进程的；而且还需把指针p赋为NULL
* `危害`
指向不可访问地址
破坏正在使用的地址空间
* `防范`  
定义指针的时候就进行初始化    
释放的时候要把指针指向NULL


## 柔性数组

* 在结构体末尾声明0长数组  
对于编译器来说，此时长度为0的数组并不占用空间，因为数组名本身不占空间，它只是一个偏移量;  
这个符号本身代表了一个不可修改的地址常量 （注意：数组名永远都不会是指针！ ）; 但对于这个数组的大小，我们可以进行动态分配
   ```
   typedef struct FlexiableStruct
   {
       int a;
       char array[0]; //或char array[]; // 定义0长数组,只是把一个符号放在结构体内, 不占用内存
   }stFlexiable, *pstFlexiable;
   pstFlexiable p_stFlexiable = (pstFlexiable)malloc(sizeof(stFlexiable) + strlen(szStr) + 1); // 给柔性数组申请空间
   ```

* 动态申请的内存只是申请给数组拓展所用，结构体的大小在创建时已经确定了 array明确来说不算是结构体成员，只是挂羊头卖狗肉而已  
   这样的变长数组常用于网络通信中构造不定长数据包，不会浪费空间浪费网络流量

## 进程

### fork
* 写时复制(copy-on-write):
   * fork()进程如果没有调用exec的话, 其代码空间和父进程是一样的
   * 只有在fork之后exec之前两个进程用的是相同的物理空间（内存区）
      子进程的代码段、数据段、堆栈都是指向父进程的物理空间，也就是说
      两者的虚拟空间不同，但其对应的物理空间是同一个。当父子进程中有
      更改相应段的行为发生时，再为子进程相应的段分配物理空间
   * 资源的复制只有在写入的时候才进行
     > 例: 进程A malloc()了一块内存，并将string s，存入该空间，fork出子进程B,B是否可以访问该内存，可以对内存的变量修改吗？
       不能，虽然是在堆上分配的，子进程还是会自己重新复制一份自己的空间，在自己的空间上操作
* fork之后的资源?


### 僵尸进程、孤儿进程

* 僵尸进程
   * 什么是僵尸进程  
      父进程还在运行, 而子进程挂了, 但父进程没有使用wait来清理子进程的进程信息  
      导致子进程虽然运行实体已消失, 但是仍在内核进程表中占有数据, 造成资源浪费
   * 有哪些危害  
      子进程号会一直被占用,系统所能使用的进程号是有限的,如果产生大量的僵尸进程,最终可能导致系统没有可用的进程号,从而不能产生新的进程  
   * 解决方法
      * 杀死其所属父进程, 使其孤儿进程
        ```
         wait
            主进程阻塞, 随便一个子进程结束就停止阻塞
         waitpid
            非阻塞, 但需要用轮询的方式监控子进程
         signal
            其实是子进程退出时会给父进程一个信号, signal里用wait或waitpid都是非阻塞的
         只要父进程还在就都会监测子进程信号, 可以把所有子进程都回收
        ```
      * `kill -s SIGCHLD pid`  
         将这里的 pid 替换成父进程的进程 id, 这样父进程就会删除所有已经死掉的子进程了

* `孤儿进程`  
  子进程还在运行, 而父进程挂了, 子进程变为孤儿进程, 将由init进程收养
* `wait 和 waitpid的区别`
  * 从本质上讲，系统调用waitpid和wait的作用是完全相同的，但waitpid多出了两个可由用户控制的参数pid和options
   从而为我们编程提供了另一种更灵活的方式
    ```
    sub_pid = waitpid(-1, &stat, WNOHANG);
    >0    只等待进程ID等于指定进程号的子进程，不管其它已经有多少子进程运行结束退出了，只要指定的子进程还没有结束 waitpid就会一直等下去。
    =-1   等待任何一个子进程退出，没有任何限制，此时waitpid和wait的作用一模一样。 　　
    =0    等待同一个进程组中的任何子进程，如果子进程已经加入了别的进程组，waitpid不会对它做任何理睬。
    <-1   等待一个指定进程组中的任何子进程，这个进程组的ID等于pid的绝对值
    ```


### 守护进程

* 运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件
  * 守护进程最重要的特性是[后台运行]  
  * 守护进程必须与其运行前的环境[隔离]开来  
    这些环境包括未关闭的文件描述符，控制终端，会话和进程组，工作目录以及文件创建掩码等; 这些环境通常是守护进程从执行它的父进程（特别是shell）中继承下来的  
     进程组
        就是多个进程，进程组由进程组ID标识，进程组ID 也是一个进程的必备属性，每个进程组都有一个组长进程,
        组长进程的ID等于进程组的ID，进程ID不会因为组长进程的退出而受到影响  
     会话组
        是多个进程组组成的，一个会话开始于用户登录，终止于用户退出，在此期间用户运行的所有进程都属于这个会话期，

   * 除开这些特殊性以外，守护进程与普通进程基本上没有什么区别  
      编写守护进程实际上是把一个普通进程按照上述的守护进程的特性改造成为守护进程
* 步骤
```
　1. [脱离终端]
　　　创建子进程，父进程退出
　　　所有工作在子进程中进行
　　　形式上脱离了控制终端
　2. 在子进程中[创建新会话]
　　　setsid()函数
　　　使子进程完全独立出来，脱离控制
　3. [改变当前目录]为根目录
　　　chdir()函数
　　　防止占用可卸载的文件系统
　　　也可以换成其它路径
　4. 重设[文件权限掩码]
　　　umask()函数
　　　防止继承的文件创建屏蔽字拒绝某些权限
　　　增加守护进程灵活性
　5. [关闭文件描述符]
　　　继承的打开文件不会用到，浪费系统资源，无法卸载
```

### 进程间通信

> 管道(FIFO)、信号、共享内存、消息队列、信号量、套接字; IPC好像都是通过一个ID来让进程间通讯

* 无名管道
  * 其实就是依靠fork函数, 利用fork来和父进程公用一个管道
  * 参数 filedis 返回两个文件描述符：filedes[0] 为读而打开
    ```
    int pipe(int filedis[2]) // 1. 创建无名管道(fork之前)
    close(file_descriptors[INPUT]); // 2. 关闭管道的读端
    write(file_descriptors[OUTPUT], "test data", strlen("test data") + 1); // 写入数据
    close(file_descriptors[OUTPUT]); // 关闭管道的写端
    read(file_descriptors[INPUT], buf, sizeof(buf)); // 读取数据
    ```

* 有名管道
  * 可以认为是通过文件来进行进程间通信, 写入读出的对象都是一个文件
  * 管道都有同步和阻塞的问题, 读写有等待的情况; 而且当读写的数据大于最大长度时会阻塞等待
    ```
    mkfifo(PIPENAME, 0666);    // 1. 创建管道
    open(PIPENAME, O_WRONLY);  // 2. 打开管道
    write(fd, &i, sizeof(i));  // 3. 写数据
    close(fd);                 // 4. 关闭管道
    ```

* 消息队列
   * 和有名管道一样, 发送的数据都有一个最大长度限制
   * 生命周期随内核，消息队列会一直存在，需要我们显式的调用接口或使用命令删除
   * 消息队列可以双向通信
   * 克服了管道只能承载无格式字节流的缺点
     ```
     #include<sys/msg.h>
     key_t key = ftok("./", 88);                  // 1. ftok 产生key
     int msgget(key_t key,int msgflg);            // 2. 建立消息队列
     int msgsnd(int msgid,void *msg_ptr,size_t msg_sz,int msgflag);
                                                  // 3.1 发送消息 0 阻塞 IPC_NOWAIT 非阻塞
     int msgrcv(int msgid,void *msg_ptr,size_t msg_sz,long int msg_type,int msgflag);
                                                  // 3.2.  接收消息类型为msgtype的消息
     int msgctl(int magid,int cmd,struct msgid_ds *buf);
                                                  // 4. 控制消息队列(也i可以删除)
     ```
   // TODO

* 共享内存
   * 因为系统内核没有对访问共享内存进行同步，您必须提供自己的同步措施, 比如用信号量进行同步
     ```
     #include<sys/shm.h>
     key_t key = ftok("./", 88);                                 // 1. ftok 产生key
     int shmget(key_t key,size_t size,int shmflag);              // 2. 产生信号量ID
     void *shmat(int shm_id,const void *shm_addr,int shm_flag);  // 3. 映射共享内存地址
     int shmctl(int shm_id,int cmd,struct shmid_ds *buf);        // 4. 控制共享内存(也可以删除)
     int shmdt(const void *shm_addr);                            // 5. 解除映射
     ```

* 信号量 Pv   
   解决进程间同步与互斥问题的一种进程间通讯机制
   ```
   #include<sys/sem.h>
   key_t key = ftok("./", 88);                                 // 1. ftok 产生key
   int semget(key_t key,int num_sems,int sem_flgs);            // 2. 产生信号量ID
   int semctl(int sem_id,int sem_num,int command...);          // 3. 控制信号量(也可以删除)
   int semop(int sem_id,struct sembuf *sem_ops,size_t num_sem_ops); // 解锁或锁定共享资源
   ```
   // TODO

* 基于套接字通信  
   所有的方法都是基于套接字通信的, 所以都有个套接字的入参
  * 服务器
    * 创建socket套接字
      ```
      int fd = socket(AF_INET, SOCK_STREAM, 0);
      AF_INET 表示使用TCP/IP协议族; SOCK_STREAM 表示使用TCP协议, SOCK_DGRAM 表示使用UDP协议;
      ```
     * bind绑定地址和端口
     * 设置套接字为listen状态,等待客户端链接
     * accept接收到客户端连接进来, 创建新套接字与该客户端进行通信
     * 进行读recv写send通信
        ```
        int write(int fd, void *buf, size_t nbytes);
        int send (int sockfd, void *buf, int len, int flags)
        ```
        在功能上，read/write是recv/send的子集。read/wirte是更通用的文件描述符操作，而recv/send在socket领域则更“专业”一些
        有多一个参数用来进行socket控制
        如: 为接收和发送进行一些选项设置;从多个客户端中接收报文等
     * 关闭套接字
       ```
       close(fd);
       ```
  * 客户端
    * 创建socket套接字
    * connect与服务器进行链接(三次握手)
    * 与服务器进行收recv发send通信
    * 关闭套接字


## 线程

### 线程和进程的区别

* 进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发；
* 线程是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发；
* 一个程序至少有一个进程，一个进程至少有一个线程，线程依赖于进程而存在;
* 进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。


### 线程同步

* `mutex`  
  * lock_guard:类模板, 构造函数进行加锁, 析构函数进行解锁. 可以自己用大括号来限定作用域
  * unique_lock: 比lock_gurad灵活在会记住锁的状态,
* condition_variable + unique_lock + notify_once + wait
* future、promise、async、atomic

### 线程有哪些状态
TODO
https://www.cnblogs.com/domi22/p/8046851.html
* 就绪：参与调度，等待被执行，一旦被调度选中，立即开始执行
* 运行：占用CPU，正在运行中
* 休眠：暂不参与调度，等待特定事件发生
* 中止：已经运行完毕，等待回收线程资源
　　
### 协程
TODO


### 死锁
```
1. 产生原因
   陷入互相等待的状态
   A线程锁住了mutex1, 在想用mutex2锁住的变量时尝试锁mutex2, 发现mutex2被锁了, 等待mutex2释放
   B线程锁住了mutex2, 在想用mutex1锁住的变量时尝试锁mutex1, 发现mutex1被锁了, 等待mutex1释放
   原因是A、B线程锁互斥量的顺序不一致, 解锁顺序倒是不影响
2. 解决：
   1) std:lock() 函数模板
      std:lock(mutex1, mutex 2)
      解锁还是要手工unlock()，解锁顺序不影响
      可以一次锁住>=2个互斥量，不存在因锁的顺序问题而导致死锁的存在，会等所有都锁住才继续往下走
      原理:
      如果有一个互斥量没锁成功，则会释放掉已锁成功的互斥量，过段时间再去尝试，直到把所有互斥量都锁住为止
      缺点:
      lock()解决死锁的痛点在于存在忘记unlock的危险，而lock_guard刚好可以自动unlock，可否两者优点都有呢？
   2) lock() 和 lock_guard
      使用lock_guard的adopt_lock参数可以做到，让lock_guard构造的时候不lock, 但是必需在lock_guard之前加锁
      std:lock（mutex1,mutex2)
      lock_guard<mutex>lock_guard(mutex1, adopt_lock)
   3) atomic 原子操作
      类模板atomic声明的对象确保了该操作是原子性的, 不需要加锁
      std::atomic<int> g_atomic_counter(0); // atomic是一个类模板
      g_atomic_counter++;
```

## 结构与联合的区别

* 结构和联合都是由多个不同的数据类型成员组成;  
   但在任何同一时刻, 联合中只存放了一个被选中的成员（所有成员共用一块地址空间）, 而结构的所有成员都存在（不同成员的存放地址不同）。
* 对于联合的不同成员赋值, 将会对其它成员重写, 原来成员的值就不存在了, 而对于结构的不同成员赋值是互不影响的。

## 结构体和类的区别

> 最本质的一个区别就是访问权限和继承权限不同
```
1. C++中的struct对C中的struct进行了扩充，它已经不再只是一个包含不同数据类型的数据结构了，它已经获取了太多的功能：
   ① struct能包含成员函数吗？ 能
   ② struct能继承吗？ 能
   ③ struct能实现多态吗？ 能
2. 既然这些它都能实现，那它和class还能有什么区别？
   ①若不指明，struct成员的默认属性是public的，class成员的默认属性是private的；
   ②若不指明，struct成员的默认继承权限是public的，class成员的默认继承权限是private的；
```

## 结构体对齐

* 结构体大小计算

* 类的大小计算
```
   类的存储大小sizeof运算也可以当做结构体来计算;
   注意函数声明不占内存; 静态成员分配在全局区, 也不计入类大小;
   空类会有一个字节做标记; 有虚函数的类, 会包含一个虚函数指针的大小;
   如果父类有虚函数, 子类也有虚函数, 则子类大小 = 基类大小 + 子类大小 + 一个虚函数指针
   要注意继承问题：比如派生类继承基类，那么： 派生类大小=基类成员（不包括静态成员）+自己本身
```

## 类型转换 C++中的四种类型转换方式

> 常见的(type)类型转换是C语言中的类型转换方式，其有很多缺陷如：容易产生两个不和互相转换的类型被转换，从而引发错误等等  
> 有的时候用c风格的转换是不合适的，因为它可以在任意类型之间转换;  
> 比如你可以把一个指向const对象的指针转换成指向非const对象的指针;  
  把一个指向基类对象的指针转换成指向一个派生类对象的指针，这两种转换之间的差别是巨大的;
  但是传统的c语言风格的类型转换没有区分这些

* `static_cast`  
   最常用的类型转换符，正常状况下的类型转换，如把int转换为float;
   如：int i；float f；f=(float) i; 或者用C++类型转换模式：f=static_cast<float>(i)；

* `const_cast`  
   用于取出const属性，把const类型的指针变为非const类型的指针; 只能作用于引用或指针;
   如：`const int *fun(int x,int y){}; int *ptr=const_cast<int *>(fun(2,3))；`

* `dynamic_cast`  
   通常在它被用于安全地沿着类的继承关系向下进行类型转换，但是被转换类必须是多态的，即必须含有虚函数;
   如：`dynamic_cast<T*> (new C);`其中类C必须含有虚函数，否则转换就是错误的；

* `reinterpret_cast`  
   interpret是解释的意思，reinterpret即为重新解释，可以把一个指针转换成一个整数，也可以把一个整数转换成一个指针
   如：`int i; char *ptr="hello freind!"; i=reinterpret_cast<int>(ptr);`

## 大小端

> (高位) 0x12345678 (地位)  
> [低地址]: 12 34 56 78 (大端)  
> [低地址]: 78 56 34 12 (小端)  

* 大端  
   指数据的高字节保存在内存的低地址中，而数据的[低字节]保存在内存的[高地址]中
* 小端  
   指数据的高字节保存在内存的高地址中，而数据的[低字节]保存在内存的[低地址]中
* 利用union判断是大端还是小端
```
 由于union只存储一个成员，若一个union有一个int变量和一个char变量，那么若前一个int变量被赋值后 此时union存储的就是该int变量
 若此时读取char变量，由于char并没有被重写，所以读取的还是int变量的前8位
 根据读取的的8位字节判断是否=int的值, 如果相等，则证明int的值保存在低地址
            15       0        0        0
 [低地址->] 00001111 00000000 00000000 00000000[高地址] // 如果前8位=int的值, 则为小端
            0        0        0        15
 [高地址->] 00000000 00000000 00000000 00001111[低地址] // 如果后8位=int的值, 则为大端
bool IsLittleEndian()
{
    union
    {
      int a;
      char b;
    } u;

    int k = 15; //要在char范围内
    u.a = k;
    if ((int)u.b == k)
    {
        printf("小端\n");
        return true;
    }
    else
    {
        printf("大端\n");
        return false;
    }
}
```


## 哈希

* 原理 
  * 哈希表（也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。
  * 它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度; 这个映射函数叫做散列函数，存放记录的数组叫做散列表。 `string --> key = hash(string)`

* 解决冲突的方法
   ```
   不同的内容经过同一个散列函数后得到的key值可能是相同的, 这样叫发生冲突(碰撞)
   缓冲区:
      把有冲突的数据都放到缓冲区, 如果在哈希表查不到就去缓冲区找
   二次探测法:
      如果发现数组下标为hash(string)中已有值了, 就往右找(或者同时往左找)第一个没值的位置存放
   再次哈希法:
      这种方法是同时构造多个不同的哈希函数： Hi=RH1（key）  i=1，2，…，k
      当哈希地址Hi=RH1（key）发生冲突时，再计算Hi=RH2（key）……，直到冲突不再产生。这种方法不易产生聚集，但增加了计算时间。
   拉链法
      数组的特点: 查找容易, 插入删除困难
      链表特点:   查找困难, 插入删除容易
      对于相同的key = hash(string)值的数据, 则以key为链表头结点, 往后拉出一条链表, 所有key相同的数据都插入到链表中
   ```

* 哈希表的应用
```
安全领域
   如md5、sha1等消息摘要算法, 用来判断文件完整
查找
   拿到string的key值后, 就能知道该string存储在哪了
词频问题
top-k问题
查找问题
```


## map
   unorder_map和map, 前者是通过哈希表来实现的, 后者则是通过红黑树(默认就是有序的)

## Linux信号 
TODO


# 计算机网络和网络安全


## 分层模型

* 各层的作用
  ```
  应用层: 用户与网络间的接口    http
  运输层: 进程到进程间的接口    tcp/udp
  网络层: 主机到主机间的接口    ip
  数据链路层: 相邻结点间的接口  mac、以太网
  物理层: 物理介质间的接口
  ```
* 分层模型
```
OSI
应用层 -> 表示层 -> 会话层 -> 运输层 -> 网络层 -> 数据链路层 -> 物理层
TCP/IP
应用层 -> 运输层 -> 网际层 -> 网络接口层
```
* socket套接字接口就是七层模型中应用层以下封装的一个系统调用


## ARP
```
0. ARP是地址转换协议（Address Resolution Protocol）的英文缩写，它是一个链路层协议，工作在 OSI 模型的第二层
1：首先，每个主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址之间的对应关系。
2：当源主机要发送数据时，首先[检查ARP缓冲列表]中是否有对应IP地址的目的主机的MAC地址，如果有，则直接发送数据;
   如果没有，就向本网段(**局域网**)的所有主机[发送ARP数据包]，包括的内容有：源主机IP地址，源主机MAC地址，目的主机的IP地址。
3：当本网络的所有主机收到该ARP数据包时，首先检查数据包中的目的IP地址是否是自己的IP地址，如果不是，则忽略该数据包;
   如果是，则[更新自身Arp缓存]首先从数据包中取出源主机的IP和MAC地址写入到ARP列表中;
   如果已经存在，则覆盖，然后将自己的[MAC地址写入ARP响应包]中，告诉源主机自己是它想要找的MAC地址。
4：源主机收到ARP响应包后, [更新自身arp缓冲]将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据;
   如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。

0. A表示 IP地址, 电话号码表示Mac地址
1. 在公园里, A 想打电话给 B, 翻看通讯录[检查arp缓存]没发现B的号码; (如果有就直接打电话过去了)
2. 于是A在公园大喊一声[arp请求(广播)]:我是A,我号码是123, B你的电话号码是什么
3. 公园里其他人看到问的是B, 就没管它;
   B看到有人问自己号码, 于是就把对方存到通讯录[更新arp缓存], 然后打电话告诉对方:我就是B[arp响应(单播)]
4. A看到接到电话说他就是B, 于是就记录到自己通讯录中, 下次想找B直接从通讯录打电话过去
```

## Arp欺骗

* 有两个问题  
A不管谁打电话来说他是B, 他都认为是真的 B 打过来的  
B也不管谁说A的号码是什么, 他都认为这就是真的 A 的号码

* 假设有一个不规矩的C,电话号码是234  
  * A在公园喊：我是A, 我号码是123,  B你的电话是多少?  
   `单向欺骗` 这时候C就打电话给A, 说我就是B, 然后A就把234保存为B的号码, 这样以后A要联系B都会去通讯录找
   所以C就完全知道A想告诉B的内容了
  * `双向欺骗` C再可以假冒A, A虽然在公园喊谁是B的时候, C也在喊:我是A, 我的号码是234, B你的电话是多少?  
   这时候B会把234当作A的电话号码记到通讯录,.  
   之后, A要跟B交流会打234这个号码, C看到A发给B的内容后, 转手发给B, B看到是234发过来的, 就认为是A的内容, 然后继续通信下去...


## TCP/UDP的区别

* 用户数据包协议
UDP是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部）。
* 传输控制协议
TCP是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流  
把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块
* TCP通过确认机制，丢包可以重发，保证数据的正确性;
UDP不保证正确性，只是单纯的负责发送数据包；
* UDP是面向报文的。发送方的 UDP 对应用程序交下来的报文，在添加首部后就向下交付给 IP 层
  * 既不拆分，也不合并，而是保留这些报文的边界，因此，应用程序需要选择合适的报文大小；
* UDP的头部，只有 8 个字节，相对于TCP头部的 20 个字节信息包的额外开销很小。

* 连接性  
TCP是面向连接(Connection oriented)的协议，UDP是无连接(Connection less)协议
* 可靠性   
TCP可靠，UDP不可靠；TCP丢包会自动重传，UDP不会。
* 有序性  
TCP有序，UDP无序；消息在传输过程中可能会乱序，后发送的消息可能会先到达，TCP会对其进行重排序，UDP不会进行重排序。
* 有界性  
TCP无界，UDP有界； TCP通过字节流传输，UDP中每一个包都是单独的。
* 拥塞控制  
TCP有流量控制（拥塞控制），UDP没有；TCP主要靠三次握手实现以及慢开始、拥塞避免、快重传、快恢复。
* 传输速度  
TCP传输慢，UDP传输快； 因为TCP需要建立连接、保证可靠性和有序性，所以比较耗时。这就是为什么视频流、广播电视、在线多媒体游戏等选择使用UDP。
* 量级  
TCP是重量级的，UDP是轻量级的；TCP要建立连接、保证可靠性和有序性，就会传输更多的信息，如TCP的包头比较大。
* 头部大小  
TCP包头比较大。
* 应用场合  
TCP一般应用在对可靠性要求比较高的场合，例如http，ftp等等。而UDP一般应用在对实时性要求较高场合，例如视频直播，大文件传输等等。

## 三次握手

> 目的是为了保证双方都能正常收发数据
> ![](http://blog.chinaunix.net/attachment/201304/8/22312037_1365405910EROI.png)

* 第一次握手：建立连接时,客户端发送syn包(syn=j)到服务器,并进入SYN_SEND状态,等待服务器确认;
   SYN：同步序列编号(Synchronize Sequence Numbers)
* 第二次握手：服务器收到syn包,必须确认客户的SYN（ack=j+1）,同时自己也发送一个SYN包（syn=k);
   即SYN+ACK包,此时服务器进入SYN_RECV状态；
* 第三次握手：客户端收到服务器的SYN＋ACK包,向服务器发送确认包ACK(ack=k+1);
   此包发送完毕,客户端和服务器进入ESTABLISHED状态,完成三次握手.
* 三次握手失败, S主动关闭   
当client与server的第三次握手失败了之后，即client发送至server的确认建立连接报文段未能到达server，server在等待client回复ACK的过程中超时了，那么`server会向client发送一个RST报文段并进入关闭状态`，即：并不等待client第三次握手的ACK包重传，直接关闭连接请求，这主要是为了防止泛洪攻击，即坏人伪造许多IP向server发送连接请求，从而将server的未连接队列塞满，浪费server的资源。
* 解释
```
        你能听到我说话吗?
A ---------------------------> B (A发完SYN进入SYN_SEND状态)
             SYN

       听到了,你能听到我吗?
A <--------------------------- B (B发完ACK和SYN两个包后, 进入SYN_RECV状态) // 半连接
           SYN,ACK

            我听到了
A ---------------------------> B (A发完ACK, A,B都进入ESTABLISHED状态) // 全连接
             ACK
```
 
## 全连接、半连接

* Linux内核协议栈为一个tcp连接管理两个队列，一个是半链接队列（用来保存处于SYN_SENT和SYN_RECV状态的请求），一个是全连接队列（accpetd队列）（用来保存处于established状态，但是应用层尚未调用accept取走的请求）
* 完成三次握手的链接被放到到全连接队列, 只完成了两次握手的队列放在半链接队列


## SYN攻击
拒绝服务(DDOS)攻击

* 在三次握手过程中，服务器发送SYN、ACK后,收到客户端的ACK之前的TCP连接称为半连接(half-open connect).此时服务器处于Syn_RECV状态.当收到ACK后，服务器转入ESTABLISHED状态.

* Syn攻击  
  * 伪冒客户端, 在短时间内伪造大量不存在的IP地址, 不断先服务器发SYN包, 服务器回复确认包并等待客户端的确认包(前两次握手的过程)  
但是由于这些IP是伪造的,不会回复ACK包, 服务器会不断重发直到超时, 这些为找的SYN包会长时间占用`半连接队列`, 导致正常的SYN请求被丢弃.  
导致服务器响应缓慢, 严重者导致网络堵塞甚至系统瘫痪
  * 每收到一个SYN包, 就需要为该请求分配一个TCB（Transmission Control Block）, 通常一个TCB至少需要280个字节，在某些操作系统中TCB甚至需要1300个字节，并返回一个SYN ACK命令, 立即转为SYN-RECEIVED即半开连接状态
  * Syn攻击是一个典型的DDOS攻击。检测SYN攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击

* 防范措施   
  * 监测是否被攻击  
  `netstat -n -p TCP | grep SYN_RECV`
  * `SynCache技术`
    这种技术是在收到SYN数据报文时不急于去分配TCB, 而是先回应一个SYN ACK报文, 并在一个专用HASH表（Cache）中保存这种半开连接信息，直到收到正确的回应ACK报文再分配TCB; 在FreeBSD系统中这种Cache每个半开连接只需使用160字节，远小于TCB所需的736个字节
    旧逻辑: 收到syn就分配TCB保存到半连接队列中
    现逻辑: 收到syn先计算一个哈希值, 把哈希值保存到半连接队列, 等收到ack后再实际分配TCB, 并转入全连接队列
    缺陷: 需要保存连接的序列号信息
  * `SynCookie技术`
    * 完成三次握手前不分配资源。
     原理是，在TCP服务器接收到TCP SYN包并返回TCP SYN + ACK包时, 不分配一个专门的数据区，而是根据这个SYN包计算出一个cookie值
     这个cookie作为将要返回的SYN ACK包的初始序列号。当客户端返回一个ACK包时，根据包头信息重新计算cookie，与返回的确认序列号(初始序列号 + 1)进行对比
     如果相同，则是一个正常连接，然后，分配资源，建立连接。
    * 它使用一种特殊的算法生成SequenceNumber, 这种算法考虑到了对方的IP、端口、己方IP、端口的固定信息, 以及对方无法知道而己方比较固定的一些信息,
      如MSS、时间等; 在收到对方的ACK报文后，重新计算一遍，看其是否与对方回应报文中的（SequenceNumber-1）相同，从而决定是否分配TCB资源。
  * `SYN proxy代理`  
    作为server与client连接的代理，代替server与client建立三次握手的连接，同时SYN proxy与client建立好了三次握手连接之后，确保是正常的TCP连接，而不是TCP泛洪攻击，那么SYN proxy就与server建立三次握手连接，来连通client与server
  * 增大最大半连接队列
  * 网关超时设置
    防火墙设置SYN转发超时参数, 该参数远小于服务器的timeout时间. 当客户端发送完SYN包，服务端发送确认包后（SYN＋ACK）
    防火墙如果在计数器到期时还未收到客户端的确认包(ACK)，则往服务器发送RST包，以使服务器从队列中删去该半连接。
    网关超时参数设置不宜过小也不宜过大，超时参数设置过小会影响正常的通讯，设置太大，又会影响防范SYN攻击的效果


## 只有两次握手行不行?
* 试想一下, C第一次发送SYN1请求连接, 但是在网络某节点滞留了, 然后C超时重传SYN2, 然后这一次一切正常, C跟S可以正常进行数据传输;  
等到连接释放了以后, 那个SYN1请求突然到了Service那, 如果是两次握手的话, Service发送确认ACK2, 它们就算是建立起了连接了;  
事实上C并不会理会这个ACK2确认, 因为我压根没有要传数据啊. 但是S却傻傻地以为有数据要来, 苦苦等待. 结果就是造成资源的浪费.
  ```
  C: 喂, 你听到了吗?
  C: 喂, 你听到了吗?(...那么久还没回应, 我再喊一次)
  S: 我听到了
  ......(交流)
  C: 喂, 你听到了吗?
  S: 我听到了 (???什么鬼?, 刚交流完, 又来?)
  C: ??? 我没又要跟你聊天啊, 不管了
  S: ??? 我都听到了, 怎么C还没说话?

  ```
  

* 假定C链接S, 并完成了前面两次握手(即S发了syn+ack包给C); 此时S认为连接已经成功地建立了, 可以开始发送数据分组;
  但是如果syn+ack包丢失了, C不知道S是否准备好, C一直在等待S的ack报, 将忽略一切S发过来的任何数据报文, 而S发报文没收到C的回应, S就会一致超时重发
  ```
  C : 喂, 你听到了吗?
  S : 我听到了<由于网络原因, 这句话没有成功发给C>
  S ：xxxxx(收了一大堆话)
  S : xxxxxxx(怎么没回应? 我重说一遍)
  C : ...(奇怪了, 怎么那么久还没回应, 也不知道他听到没有)
  ```

## 长连接、短链接

* 长连接  
就是客户端发送连接请求，连接成功后就一直保持连接，直到客户端和服务端断开连接
* 短连接  
就是客户端和服务端连接, 传输完数据之后，服务端再自动断开连接


## 四次挥手

> 目的是确保双方都把消息发送完了

https://zhidao.baidu.com/question/518425014.html

```
[主动方]                                  [被动方]
                        FIN1报文
FIN_WAIT1状态  C --------------------------> S  CLOSE_WAIT状态
                  我给你的消息发送完了, 你收到了吗?

                           ACK
FIN_WAIT2状态  C <-------------------------- S
                          收到了

                           FIN2
               C <-------------------------- S LAST_ACK状态
                  我给你的也发送完了, 你收到了吗?

                           ACK
TIME_WAIT状态  C --------------------------> S CLOSED状态
                          收到了
CLOSED状态
```

## 为什么握手三次, 而挥手要四次？
* 在建立连接的时候,Server把响应客户端的请求和请求客户端的确认放在一起发送给客户端了,即第二次握手时有SYN+ACK
* 而 断开连接的时候,一个方向的断开,只是说明该方向数据已传输完毕 ,而另一个方向或许还有数据要发给对方,所以得等到另一个方向数据也全部传输完成后,才能执行第三次挥手

## `Time_wait`为什么要等待`2MSL`

> 四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假设网络是不可靠的，最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。

* Time_wait状态存在于client收到server Fin并返回ack包时的状态 ，当处于time_wait状态时，我们无法创建新的连接，由于port被占用。
* 当TCP连接断开时候，执行主动关闭那一端会进入TIME_WAIT状态，等待2msl（每个分节最长生命期）
* TIME_WAIT状态有两种存在的理由：
  * 一个数据报在发送途中或者响应过程中有可能成为残余的数据报，因此必须等待足够长的时间避免新的连接会收到先前连接的残余数据报.
  * 确保被动关闭方已正常关闭


## GET请求和POST请求的区别

* GET
  * 当客户端要从服务端读取数据时用GET，使用GET方法时，请求参数和对应的值 附加在URL后面
  * 利用问号?代表URL的结尾和请求参数的开始，传递参数长度受限制，例：/index.jsp?id=100&op=bind
* POST
  * 是向服务器提交数据，POST方法请求参数封装在HTTP请求数据中，可以传输大量数据，可用来传送文件。
* Get和Post请求的区别：
  * Get是向服务器索取数据的一种请求，而Post是向服务器提交数据的一种请求
  * [参数传递方式]Get请求的参数会跟在url后进行传递, POST请求的数据会放置在请求头内提交
  * [大小限制] Get对传输的数据有大小限制, POST没有
  * [安全性]Post比Get安全

## 浏览器输入地址后发生了什么

* 客户端[应用层]浏览器通过DNS解析到www.baidu.com的IP地址220.181.27.48，通过这个IP地址找到客户端到服务器的路径;
   客户端浏览器发起一个HTTP会话到220.161.27.48，然后通过TCP进行封装数据包，输入到网络层。
* 在客户端的[传输层]，把HTTP会话请求分成报文段，添加源和目的端口，如服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000，与服务器进行交换，服务器把相应的请求返回给客户端的5000端口。然后使用IP层的IP地址查找目的端。
* 客户端的[网络层]不用关心应用层或者传输层的东西，主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器，这些都是由路由器来完成的工作，无非就是通过查找路由表决定通过那个路径到达服务器。
* 客户端的[链路层]，包通过链路层发送到路由器，通过邻居协议查找给定IP地址的MAC地址，然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换的IP数据包现在就可以传输了，然后发送IP数据包到达服务器的地址。
1. [DNS]服务器(运行在应用层)把url转为ip地址
2. 浏览器发起一个http会话到这个ip地址, 进行[三次握手], 建立TCP连接, 通过TCP封装后, 进入到网络层
3. 浏览器发起HTTP的post请求, [传输数据]
4. 请求由应用层不断包装进入到数据链路层, 然后经过路由转发(拆解到网络层), 最终经过防火墙\NAT到达目的主机
5. 服务器处理该HTTP请求, 返回HTML文件
6. 浏览器解析HTML文件, 展示

## 常用端口

```
FTP      21
TELNET   23
SMTP     25
POP3     110
HTTP     80
DNS      53
```

## 滑动窗口机制

* 由发送方和接收方在三次握手阶段，[互相将自己的最大可接收的数据量告诉对方], 也就是自己的数据接收缓冲池的大小;
   这样对方可以根据已发送的数据量来计算是否可以接着发送。
* 在处理过程中，当接收缓冲池的大小发生变化时，要给对方发送更新窗口大小的通知

## 拥塞避免机制

* 拥塞  
对资源的需求超过了可用的资源。若网络中许多资源同时供应不足，网络的性能就要明显变坏，网络的吞吐量随之负荷的增大而下降。
* 拥塞控制  
防止过多的数据注入到网络中，使得网络中的路由器或链路不致过载。
* 拥塞控制方法  
   慢启动 + 拥塞避免;  
   快重传 + 快恢复。

## 慢启动

## 指数退避


## 对称加密、非对称加密 TODO

## 挑战响应认证

* 特点是`密码不在网络上传输`
   该认证机制中认证者（服务器）每次向被认证者（客户端）发送一个不同的”挑战“字串，客户端收到这个”挑战“字串后，按照双方事先协商好的方法应答;
   挑战相当于咨询，应答相当于回答。
   ```
   C ---------- 认证请求 ----------→ S
      # Client发出认证请求，进行身份认证，发送Client的id
   C <---------- 挑战 ---------- S
      # 发送Server产生的Random_s
   C ----------  响应 ----------→ S
      # 发送用提供的加密算法加密的(Random_s + id)
   C <---------- 验证结果 ----------→S
      # S用服务器保存的C的密钥加密(Random_s + id)，和C发过来的做比较，返回认证结果。
   ```

## socket

TODO

https://blog.csdn.net/xp731574722/article/details/82868560



# 数据结构

## 排序

## 链表

* 结点结构
  ```
  typedef struct ListNode
  {
     DataType info;
     struct ListNode *next;
  }ListNode, *pListNode;
  ```
* 计算节点个数
   ```
   while (llist->link != NULL)
   {
       iNum++;
       llist = llist->link;
   }
   ```

* 链表翻转
  ```
   思路：
      把头结点后面的结点一个个插入到头结点和第一个结点之间
      循环条件: while(pFirst->next != NULL) // 所有待插入结点都处理了
      指针修改按从后往前的顺序
  ```
* 输出倒数第k个结点
  ```
   思路：
      [快慢指针]
      快慢指针都从第一个结点出发, fast先走k个结点, 然后一起走，直到fast走完
      循环条件: while(fast)
      因为fast走了k之后low才开始走, 而且fast走完全程, 所有low只走了n-k（就是倒数第k个）
      其实和先计算链表结点数再走n-k是一个道理
  ```
* 输出中间结点
  ```
   思路：
      [快慢指针]
      快慢指针都从第一个结点出发, fast和low同时前进，fast一次走两步, low一次只走一步
      循环条件：while(fast->next !=  NULL)
      因为fast走的路程是low的两倍, 所以fast走完的时候low刚好是走到n/2
  ```
* 判断是否有环
  ```
   思路：
      [快慢指针]
      同上;
      循环条件：while(fast->next != NULL)
      循环退出条件是：low=fast的时候
  ```


## 二叉树

结点结构
```
typedef char DataType;
typedef struct TreeNode
{
   DataType data;
   struct TreeNode *lchild;
   struct TreeNode *rchild;
}TreeNode, *pTreeNode;
```


### 性质
   1. 非空二叉树第k层结点最多为**2^(k-1)** 个结点
   2. 高度为 K 的二叉树中，总共最多有 **2^k - 1** 个结点
   3. 非空二叉树普遍情况下,**n0 = n2 + 1**

### 完全二叉树

   只有最下面两层结点度<2,也就是：如果没有最后一层，那么它将是一个满二叉树
   最后一层结点都分布在左边
   共有n个结点，则深度为**log2(n)+1**
   深度为k的完全二叉树，至少有**2^(k-1)**,至多有**2^k-1**<so,满二叉树是完全二叉树>

### 满二叉树

   深度为k，且最多有2^k-1个结点,可以知道，其每一层节点数都是最大节点数
   深度为 k 的完全二叉树去掉第K层就变为满二叉树了
       可以看出完全二叉树和满二叉树的关系

### 扩充二叉树

   添加外层结点，把原树中度数<2的结点都补为2
   外部结点个数 N 内部结点个数 n     **N - n = 1**
   外部路径 E 内部路径 I             **E - I = 2n**

### 平衡二叉树

   其左右子树都是平衡二叉树，左右子树的高度的绝对值<=1


### 二叉树的遍历

### 二叉树还原

* 先+中
    根据终先序找到第一个根后，就可以在中序中将序列分成左右两部分,对分开后的两部分也这样分析就可以还原了
* 中+后
    方法和上面差不多，后序中最后一个元素就是根,倒数第二个就是根右边的儿子
* 先+后
   无解,只能确定父子关系而已

### 二叉树的存储

1. 数组
   如果用数组来存储的话，可以根据父子结点的位置关系来确定一颗二叉树<如果子节点为i则富结点为i/2>
   但是无论如何都得按照完全二叉树的空间来分配即:2^k-1,很明显太浪费
   . 如果将一个算式存到二叉树那么先中后序遍历得到的式子刚好就是前缀中缀后缀

2. 链式存储
   [data][llink][rlink]

有空找找二叉树的选择题看看。


### 二叉排序树

* 结点间是左小右大，子树也是二叉排序树, 结点元素是唯一的
* 插入删除都不改变树的结构
* 经过中序遍历后得到的是递增的序列(所以插入的时候，不可以在中间插入，必须遍历完,找到的位置一般都是末尾)
* 根始终大于左子树，小于右子树
* 子树也是二叉排序树

#### 删除
三种情况:
* 所删结点为叶节点
* 所删结点左/右子树空
* 所删结点左右子树都非空

### 优先队列
* 和队列一样，队尾进,队头出。不同的是优先队列中的最大/小元素总是位于对首，所以并非先进先出，而是最大/小的元素先出。

### 线索二叉树

* 为了充分利用空指针,如果有儿子，指针就指向儿子,否则，作为线索只想前驱或后继结点。

### 最优二叉树

* 哈夫曼树 `WPL`


# 项目

## 一篇英文文章，求找出出现频率最多的单词(双缓存多线程分析大文件词频)

1. 用流的方式打开文件, 读入指定大小的字节到内存中, 注意要进行截断检查
2. 词频统计, 那怎么处理非英文的字符?
   维护一个word数组, memset初始化为false, 下标在大小写字母和数字之间的ascii码为true;
   所以, word[i]为false的字符则不读入
3. 利用两个缓存, 读入数据到buff[0]后就开多线程去处理buff[0], 然后切换buff, 读入数据到buff[1].
   实现IO分离; 多线程在创建开始之前, 就计算好了开始处理的位置和处理结束的位置,所以不会发生冲突.
4. 怎么分析
   定义一个word字符数组来装单词,读入内存的数据一个个判断是否是有效的字符(用第2步的方法, 把字符作为下标,
   判断是否为true), 知道发现第一个不在word中字符(比如空格), 则word[128]中保存的就是一个有效的单词.
   然后去<char *, unsigned int>map中find, 看是否以该单词为key值的map, 有则+1(map中的key为单词, value为数目)
5. 最后把所有的子map合并在一起, 然后遍历一遍总的map就知道了

## 探针

1. 需求
   通过实时分析生产环境后台产生的业务日志, 一旦发现超时请求串就及时发送给对接系统进行处理, 减少人工干预, 保证业务办理顺畅

2. 须知
   请求串和应答串有唯一msgid值来确定对应关系

3. 技术
4. 概述
```
系统使用双缓存多线程的方式, 把指定量的日志通过fstream读入到内存中,（如果读入的数据不是行尾, 则会继续往后读, 知道是行尾为止, 一面请求串被截断);
读取完后切换缓存, 这样可以继续分析处理已读入的文件;
具体处理方法是: 开多线程把已读入到内存的数据按照行尾分割到vector中, 然后再把这个vector按照msgid为key处理到unorder_multimap中;
   Q1: 既然使用多线程处理一个文件, 那你处理过程中有没有加锁呢？
   A1: 第一步处理到vector是通过for循环来创建线程, 而且是指定了该线程需要处理的文件长度(也会做防截位处理)才开始创建;
       所以, 新线程处理的开始位置和处理大小都是确定的, 每个线程处理的位置不一样, 不会发生冲突
       但是确实是操作着同一块缓冲, 为什么就没发生多线程问题呢?
   Q2: 那你不是要处理到一个map中吗? 又开多线程, 怎么会没有多线程问题?
   A2: 如果是多个线程同时去写一个map, 那肯定是会有多线程问题的; 我的做法是: 每个线程从vector处理到map时, 都是处理到自己的那个map;
       比如1号线程解析数据到map1, 2号到map2; 这样各自线程都是解析到自己的那个map上, 不会冲突, 最后再把几个map合并到一起继续做后面的处理
   Q3:为什么不用锁呢?
   A3: 用锁可以保证最终处理到一个map上, 避免使用锁是因为在数据产生很快的情况下, 每条数据都要插入到map中, 这明显会把处理这一步拖慢;
       所以我就采用分map的方法, 最后合并实在处理线程外合并的, 不会影响处理速度.
处理完毕后扫描逻辑会去扫描unorder_multimap，找出一个key值只有一条记录的串, 然后判断如果是req串而且已经超时了, 那么就把它删除, 如果是ans串也把它删除; 如果只有req串但没超时则保留
   Q4: 既然你是一次读入n大小的内存, 那万一你的req串在内存A, ans串在内存B呢? 怎么处理?
   A4: 如果是这样, 如果扫描发现这个req串没有超时, 则保留在map中, 如果已超时则删除, 因为已超时了, 没必要去等ans串了
对于扫描发现超时的请求会异步发送给webservice, 并查看返回结果, 看是否发送成功, 如果没发送成功则继续发送, 发送成功则获取返回的json串做展示
   Q5: **异步发送?**
   A5: 因为扫描的时候发送webservice不可能阻塞在那里等它返回结果再扫描下一条, 所以这里是用c++11的future、promise来异步发送数据, 并开了一个监视线程来轮询监视future的结果;
      这样就可以保证接收端一有结果返回，本程序就能知道, 并作出相应的动作, 因为future对象是放在一个vector中, 所以对于因客观原因比如断网没有发送成功的记录会继续发送, 知道发送成功为止, 发送成功则从vector中删除记录.
   Q6: 为什么不直接用getline()来获取?
   A6：我的实现中是读入内存,然后按照\n分割到vec, 然后遍历vec映射到map中, 前面那两步明显可以用getline来直接从文件中获取一行数据啊
   Q7: 你的这个系统在分布式架构中适用吗？
   A7：不适用, 这个系统须放在服务器上, 如果是分布式架构, 每台服务器都要部署一个这样的程序, 程序后续的更新维护很不方便;
       (而且有的请求的请求串在服务器1, 应答串在服务器2上,金正的框架实际上不会这样)
       更好的做法是用 C/S架构, customer的职责是实时获取log日志的最新行, 并通过socket发送给service, 把这么一个customer程序部署到所有服务器中;
       这样所有的日志最终都是在service端做分析处理, 解决了req串在服务器A, ans串在服务器B的问题
```

## dbf提交到oracle的工具

1. 需求
   把dbf文件插入到数据库中, dbf文件很大(有一两g), 记录数有两千多万

2. 技术方案
  ```
   使用[mmap]把dbf文件读到内存中, 提高处理效率
   dbfread 知道了dbf的二进制格式,就可以根据格式来进行解包了, 先把文件头去掉, 然后根据长度使用memcpy来进行内存拷贝
   Q1: mmap提高处理效率? 那你说说你对mmap的理解TODO
   A1: xxxxxxxxxxxxxxxxxx
   Q2: 说说系统调用和库函数的区别
   A2: xxxxxxxxxxxxxxxxxx
  ```

## 中登账户数据核对

* [参考方案](https://mp.weixin.qq.com/s?__biz=MzI4NDMyNzA4NQ==&idx=1&mid=2247483816&sn=9c60561b82c016ed8be741260bc5b157)

1. 需求
  ```
   DBF文件中保存着客户的信息资料, 需要用该信息和系统内数据表的客户信息做比对，找出系统内数据库数据和文件数据不一致的数据
   ```

2. 实行方案
   将数据插入哈希表的之前进行一次查询操作，如果插入位置已经有数据了，且恰好不是本端的数据，ok，直接删掉原有的数据，分析下一条结果就行了;
   这样，最后两端的数据插入完后，哈希表为空，说明比对结果正常。

* 比对其他字段一致, 但客户全称是否一致的例子
  ```
  1. 基于股东号维度, 把股东号、一码通号、客户证件类型、客户证件号码、客户全称 从数据库中导出到txt文件
  
  2. 解析dbf文件, 按顺序组装, 比如 string strCmpDbf = 股东号+证件类型+证件号码+客户全称;
     这样的话dbf文件每一行记录就对应一个字符串, 然后把这些字符串哈希到文件中, 用hash(strCmpDbf)的值作为文件名, 值相同的会保存到同一文件中
  
  3. 把第1步导出的数据做同样处理, 按照同样的顺序组装成字符串 string strCmpDb;
     然后计算该字符串的哈希值, 用该哈希值与第2步的文件做碰撞(与第2步中的做比较) 如果存在hash值相同的文件, 则从该文件中查找是否存在字符串strCmpDb, 存在则删除;
   如果文件没有字符串了则删除该文件, 这样的话,最终剩下来的文件就是不一致的记录了, 由于是基与股东号维度, 所以可以确保这个记录是客户全称不一致的记录.
  ```

