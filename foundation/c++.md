
<!-- TOC -->

- [C++语言基础](#c语言基础)
    - [`i++ / ++i` 是否为原子操作？](#i--i-是否为原子操作)
    - [说一说`volatile`](#说一说volatile)
    - [volatile能保证线程安全吗?](#volatile能保证线程安全吗)
    - [类里面static和const可以同时修饰成员函数吗](#类里面static和const可以同时修饰成员函数吗)
    - [C++中的四种类型转换方式](#c中的四种类型转换方式)
    - [make、gdb、动态静态库](#makegdb动态静态库)
    - [IO模型](#io模型)
    - [`select & epoll`](#select--epoll)
        - [epoll相对select优点](#epoll相对select优点)
    - [epoll的ET/LT](#epoll的etlt)
    - [浮点数在内存中是怎么存储的](#浮点数在内存中是怎么存储的)
    - [判断两个浮点数是否相等](#判断两个浮点数是否相等)
    - [比较结构体是否相等](#比较结构体是否相等)
    - [`main` 函数和启动例程](#main-函数和启动例程)
    - [C 语言函数调用过程](#c-语言函数调用过程)
    - [内核态和用户态区别](#内核态和用户态区别)
    - [系统调用和库函数调用](#系统调用和库函数调用)
    - [为什么系统调用比库函数调用更耗时?](#为什么系统调用比库函数调用更耗时)
    - [结构与联合的区别](#结构与联合的区别)
    - [结构体和类的区别](#结构体和类的区别)
    - [结构体对齐](#结构体对齐)
    - [说一说 `static`](#说一说-static)
    - [说一说 `extern`](#说一说-extern)
    - [说一说 `const`](#说一说-const)
    - [`const`和`#define`的区别](#const和define的区别)
    - [`typedef`和`#define`的区别](#typedef和define的区别)
    - [`inline`和`#define`的区别](#inline和define的区别)
    - [内联函数和成员函数的区别](#内联函数和成员函数的区别)
    - [`new`和`malloc`的区别](#new和malloc的区别)
    - [`#include <string.h>`](#include-stringh)
    - [初始化列表](#初始化列表)
    - [虚函数表](#虚函数表)
    - [抽象类和纯虚函数](#抽象类和纯虚函数)
    - [析构函数的作用](#析构函数的作用)
    - [什么时候要用虚析构函数](#什么时候要用虚析构函数)
    - [引用是否能实现动态绑定，为什么引用可以实现](#引用是否能实现动态绑定为什么引用可以实现)
    - [为什么构造函数不声明为虚的呢？](#为什么构造函数不声明为虚的呢)
    - [哪些自动生成的构造函数需要禁止](#哪些自动生成的构造函数需要禁止)
    - [`operator char()` 什么意思?](#operator-char-什么意思)
    - [访问权限和继承权限](#访问权限和继承权限)
    - [多态实现方式](#多态实现方式)
    - [对象三种创建方式](#对象三种创建方式)
    - [友元](#友元)
    - [指针](#指针)
        - [`printf`输出字符串指针](#printf输出字符串指针)
        - [数据和指针的区别](#数据和指针的区别)
        - [数组指针、指针数组、函数指针](#数组指针指针数组函数指针)
        - [引用和指针的区别](#引用和指针的区别)
        - [智能指针](#智能指针)
        - [野指针](#野指针)
    - [柔性数组](#柔性数组)
    - [STL](#stl)
        - [容器](#容器)
        - [结构](#结构)
    - [使用两个栈实现一个队列](#使用两个栈实现一个队列)
    - [用两个队列实现栈](#用两个队列实现栈)
    - [设计模式](#设计模式)
        - [单例模式](#单例模式)
- [操作系统](#操作系统)
    - [对内存的理解](#对内存的理解)
    - [栈与堆的区别](#栈与堆的区别)
    - [mmp](#mmp)
    - [段页式存储管理](#段页式存储管理)
    - [虚拟地址是怎么映射到物理地址的，说一下这个过程 TODO](#虚拟地址是怎么映射到物理地址的说一下这个过程-todo)
    - [进程](#进程)
        - [`fork`](#fork)
        - [僵尸进程、孤儿进程](#僵尸进程孤儿进程)
        - [守护进程](#守护进程)
        - [进程间通信](#进程间通信)
    - [线程](#线程)
        - [线程和进程的区别](#线程和进程的区别)
        - [互斥量](#互斥量)
        - [线程状态](#线程状态)
        - [死锁](#死锁)
        - [生产者消费者问题](#生产者消费者问题)
        - [进程池、线程池、内存池](#进程池线程池内存池)
    - [协程](#协程)
    - [大小端](#大小端)
    - [哈希](#哈希)
    - [信号](#信号)
- [计算机网络和网络安全](#计算机网络和网络安全)
    - [分层模型](#分层模型)
    - [ARP](#arp)
    - [Arp欺骗](#arp欺骗)
    - [TCP/UDP的区别](#tcpudp的区别)
    - [三次握手](#三次握手)
    - [全连接、半连接](#全连接半连接)
    - [SYN攻击](#syn攻击)
    - [只有两次握手行不行?](#只有两次握手行不行)
    - [四次挥手](#四次挥手)
    - [为什么握手三次, 而挥手要四次？](#为什么握手三次-而挥手要四次)
    - [`Time_Wait`为什么要等待`2MSL`](#time_wait为什么要等待2msl)
    - [如果已经建立了连接，但是客户端突然出现故障了怎么办?](#如果已经建立了连接但是客户端突然出现故障了怎么办)
    - [TCP重传机制](#tcp重传机制)
    - [TCP确认机制](#tcp确认机制)
    - [滑动窗口机制](#滑动窗口机制)
    - [长连接、短链接](#长连接短链接)
    - [`GET`请求和`POST`请求的区别](#get请求和post请求的区别)
    - [浏览器输入地址后发生了什么](#浏览器输入地址后发生了什么)
    - [常用端口](#常用端口)
    - [拥塞](#拥塞)
        - [拥塞控制方法](#拥塞控制方法)
    - [指数退避](#指数退避)
    - [对称加密、非对称加密](#对称加密非对称加密)
    - [`SSL`](#ssl)
    - [`HTTPS`](#https)
    - [`HTTP` 和 `HTTPS` 的区别](#http-和-https-的区别)
    - [挑战响应认证](#挑战响应认证)
    - [socket](#socket)
        - [`send 和 renv` 阻塞和非阻塞模式](#send-和-renv-阻塞和非阻塞模式)
        - [send/recv 和 write/read的区别](#sendrecv-和-writeread的区别)
- [数据结构](#数据结构)
    - [排序](#排序)
        - [堆排](#堆排)
        - [写个快排看看、如何优化？不用递归怎么写](#写个快排看看如何优化不用递归怎么写)
    - [队列和栈](#队列和栈)
        - [用栈来判断括号是否匹配](#用栈来判断括号是否匹配)
        - [用两个栈实现一个队列](#用两个栈实现一个队列)
        - [用两个队列实现一个栈](#用两个队列实现一个栈)
    - [链表](#链表)
        - [翻转链表](#翻转链表)
        - [输出倒数第k个结点](#输出倒数第k个结点)
        - [输出链表中间结点](#输出链表中间结点)
        - [判断链表是否有环](#判断链表是否有环)
        - [求单向局部循环链表的环入口](#求单向局部循环链表的环入口)
        - [判断链表是否相交](#判断链表是否相交)
        - [有序链表合并](#有序链表合并)
    - [二叉树](#二叉树)
        - [父节点和子节点间关系](#父节点和子节点间关系)
        - [概念](#概念)
        - [先序遍历](#先序遍历)
        - [中序遍历](#中序遍历)
        - [后序遍历](#后序遍历)
        - [翻转二叉树](#翻转二叉树)
        - [二叉树第K层的节点个数](#二叉树第k层的节点个数)
        - [二叉树中叶子节点的个数](#二叉树中叶子节点的个数)
        - [二叉树中节点的最大距离](#二叉树中节点的最大距离)
        - [二叉树中节点的最大距离](#二叉树中节点的最大距离-1)
        - [判断是否是平衡二叉树](#判断是否是平衡二叉树)
        - [二叉树还原](#二叉树还原)
        - [二叉树的存储](#二叉树的存储)
        - [二叉排序树](#二叉排序树)
            - [删除](#删除)
        - [优先队列](#优先队列)
        - [线索二叉树](#线索二叉树)
        - [最优二叉树](#最优二叉树)
        - [红黑树](#红黑树)
    - [堆](#堆)
    - [图](#图)
        - [图的遍历](#图的遍历)
            - [DFS](#dfs)
            - [BFS](#bfs)
- [算法](#算法)
    - [100层楼和两个玻璃球](#100层楼和两个玻璃球)
    - [4亿个数，你只有1G内存，你怎么判断某个数已经出现？](#4亿个数你只有1g内存你怎么判断某个数已经出现)
    - [有n级台阶，一个人每次上一级或者两级，问有多少种走完n级台阶的方法。](#有n级台阶一个人每次上一级或者两级问有多少种走完n级台阶的方法)
    - [一个公交站在1分钟内有车经过概率是p，问3分钟内有车经过概率](#一个公交站在1分钟内有车经过概率是p问3分钟内有车经过概率)
- [数据库](#数据库)
    - [连接查询](#连接查询)
    - [索引](#索引)
- [项目](#项目)
    - [一篇英文文章，求找出出现频率最多的单词(双缓存多线程分析大文件词频)](#一篇英文文章求找出出现频率最多的单词双缓存多线程分析大文件词频)
    - [探针](#探针)
    - [dbf提交到oracle的工具](#dbf提交到oracle的工具)
    - [中登账户数据核对](#中登账户数据核对)
- [架构](#架构)
    - [如何设计一个高并发的系统](#如何设计一个高并发的系统)
    - [分布式系统](#分布式系统)
    - [缓存与数据库](#缓存与数据库)
        - [缓存穿透](#缓存穿透)
        - [缓存雪崩](#缓存雪崩)
        - [缓存击穿](#缓存击穿)
    - [消息队列](#消息队列)
- [Linux](#linux)
    - [netstat](#netstat)

<!-- /TOC -->

---

[TOC]

---

# C++语言基础

## `i++ / ++i` 是否为原子操作？

* 不是。操作系统原子操作是不可分割的，在执行完毕不会被任何其它任务或事件中断，分为两种情况（两种都应该满足）
  * 在单线程中， 能够在单条指令中完成的操作都可以认为是" 原子操作"，因为中断只能发生于指令之间。
  * 在多线程中，不能被其它进程（线程）打断的操作就叫原子操作。

* i++分为三个阶段, 这三个阶段中间都可以被中断分离开.
  ```
  内存加载到寄存器
  寄存器自增
  写回内存
  ```
* ++i  
  在多核的机器上，cpu在读取内存i时也会可能发生同时读取到同一值，这就导致两次自增，实际只增加了一次。


## 说一说`volatile`

> 声明时语法：`int volatile vInt;`  
> 它用来解决变量在“共享”环境下容易出现读取错误的问题。

* 不用该关键字修饰，编译器优化有可能会`先把数据从内存加载到寄存器，然后再到用户空间`, 而用它声明的类型变量，编译器对访问该变量的代码就不再进行优化， 即当要使用 volatile 声明的变量的时候，`系统总是重新从它所在的内存读取数据`。

* volatile关键字保证了在多线程环境下,被修饰的变量在别修改后会马上同步到主存,这样`该线程对这个变量的修改就是对所有其他线程可见的`,其他线程能够马上读到这个修改后值. 

## volatile能保证线程安全吗?

> [volatile能保证线程安全吗?](https://blog.csdn.net/qq_43401808/article/details/86540962)

* 不能指望volatile能解决多线程竞争问题，除非所用的环境系统不可靠才会为了保险加上volatile，

* volatile解决的是多线程间共享变量的可见性问题，而`保证不了多线程间共享变量原子性问题`。对于多线程的i++,++i,依然还是会存在多线程问题,volatile是无法解决的,详见上面的[i++/++i是否为原子操作]


##  类里面static和const可以同时修饰成员函数吗

* 不可以同时用const和static修饰成员函数
* C++编译器在实现const的成员函数的时候为了确保该函数不能修改类的实例的状态，会在函数中添加一个隐式的参数`const this*`。但当一个成员为static的时候，该`lstatic函数是没有this指针`的。也就是说此时const的用法和static是冲突的。


## C++中的四种类型转换方式

> [C++中的四种类型转换方式](https://www.cnblogs.com/carsonzhu/p/5251012.html)

* C风格的强制类型转换(Type Cast)很简单，不管什么类型的转换统统是：`TYPE b = (TYPE)a`  
  常见的(type)类型转换是C语言中的类型转换方式，其有很多缺陷如：容易产生两个不可互相转换的类型被转换，从而引发错误等等  

* 有的时候用c风格的转换是不合适的，因为它可以在任意类型之间转换;  
  比如你可以把一个指向const对象的指针转换成指向非const对象的指针;  比如：`char* test = (char*) string.c_str();`
  把一个指向基类对象的指针转换成指向一个派生类对象的指针，这两种转换之间的差别是巨大的;
  但是传统的c语言风格的类型转换没有区分这些

* `static_cast`c++内置类型间转化  
   最常用的类型转换符，正常状况下的类型转换，如把int转换为float;
   如：int i；float f；f=(float) i; 或者用C++类型转换模式：f=static_cast<float>(i)；

* `const_cast`  
   用于取出const属性，把const类型的指针变为非const类型的指针; 只能作用于引用或指针;
   如：`const int *fun(int x,int y){}; int *ptr=const_cast<int *>(fun(2,3))；`

* `dynamic_cast`含虚函数的类  
  * 其他三种都是编译时完成的，dynamic_cast是运行时处理的，运行时要进行类型检查。  
  * 不能用于内置的基本数据类型的强制转换。 
  * dynamic_cast转换如果成功的话返回的是指向类的指针或引用，转换失败的话则会返回NULL。
  * 使用dynamic_cast进行转换的，基类中一定要有虚函数，否则编译不通过  
  * 通常在它被用于安全地沿着类的继承关系向下进行类型转换，但是被转换类必须是多态的，即必须含有虚函数  
  如：`dynamic_cast<T*> (new C);`其中类C必须含有虚函数，否则转换就是错误的；

* `reinterpret_cast`  
   interpret是解释的意思，reinterpret即为重新解释，可以把一个指针转换成一个整数，也可以把一个整数转换成一个指针
   如：`int i; char *ptr="hello freind!"; i=reinterpret_cast<int>(ptr);`



## make、gdb、动态静态库

* `make` 传递参数给 `makefile`  
  * `makefile`：
    ```
    CFLAGS=CFLAG // CFLAG相当于一个变量
    CFLAGS+=-g -Wall
    object=myprog
    all:$object
    myprog:a.c 
      gcc ${CFLAGS} a.c -o ${object}
    ```
  * `make` 传递参数
    ```
    make CFLAG=-DDEBUG
    ```
* `makefile` 传递参数到代码： `-D DEBUG`


## IO模型

* [IO 模型](https://blog.csdn.net/baixiaoshi/article/details/48708347)

* 同步和异步  
  描述的是用户线程与内核的交互`需不需要等待内核返回`
  * `同步` 是指用户线程发起IO请求后需要等待或者轮询内核IO操作完成后才能继续执行    
  所谓同步，就是在发出一个功能调用时，在没有得到结果之前，该调用就不返回,绝大多数函数都是同步调用的    
  * `异步` 是指用户线程发起IO请求后仍继续执行，当内核IO操作完成后会通知用户线程，或者调用用户线程注册的回调函数。

* 阻塞和非阻塞  
  描述的是用户线程调用内核IO操作的方式  
  * `阻塞` 是指IO操作需要彻底完成后才返回到用户空间  
  * `非阻塞` 是指IO操作被调用后立即返回给用户一个状态值，无需等到IO操作彻底完成。

* UNIX下有五种IO模型  
  * 阻塞式 I/O  
  * 非阻塞式 I/O  
  * I/O 复用（select 和 poll）
  * 信号驱动式 I/O（SIGIO）
  * 异步 I/O（AIO）

* `同步阻塞`  

  * 应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。
  * 用户线程通过系统调用read发起IO读操作，由用户空间转到内核空间。内核等到数据包到达后，然后将接收的数据拷贝到用户空间，完成read操作

  ![](http://images.cnitblog.com/blog/405877/201411/142330286789443.png)

* `同步非阻塞`

  * 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为`轮询（polling）`

  * 由于socket是非阻塞的方式，因此用户线程发起IO请求时立即返回。但并未读取到任何数据，用户线程需要不断地发起IO请求，直到数据到达后，才真正读取到数据，继续执行

  ![](http://images.cnitblog.com/blog/405877/201411/142332004602984.png)

* `IO多路复用 select、pool、epoll`  

  * 多路复用也是同步非阻塞，只不过同步非阻塞只轮询一个IO，多路复用可以同时等待多个IO

  * 这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数`可以同时阻塞多个I/O操作`。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。

  *  用户首先将需要进行IO操作的socket添加到 select 中，然后循环调用select（`会阻塞直到select系统调用返回`）。当数据到达时，socket被激活，select函数返回。用户线程正式发起read请求，读取数据并继续执行  

  ![](http://images.cnitblog.com/blog/405877/201411/142332187256396.png)

* `信号驱动IO`
  * 比较少用，因为信号个数有限，多个描述符时不适用
  * 应用进程使用 `sigaction` 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在**数据到达时**向应用进程发送 `SIGIO` 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。

  ![](https://mmbiz.qpic.cn/mmbiz_jpg/D67peceibeIRonM4xRPsSvCaA6KicF8bL6wwM8VVhUaCWReVR2qribs24rO7uWGMpns1M16PaCvb6cz6dUm2oTJgQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


* `异步IO`

  * 应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。

  * 异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。

  ![](http://images.cnitblog.com/blog/405877/201411/142333511475767.png)


## `select & epoll`

* 问题的引出，当需要读两个以上的I/O的时候（`比如socket编程中有多个客户端连接进来`），如果使用阻塞式的I/O，那么可能长时间的阻塞在一个描述符上面，另外的描述符虽然有数据但是不能读出来，这样实时性不能满足要求，大概的解决方案有以下几种：

* `同步阻塞IO`使用`多进程或者多线程`，但是这种方法会造成程序的复杂，而且对与进程与线程的创建维护也需要很多的开销。（Apache服务器是用的子进程的方式，优点可以隔离用户）

* 用一个进程，但是使用`同步非阻塞`的I/O读取数据，当一个I/O不可读的时候立刻返回，检查下一个是否可读，这种形式的循环为`轮询（polling）`，这种方法比较浪费CPU时间，因为大多数时间是不可读，但是仍花费时间不断反复执行read系统调用。

* `信号驱动I/O`，当一个描述符准备好的时候用一个信号告诉进程。

* `I/O多路复用`, 先构造一张有关描述符的列表（epoll中为队列），然后调用一个函数，直到这些描述符中的一个准备好时才返回，返回时告诉进程哪些I/O就绪。select和epoll这两个机制都是多路I/O机制的解决方案，select为POSIX标准中的，而epoll为Linux所特有的。





### epoll相对select优点

>  [epoll相对select优点](https://blog.csdn.net/u014800094/article/details/60591852)

* select的句柄数目受限，在`linux/posix_types.h`头文件有这样的声明：`#define __FD_SETSIZE 1024`  表示select最多同时监听1024个fd。  
  epoll没有，它的限制是最大的打开文件句柄数目。

* epoll的最大好处是不会随着FD的数目增长而降低效率，在selec中采用轮询处理，其中的数据结构类似一个数组的数据结构，而epoll是维护一个队列，直接看队列是不是空就可以了。epoll只会对"活跃"的socket进行操作---这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。那么，只有"活跃"的socket才会主动的去调用 callback函数（把这个句柄加入队列），其他idle状态句柄则不会，在这点上，epoll实现了一个"伪"AIO。但是如果绝大部分的I/O都是“活跃的”，每个I/O端口使用率很高的话，epoll效率不一定比select高（可能是要维护队列复杂）。

* 使用`mmap加速内核与用户空间的消息传递`。无论是select,poll还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存拷贝就很重要，在这点上，epoll是通过内核于用户空间mmap同一块内存实现的。



## epoll的ET/LT


## 浮点数在内存中是怎么存储的
https://www.cnblogs.com/zxtp/p/4938742.html


## 判断两个浮点数是否相等

* 浮点数的表示是不精确的, float 和 double 都不能保证可以把所有实数都准确的保存在计算机中, 采用`==`运算符是不可行的
* 因此都是求绝对值的差值和精度作比较来判断是否相等
  ```c++
  const double eps = 1e-6;
  if (fabs(double_a - double_b) < eps)
  {
     ...
  }
  ```

## 比较结构体是否相等

* 不能直接用 `==` , 该操作符不能比较自建类型
* 不能用 `memcpy` , 因为memcpy是逐字节比较的, 结构体对齐时补的字节内容是随机的
* 可以通过重载 `==` 来实现
  ```c++
  struct s
  {
      int a;
      int b;
      bool operator == (const s &rhs);
  };
  
  bool s::operator == (const s &rhs)
  {
      return ((a == rhs.a) && (b == rhs.b));
  }
  if(a == b)
      ...
  ```


## `main` 函数和启动例程

> [深度剖析c语言main函数 --- main函数的执行顺序](https://blog.csdn.net/z_ryan/article/details/80985101)

* `main` 函数启动前, 系统主要做了初始化的工作
  * 初始化static静态和global全局变量
  * 将未初始化部分的赋初值：数值型short,int,long等为0,bool为false,指针为NULL,等等
  * 运行全局构造器，类似c++中全局构造函数
  * 将main函数的参数, argc,argv等传递给main函数，然后才真正运行main函数

* `main` 函数之前运行的代码
  * 全局对象的构造函数会在main 函数之前执行。
  * 一些全局变量、对象和静态变量、对象的空间分配和赋初值就是在执行main函数之前，而main函数执行完后，还要去执行一些诸如释放空间、释放资源使用权等操作
  * 进程启动后，要执行一些初始化代码（如设置环境变量等）

* `main` 函数是怎么启动的
  * linux系统下程序的入口是`_start`，这个函数是linux系统库的一部分，当我们的程序和Glibc库链接在一起形成最终的可执行文件的之后
    这个函数就是程序执行初始化的入口函数。
  * 编译器缺省是找 `__start` 符号, 而不是 `main` 
  * `__start` 这个符号是程序的起始 
  * `main` 是被标准库 `stdlib` 调用的一个符号

* `main` 函数不能被调用, 为什么还需要返回值  
  `return n; 其实相当于 exit(n);`  
  当一个进程执行完毕时，该进程会调用一个名为 _exit 的例程来通知内核它已经做好"消亡"的准备了;
  该进程会提供一个退出码（一个整数）表明它准备退出的原因。0用来表示正常的或者说“成功”的终止。

* `main` 函数退出状态  
  经过`g++`编译运行后, 可以通过 `echo $?` 查看退出码, 而且，这个退出码是由刚刚执行完的进程提供给系统内核的。

* `main` 函数结束后
  * 全局对象的析构函数会在main函数之后执行； 
  * 用atexit注册的函数也会在main之后执行

* 获取当前执行文件路径 `argv[0]`


## C 语言函数调用过程

* 从栈空间分配存储空间
* 从实参的存储空间复制值到形参栈空间
* 进行运算
  * `形参`在函数未调用之前都是没有分配存储空间的，在函数调用结束之后，形参弹出栈空间，清除形参空间。
    传值：传值，实际是把实参的值拷贝给形参，相当于copy。那么对形参的修改，不会影响实参的值 。
    传址：实际是传值的一种特殊方式，只是他传递的是地址，不是普通的赋值，那么传地址以后，实参和行参都指向同一个对象，因此对形参的修改会影响到实参。
    传引用：引用是变量的一个别名，它不会另外分配空间，所以最终修改的还是原来的变量
  * `数组`作为参数的函数调用方式是地址传递，形参和实参都指向相同的内存空间，调用完成后，形参指针被销毁，但是所指向的内存空间依然存在，不能也不会被销毁。
  * 当函数有多个返回值的时候，不能用普通的 return 的方式实现，需要通过传回地址的形式进行，即地址/指针传递。


## 内核态和用户态区别

* 用户态切换到内核态:  
   系统调用、 异常、中断
* 当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）  
   *  此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈
* 当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）  
   * 此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。这与处于内核态的进程的状态有些类似。
* 既然库函数是调用系统函数, 那为什么不所有代码都放在内核中执行?  
   * 虽然内核执行高效, 但是放内核中执行太危险了, 一旦发生问题就会有宕机的风险; 所以要把有风险的程序放到用户态下执行

## 系统调用和库函数调用

* 函数库调用是语言或应用程序的一部分，而系统调用是操作系统的一部分。

* 用户应用程序访问并使用内核所提供的各种服务的途径即是系统调用
  在内核和用户应用程序相交界的地方,内核提供了一组系统调用接口，通过这组接口，应用程序可以访问系统硬件和各种操作系统资源。

* 系统调用是为了方便应用使用操作系统的接口  
 而库函数是为了方便人们编写应用程序而引出的，比如你自己编写一个函数其实也可以说就是一个库函数。

* 系统调用可以理解为内核提供给我们在用户态用的接口函数，可以认为是某种内核的库函数; 系统调用比库函数调用更耗时  
   read就是系统调用,而fread就是C标准库函数.


## 为什么系统调用比库函数调用更耗时?

* `上下文的切换`  
  系统调用一般都需要保存用户程序的上下文(context) ,在进入内核的时候需要保存用户态的寄存器，在内核态返回用户态得时候会恢复这些寄存器得内容, 这是一个开销的地方
* `堆栈恢复现场`  
  当程序中有系统调用语句，程序执行到系统调用时，首先使用类似int 80H的软中断指令，保存现场;去调系统调用号, 在内核态执行，然后恢复现场.
* 每个进程都会有两个栈，一个内核态栈和一个用户态栈。当执行int中断执行时就会由用户态，栈转向内核栈;
   * 系统调用时需要进行栈的切换。而且内核代码对用户不信任，需要进行额外的检查。系统调用的返回过程有很多额外工作; 比如检查是否需要调度等。



## 结构与联合的区别

* 结构和联合都是由多个不同的数据类型成员组成;  
   但在任何同一时刻, 联合中只存放了一个被选中的成员（所有成员共用一块地址空间）, 而结构的所有成员都存在（不同成员的存放地址不同）。
* 对于联合的不同成员赋值, 将会对其它成员重写, 原来成员的值就不存在了, 而对于结构的不同成员赋值是互不影响的。

## 结构体和类的区别

> 最本质的一个区别就是访问权限和继承权限不同
```
1. C++中的struct对C中的struct进行了扩充，它已经不再只是一个包含不同数据类型的数据结构了，它已经获取了太多的功能：
   ① struct能包含成员函数吗？ 能
   ② struct能继承吗？ 能
   ③ struct能实现多态吗？ 能
2. 既然这些它都能实现，那它和class还能有什么区别？
   ①若不指明，struct成员的默认属性是public的，class成员的默认属性是private的；
   ②若不指明，struct成员的默认继承权限是public的，class成员的默认继承权限是private的；
```

## 结构体对齐

* 结构体大小计算

* 类的大小计算
  ```
  类的存储大小sizeof运算也可以当做结构体来计算;
  注意函数声明不占内存; 静态成员分配在全局区, 也不计入类大小;
  空类会有一个字节做标记; 有虚函数的类, 会包含一个虚函数指针的大小;
  如果父类有虚函数, 子类也有虚函数, 则子类大小 = 基类大小 + 子类大小 + 一个虚函数指针
  要注意继承问题：比如派生类继承基类，那么： 派生类大小=基类成员（不包括静态成员）+自己本身
  ```
* 修改默认对齐数`#param pack(4)`

## 说一说 `static`

* `内存分配、生命周期`  
   static修饰的变量在编译阶段被分配在全局区, 其生命周期随程序的结束而结束
* `静态局部变量`  
   static修饰局部变量时，使得被修饰的变量成为静态变量，存储在静态区。存储在静态区的数据生命周期与程序相同;
   但是作用域只限制于其所在的函数中。 main函数执行之前初始化，程序退出时销毁。（无论是局部静态还是全局静态）
* `静态全局变量`  
   全局变量本来就存储在静态区，因此static并没有改变其存储位置。但是，static限制了其链接属性;
   被static修饰的全局变量只能被该包含该定义的文件访问（即改变了作用域）。
* `修饰函数`  
   static修饰函数使得函数只能在包含该函数定义的文件中被调用。对于静态函数，声明和定义需要放在同一个文件夹中。
* `类static成员变量`  
   用static修饰类的数据成员变量使其成为类的全局变量，会被类的所有对象共享(包括派生类的对象), 所有的对象都只维持
   同一个实例。 因此，static成员必须在类外进行初始化(初始化格式：intse::var=10;)，而不能在构造函数内进行初始化
   不过也可以用const修饰static数据成员在类内初始化。 静态成员变量在构造类之前就存在了，所有类对象只有一份拷贝
* `static成员函数`  
   用static修饰成员函数，使这个类只存在这一份函数，所有对象共享该函数，不含this指针，因而只能访问类的static成员变量
   只可以访问static成员，因为没有this指针(所以也不能声明为虚函数)
* `隐藏`  
   用static修饰的变量或函数仅在本文件内有效， 所以用static可以在不同文件中定义相同名称的变量或函数

## 说一说 `extern`

* `extern int g_Int;`  
   它的作用就是声明函数或全局变量的作用范围的关键字, 其声明的函数和变量可以在本模块或其他模块中使用,不能重复初始化
* 声明函数的时候使用`extern "C" {void fun(int a,int b);}` 可以让编译器按照C语言的方式生成函数的符号


## 说一说 `const`

* const修饰变量(包括指针)
   ```c++
   const int a = 10;
   const int *p = 10; // 表示*p的值不允许改变，*p = 100;// error; int b = 20; p = &b; // ok
   int c = 10;
   int * const p = &c; // p存放了一个固定的地址，所以初始化的时候要给他一个初值，表示p的地址不允许改变
   					   // int d = 20; p = &d // error; c = 20; //ok
   ```
* const修饰函数参数
   ```
   char* strcpy(char* dst, const char* src); // 防止src在strcpy函数内部被改变
   ```
* const修饰函数返回值
   ```
   const int get(); // 防止get() 函数返回值被改变
   ```
* const修饰函数
   ```
   int get() const;
   // 只可以用于类成员函数, 表示get()函数仅可访问类成员变量, 但是不可以改变类成员变量;
   // 只能调用const 成员函数，因为get()函数隐含了一个const this*指针
   ```




## `const`和`#define`的区别

* const 常量有数据类型, 而宏常量没有数据类型。编译器可以对前者进行类型安全检查。 而define只进行字符替换，没有类型安全检查，并且在字符替换可能会产生意料不到的错误。
* 有些集成化的调试工具可以对const 常量进行调试，但是不能对宏常量进行调试。
* #define 是在预处理阶段进行替换  
   const会在编译阶段替换, 会做安全检查, define只是简单地做替换;  
   const会报错, 便于调试

## `typedef`和`#define`的区别

> 类型别名与宏的三点区别，如`typedef char *String_t; 和#define String_d char *`两句：

* 前者是类型别名，要做类型检查，后者只是一个替换，不做类型检查；
* 前者编译时处理，后者预编译时处理，即预编译期间替换掉宏；
* 前者能保证定义的全都是char* 类型，String_d却不能;

## `inline`和`#define`的区别

* 区别在于，宏是由`预处理器`对宏进行替代，而内联函数是通过`编译器`控制来实现的
* 内联函数是真正的函数，只是在需要用到的时候，内联函数像宏一样的展开，所以取消了函数的参数压栈，`减少了调用的开销`。你可以像调用函数一样来调用内联函数，而不必担心会产生于处理宏的一些问题

## 内联函数和成员函数的区别

* 既然内联函数可以节省函数调用的开销, 那为什么不把所有的函数都声明为内联函数?  
如果程序在10个不同的地方调用同一个内联函数，则该程序将包含该函数代码的10个副本,会`消耗更多空间`,所以作为内敛函数的`运行时长越短越好`(因为会展开,所以含有递归调用的函数不能设置为inline)

## `new`和`malloc`的区别

* `性质`  
   new是操作符，操作符可以进行重载，malloc是库函数
* `使用`  
   new使用的时候会自动计算大小，malloc则要指定大小
   new/delete在对象(如类对象)创建的同时会自动执行构造函数做初始化，在对象在消亡时会自动执行析构函数
   而malloc只管分配内存，并不能对所得的内存进行初始化，所以得到的一片新内存中，其值将是随机的；
* `成功`  
   new成功后返回对象类型的指针，malloc返回void* 指针，需要自己做类型转换
* `失败`  
   new抛出异常，malloc返回会NULL，所以用new之后在判断是否为NULL没什么意义
* `扩容`  
   new不支持扩容, malloc在使用过程中发现内存不够可以使用realloc来进行扩容
* 既然有了malloc为什么还要new呢？

## `#include <string.h>`

> 这部分内容更详细的注释在 `string_test.cpp`  
> [Linux中的字符串和字节序列处理函数](https://blog.csdn.net/frecon/article/details/79605941)

* 字符串翻转 `huangjinjie --> eijnijgnauh`
  * 思路:  直接从两头往中间走，同时交换两边的字符即可
    ```c++
    void reverseChar(char *left, char *right)
    {
        assert(left != NULL && right != NULL);
        while (left < right)
        {
            // 异或的方法交换
            *left ^= *right;
            *right ^= *left;
            *left ^= *right;
            left++, right--;
        }
    }
    ```

* 单词翻转 `huang jin jie --> jie jin huang`
  * 先把整个字符串翻转, 然后再按照空格把一个个单词翻转(最后一个不是空格)
     >huang jin jie --> eij nij gnauh --> jie jin huang
     ```c++
     void reverseWord(char *msg)
     {
         int len = strlen(msg) - 1;
         reverseChar(msg, msg + len);
         int left = 0;
         int right = 0;
         char *cur = msg;
         // while (*cur != '\0')
         while (right <= strlen(msg))
         {
             if (*cur == ' ' || *cur == '\0')
             {
                 reverseChar(msg + left, msg + right - 1); // -1 空格
                 left = right + 1;
             }
             right++;
             cur++;
         }
      }
      ```

* 左旋字符串 `huangjinjie --> angjinjiehu` (左旋两位)
  * 思路1：拿出首个字符h, 将其与后面的每一个字符交换一次, 即可完成一次左旋
    > huang -> uhang -> uahng -> uanhg -> uangh
  * 思路2：先翻转**前cnt**个字符, 再翻转**后len-cnt**个字符, 最后把整个字符翻转
    > huangjinjie --> auhngjinjie --> auheijnijgn --> ngjinjiehua

* 右旋字符串 `huangjinjie --> iehuangjinj` (右旋两位)
  * 思路和左旋一样
  * 先翻转**后cnt**个字符, 再翻转**前len-cnt**个字符, 最后把整个字符串翻转
    > huangjinjie --> huangjineij --> nijgnauheij --> jiehuangjin


* strcpy
  ```c++
  char* strcpy(char* dst, const char* src)
  {
  	assert(dst!=NULL);
  	assert(src!=NULL);
  	while((*dst++ = *src++)!= '\0');
  	return dst;
  }
  ```

* memcpy
  ```c++
  char* memcpy(char* dst, const char* src, size_t n)
  {
  	assert((dst!=NULL) && (src!=NULL));
  	while((*dst++ = *src++) != '\0' && --n);
  }
  ```

* strcmp
  ```c++
  int MyStrcmp(const char* str1, const char* str2)
  {
  	   assert((dst!=NULL) && (src!=NULL));
      while ((*str1++ == *str2++)!='\0' && *str1 && *str2);
      int result = *(--str1) == *(--str2) ? 0 : (*(--str1) > *(--str2) ? 1 : -1);
  }
  ```

* strncpy
  这个库函数不会在末尾补`\0`的，自己写的那个是为了安全，才把最后一位改为`\0`
  ```c++
  /*
  * char *strncpy(char *dest, const char *src, size_t n)
  * 从源串的开始拷贝n个字符到目标串地址，n大于[源串长度]时，遇到 '\0' 结束;
      1. dst是否足够空间容纳src
      2. dst末尾是否补\0

      . strncpy 【不负责】在目标串末尾补充'\0' 字符,所以如果n=dest长度的话，会有问题
      . 一般定义 n = strlen(dst) = strlen(src) + 1
      . 当strlen(dst)远大于n时效率低下, 不如用snprintf

  * strlen(dst) = n <= strlen(src), n小于源串长度时, 只拷贝到第n个, 如果等于, 此时dst已经没有地方放\0了
  * strlen(dst) = n > strlen(src),  n大于源串长度时，遇到’\0’结束; dst剩余字节都用’\0’填充
  * strlen(dst) < n, 会破坏dst后面的内存, 输出的值不确定
  */
  char *mystrncpy(char *dest, const char *str, int dest_len, int len)
  {
      int n;
      assert((dest != NULL) && (str != NULL));
  
      char *cp=dest;
      if (dest_len > len)
          n = len;
      if (dest_len <= len)
          n = dest_len; // 只拷贝dest_len个字符
  
      while ((*cp++ = *str++) != NULL && --n)
          ;
  	return dest;
  }
  ```

* strstr
  ```c++
  char* MyStrstr(char* str1, const char* str2)
  {
      assert(str1 != NULL);
      assert(str2 != NULL);
  
      if (*str2 == '\0')
          return str1;
  
      while(str1)
      {
          const char *cur = str2;
          // 每次不相等都从第一个字符重新开始
          while ((*str1++ == *cur++) && *str1 && *cur)
              ;
          // 循环退出, 指针指向不相等的字符的下一个字符
          if (*(--cur) == *(--str1))
              return str1 - strlen(str2) + 1;
          str1++;
  
          if (*str1 == '\0')
              return NULL;
      }
      return NULL;
  }
  ```

## 初始化列表

> [初始化列表](https://www.cnblogs.com/weizhixiang/p/6374430.html)

* 下列情况一定要使用初始化成员列表
  * 常量成员`const`，因为常量只能初始化不能赋值，所以必须放在初始化列表里面
  * 引用类型`&`，引用必须在定义的时候初始化，并且不能重新赋值，所以也要写在初始化列表里面
  * 没有对应的默认构造函数的类类型，因为使用初始化列表可以不必调用默认构造函数来初始化，而是直接调用拷贝构造函数初始化
    * `如果类中声明了构造函数，那么系统不再提供默认构造函数，此时用户如果还要使用无参构造函数，则需要自己重载构造函数`
      ```c++
      class A
      {
         public:
           A(int a){_num = a;}
         private:
           int _num;
      }
      A aobj; // 报错
      ```

  
## 虚函数表

* 编译器为每一个类维护一个虚函数表(本质是一个函数指针数组,数组里面存放着该类所有虚函数的地址);  
  * 每个对象的首地址保存着**各自**指向该虚函数表的指针, 同一个类的不同对象实际上指向同一张虚函数表。    
  `_vptr`存在于对象实例中最前面的位置是为了保证取到虚函数表有最高的性能——如果有多层继承或是多重继承的情况下
  * 对象不包含虚函数表，只有虚指针，类才包含虚函数表，虚指针指向虚函数表，派生类会生成一个兼容基类的虚函数表

* 在单继承形式下, 子类完全获得父类的虚函数表和数据; 子类的虚函数表包含父类的虚函数地址, 且子类虚函数地址在后面  
  * 子类如果重写了父类的虚函数fun;就会把子类虚函数表中原本父类的虚函数fun对应的记录（内容BaseClass::fun）覆盖为子类的fun函数地址（内容SonClass::fun）  


* [单继承、多继承下的虚函数表](https://blog.csdn.net/qq_20309055/article/details/79298593)   
  * 单继承无重写
    ![](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_vtable2.JPG)  
    父类虚函数地址排列在子类虚函数地址前面

  * 单继承有重写  
    ![单继承](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_vtable3.JPG)  
    父类虚函数地址排列在子类虚函数地址前面，父类中被重写的虚函数换成了子类对应的虚函数地址

  * 多继承无重写  
    ![多继承](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_vtable4.JPG)  
    每个父类都有自己的虚表（所以对应每个基类，子类对象中就多一个指针所占的空间）。  
    子类的成员函数被放到了第一个父类的表中。（所谓的第一个父类是按照声明顺序来判断的）

  * 多继承有重写  
    ![](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_vtable5.jpg)  
    (三个父类都有f函数, 子类重写了f函数)  
    三个父类虚函数表中的f()的位置被替换成了子类的函数指针。这样，我们就可以任一静态类型的父类来指向子类，并调用子类的f()了

* 虚函数表并不很安全
  * 对象的地址就是虚函数的地址，对于没有重写的虚函数，无法通过指向子类的父类指针来调用`Base b = new Driver();`  
    但是却可以通过对象的地址计算来访问其他未重写的虚函数
  * 如果父类的虚函数是private或是protected的，但这些非public的虚函数同样会存在于虚函数表中，所以，我们同样可以使用访问虚函数表的方式来访问这些non-public的虚函数


## 抽象类和纯虚函数

* 带有纯虚函数的类为抽象类，它不能生成对象。`如果实现了纯虚函数，就不再是抽象类`。

* 为一个继承体系提供一个公共的根，为派生类提供操作接口的通用语义。

* 就像动物类，它是一个类别的抽象(`抽象类`)，没有实际意义，就像马、牛这样实实在在的生物，他们属于动物这个类别。这些动物都有一个属性就是[会动]，那这个属性就可以看成是动物这个类的纯虚函数，但不同的动物动的方式不一样，所以这个属性应该由马、牛这些子类去做具体的实现

* 在很多情况下，基类本身生成对象是不合情理的。为了解决这个问题，方便使用类的多态性，引入了纯虚函数的概念，将函数定义为纯虚函数（方法：virtual ReturnType Function()= 0;）`纯虚函数不能在基类中实现`，编译器要求在派生类中必须予以重写以实现多态性。

* 抽象类只能作为基类来使用(`比如动物不是实实在在的一个实体`)，而继承了抽象类的派生类如果没有实现纯虚函数，而只是继承纯虚函数，那么该类仍旧是一个抽象类(`比如马是动物的一种, 但马还可以分不同品种`)，抽象类不能生成对象(`比如动物, 只知道它会动, 但不知道怎么动, 这个对象也就没实际意义`)

* 纯虚函数相当于占位符, 先在`虚函数表`中占一个位置由派生类实现后再把真正的函数指针填进去;除此之外和普通的虚函数没什么区别


## 析构函数的作用

* 析构函数是用来释放所定义的对象中使用的指针，默认的析构函数不用显示调用，自建的析构函数要在程序末尾调用。
* 默认析构 
  * 如果类里面只用到的基本类型，如int char double等，系统的默认析构函数其实什么都没有做
  * 如果使用了其他的类如vector，string等，系统的默认析构函数就会调用这些类对象的析构函数
* 自己写的析构
  * 如果动态申请了内存，析构函数中需要进行释放
  * 如果打开了文件，析构函数中也要进行关闭


## 什么时候要用虚析构函数

* 虚函数是动态绑定的基础  
   假如析构函数不是virtual的，就不会发生动态绑定，而是静态绑定，指针的静态类型为基类指针;  
   因此在delete时候只会调用基类的析构函数,而不会调用派生类的析构函数;
   这样, 在派生类中申请的资源就不会得到释放，就会造成内存泄漏
   
* 由于基类函数是虚函数  
   派生类相同函数就自动变虚函数，所以派生类同名函数可以不指定为虚函数

## 引用是否能实现动态绑定，为什么引用可以实现

* 可以。因为引用（或指针）既可以指向基类对象也可以指向派生类对象，这一事实是动态绑定的关键。用引用（或指针）调用的虚函数在运行时确定，被调用的函数是引用（或指针）所指的对象的实际类型所定义的。


## 为什么构造函数不声明为虚的呢？

* 虚函数相应一个指向vtable虚函数表的指针，但是这个指向vtable的指针事实上是存储在对象的内存空间的。假设构造函数是虚的，就须要通过 vtable 来调用，但是对象还没有实例化，也就是内存空间还没有，怎么找vtable呢？所以构造函数不能是虚函数。

## 哪些自动生成的构造函数需要禁止

* 定义类的时候, 编译器会自动产生哪些函数?
  ```c++
  A();
  A(const A&); // 拷贝构造函数
  A& operator = (const A& a); // 赋值构造函数
  ~A();
  ```
* 哪些自动生成的函数要禁止? 为什么?   
  拷贝构造函数、赋值构造函数   
  因为默认生成的这两个函数进行拷贝的时候都是进行浅拷贝, 如果类的成员中有指针的话，浅拷贝方式的结果是只拷贝了便利, 没有重新分配内存, 导致两个不同对象的指针指向同一块内存区域，容易出现访问冲突，多次delete等错误

* 什么时候会调用拷贝构造函数?
  * (就像内建类型一样, 函数的参数和返回值也都是拷贝到临时变量的)
  * 像以值传递的方式传入函数参数 
  * 对象以值传递的方式从函数返回 
  * 新建一个对象并将其初始化为同类现有对象

* 怎么禁止?
  * 用关键字`delete`  
    如：`A(const A&)=delete` 表示删除默认拷贝构造函数，即不能进行默认拷贝
  * 自定义拷贝构造函数


## `operator char()` 什么意思?

> [operator char() 什么意思](https://www.cnblogs.com/edwardlost/archive/2010/12/01/1887983.html)

* `operator` 不仅仅用于`操作符重载`，还可用于`强制类型转换`， 即该类型可以自动转换为char类型。
```c++
class A{
   ...
   operator int() {return static_cast<int>(dat);}
}
... 
cout << add(a1, a2) << std::endl; // a1, a2为A类对象


```





## 访问权限和继承权限

* `三种继承方式`
  * 继承方式是为了控制子类的调用方(也叫用户)对父类的访问权限。
意思就相当于你怎么继承你祖先的东西,想把父类的东西变为自己的东西，你要给这些东西加个属性啊
  * 比如你不想让所有人知道，私下继承，那你祖先原本公开（public属性)或者只允许子孙知道的(protected)东西到了你这儿就都变成私有的了。
  * 如果你继承了你祖先的东西，而这些你继承来的东西你不想别人知道，但你的子孙可以知道，那就用protected方式，这样的话，你祖先原本公开的物资, 到了你这儿也都变成自由子孙可以知道了
  * 如果你大大方方地继承你父类的东西，父类是怎么样的别人看到的就是怎么样

* 继承方式不影响子类对父类的访问权限

* 子类对父类只看父类的访问控制权，即不可能通过public继承来让子类看到父类的private变量;子类仍然能访问 public 和 protected 权限的父类成员

## 多态实现方式

* 编译时多态  
  * `重载`  
    * 同一类中的同名函数是重载, 这些方法的名称相同, 但是参数类型或个数不同, virtual关键字可有可无
    * 不同类中同名函数可能是覆盖，也可能是隐藏。根据是否有virtual以及函数参数是否相同区分；
  * `隐藏`
    * 指派生类的函数屏蔽了与其同名的基类函数，派生对象都是调用派生类的同名函数。
    * 如果子类的函数与父类同名，但是参数不同，此时**不论有无virtual**关键字、基类的函数都将被隐藏;
    * 如果子类的函数与父类同名，且参数也相同，但是基类函数**无virtual**关键字，此时基类的函数被隐藏
      别和覆盖混淆了,覆盖是必须有virtual关键字

* 运行时多态
  * `重写(覆盖)`  
   是指子类重新定义父类虚函数的方法, 以实现不同的功能; 函数体特征相同(函数名、参数类型个数),基类要是虚函数

## 对象三种创建方式
```
A a(1);           //栈中分配
A b = A(1);       //栈中分配
A* c = new A(1);  //堆中分配 1. 内存分配在堆中; 2. 用new会自动调用构造函数
```

## 友元

> `friend int func(int arg);`  
> `friend class CA;` 

* 通过友元，一个不同函数或者另一个类中的成员函数可以访问类中的私有成员和保护成员。
* 友元函数是可以访问类的私有成员的非成员函数。它是定义在类外的普通函数，不属于任何类，但是需要在类的定义中加以声明。
* 友元类的所有成员函数都是另一个类的友元函数，都可以访问另一个类中的隐藏信息（包括私有成员和保护成员）。        

* 友元关系`不能被继承`。 
* 友元关系是`单向`的，不具有交换性。若类B是类A的友元，类A不一定是类B的友元，要看在类中是否有相应的声明。 
* 友元关系`不具有传递性`。若类B是类A的友元，类C是B的友元，类C不一定是类A的友元，同样要看类中是否有相应的申明


## 指针

### `printf`输出字符串指针

* 定义一个字符串指针, 并输出
   ```c++
   char* p_buff = "huangjinjie";
   printf("%s", p_buff);
   Q1: 可不可以去掉`"%s"`  
   A1: 字符串是可以的, 如果printf一个非字符串不加字符格式是不行的
       如: `printf("hello world");`可以打印,  
       `"hell world"`是一个字符串常量, 和`printf(p_buff)` 一样, 传入了一个地址`char*`, 所以可以不需要`%s`
   ```

### 数据和指针的区别

* 修改内容上的差别(比如++运算和字符常量)
* sizeof的差别
* 数组名的作用以及数组名前面添加取地址符的作用  
   * 数组名是数组首地址，是一个常量，不可以当作指针变量用，如：若str为数组名，str++就不合法，相当于常量自增。再次注意：数组名是常量！常量！常量！常量就不可被赋值
      ```c++
      char s[10];
      char *pt, s="hello"；//将常量赋给s，实质就是将常量首地址赋值给s；
      s=pt; // 错误的，s是数组名不可被赋值，任何形式的赋值都不可以。
      ```
   * 同时，一维数组名当被直接使用时，是一个指向数组首地址的指针。  
   * 数组名表示首地址，那么数组名前有取地址符是什么意思？
      例如：数组a[]，a表示数组首元素地址，&a表示数组整体地址，&a+1就是该数组末尾后一个地址

### 数组指针、指针数组、函数指针

* 数组指针：`int (*p)[n];`  
   其中()优先级高，首先说明p是一个指针，指向一个整型的一维数组（或二维数组的某一行）
* 指针数组: `int *p[n];`  
   * 其中[]优先级高，先与p结合成为一个数组，再由`int*`说明这是一个整型指针数组，它有n个指针类型的数组元素。
   * `int *p=new int(12)与int *p=new int[12]`的区别  
      前者表示创建一个指针变量; 其指向一个存储数字12的地址; 后者表示创建一个长度为12的数组。
* 函数指针: `int (*pf)(int *)`  
   为一个返回值为int，参数为`int*`的函数指针;

### 引用和指针的区别

* `内存`   
  引用只是个符号，不占用空间; 指针则要分配空间;
  ```
  占内存大小:
  sizeof(引用) = sizeof(原变量);
  sizeof(指针) = 4 (32位机器上)
  ```
* `初始化`  
指针可以为空，但是引用不可以为空;

* `使用`  
引用在定义的时候就要初始化, 而且初始化之后就不许修改了，指针则可以随时改变指向;


### 智能指针

> [智能指针](https://www.cnblogs.com/wxquare/p/4759020.html)

* 智能指针的原理是什么  
  智能指针实质是一个类，行为上表现得像一个指针（如使用->访问）这个类的构造函数中传入一个普通指针，析构函数中释放传入的指针来实现资源的分配和释放。智能指针的类都是栈上的对象，所以当函数（或程序）结束时会自动被释放  

* 什么时候改变引用计数？(shared_ptr使用引用计数)
  * 构造函数中计数初始化为 1
  * 拷贝构造函数中计数值 +1
  * 析构函数中引用计数 -1
  * 赋值运算符中，左边的对象引用计数 -1 ，右边的对象引用计数 +1
  * 赋值运算符和析构函数中，如果减一后为0，则调用delete释放对象

* 你知道的智能指针有哪些？
  * C++11 `unique_ptr` 只能由一个智能指针指向对象   
    也不支持复制和赋值，但比auto_ptr好，直接赋值会编译出错。实在想赋值的话，需要使用：std::move。
    ```c++
    {
        std::unique_ptr<int> uptr(new int(10));  // 绑定动态对象
        // 和shared_ptr相比，不能拷贝，不能赋值
        // std::unique_ptr<int> uptr2 = uptr;    // 不能赋值
        // std::unique_ptr<int> uptr2(uptr);     // 不能拷贝
        std::unique_ptr<int> uptr2 = std::move(uptr); // 转换所有权
        uptr2.release(); // 释放所有权
    }
    // 超过作用域，会自动释放内存
    ```

  * C++11的 `shared_ptr` 允许多个指针指向同一个对象    
    基于引用计数的智能指针。可随意赋值，直到内存的引用计数为0的时候这个内存会被释放。
    ```c++
    int a = 10;
    int *p = NULL;
    int testp = new int;
    shared_ptr<int> test(testp); // 传入指针，通过构造函数初始化
    shared_ptr<int> ptra = make_shared<int> a; // 用make_shared初始化
    shared_ptr<int> ptra2(ptra); // copy 指针ptra和ptra2都指向a
    p = ptr.get(); // 获取原始指针
    ```

  * C++11的 `weak_ptr`  
    弱引用。 引用计数有一个问题就是互相引用形成环，这样两个指针指向的内存都无法释放。需要手动打破循环引用或使用weak_ptr。顾名思义，weak_ptr是一个弱引用，只引用，不计数。如果一块内存被shared_ptr和weak_ptr同时引用，当所有shared_ptr析构了之后，不管还有没有weak_ptr引用该内存，内存也会被释放。所以weak_ptr不保证它指向的内存一定是有效的，在使用之前需要检查weak_ptr是否为空指针。



### 野指针

* `产生`
  * `声明`  
  指针的时候, 没有初始化为NULL, 这样的话这个指针指向什么地方都是不确定的
  * `释放`  
  动态申请的内存时, 只delete或free了, delete只是表示程序释放  
  delete 释放空间，只是做个标志，表示p所在的内存空间可以被其他进程使用了  
  没释放之前，使用权是当前进程的；而且还需把指针p赋为NULL
* `危害`
指向不可访问地址
破坏正在使用的地址空间
* `防范`  
定义指针的时候就进行初始化    
释放的时候要把指针指向NULL


## 柔性数组

* 在结构体末尾声明0长数组  
对于编译器来说，此时长度为0的数组并不占用空间，因为数组名本身不占空间，它只是一个偏移量;  
这个符号本身代表了一个不可修改的地址常量 （注意：数组名永远都不会是指针！ ）; 但对于这个数组的大小，我们可以进行动态分配
   ```c++
   typedef struct FlexiableStruct
   {
       int a;
       char array[0]; //或char array[]; // 定义0长数组,只是把一个符号放在结构体内, 不占用内存
   }stFlexiable, *pstFlexiable;
   pstFlexiable p_stFlexiable = (pstFlexiable)malloc(sizeof(stFlexiable) + strlen(szStr) + 1); // 给柔性数组申请空间
   ```

* 动态申请的内存只是申请给数组拓展所用，结构体的大小在创建时已经确定了 array明确来说不算是结构体成员，只是挂羊头卖狗肉而已  
   这样的变长数组常用于网络通信中构造不定长数据包，不会浪费空间浪费网络流量

## STL

* [STL](https://blog.csdn.net/sinat_25721683/article/details/79073336)

### 容器

  * list 封装了双向链表, vector 封装了数组, list和vector得最主要的区别在于vector使用连续内存存储的，他支持`[]`运算符，而list是以链表形式实现的，不支持[]

  * Vector对于随机`访问`的速度很快，但是对于`插入`尤其是在头部插入元素速度很慢，在尾部插入速度很快。List对于随机访问速度慢得多，因为可能要遍历整个链表才能做到，但是对于插入就快的多了，不需要拷贝和移动数据，只需要改变指针的指向就可以了。另外对于新添加的元素，Vector有一套算法，而List可以任意加入。
  * vector 当插入新的元素内存不够时，通常以2倍重新申请更大的一块内存，将原来的元素拷贝过去，释放旧空间。

* `map / set`
  * Map,Set属于标准关联容器，使用了非常高效的平衡检索二叉树：`红黑树`，他的插入删除效率比其他序列容器高是因为不需要做内存拷贝和内存移动，而直接替换指向节点的指针即可。
  * Set不包含重复的数据。Set只含有Key，而Map有一个Key和Key所对应的Value两个元素。
  * unorder_map和map, 前者是通过哈希表来实现的, 后者则是通过红黑树(默认就是有序的)

### 结构

* `queue / stack`
  ```
  #include <queue>
  queue<typename> name;
  队首：front()
  队尾：back()
  栈首：top()
  
  公用:
  入：push() 
  出：pop()
  是否空：empty()
  大小：size()
  ```



## 使用两个栈实现一个队列

> [使用两个栈实现一个队列](https://www.cnblogs.com/tracyhan/p/5490775.html)

* 队先进先出，栈先进后出
* 思路  
  入队时全入到stack1中, 出队时把stack1全倒到stack2后，再由stack2来pop ；这样stack1是正确的入队顺序，stack2是正确的出队顺序
  * 缺陷   
    如果是连续出栈操作或连续进栈操作的话没问题, 但是如果入队1 2 3 4 5 6 7 出队 1 2 3 4 再入队 8 9
    ```
    [top] stack1: 1 2 3 4 5 6 7 ---> 5 6 7 ---> 5 6 7 8 9 ; stack2: 1 2 3 4 5 6 7 ---> 8 9 5 6 7
    ```
  * 修复  
    问题在于stack2中的元素还没出队完就把stack1倒进去了, 修改为先判断stack2输出完, stack2不空则继续输出，否则才把stack1倒到stack2里

## 用两个队列实现栈

* 思路  
  入栈：队列1保存入栈序列  
  出栈：队列1的size-1个元素转移到队列2，这样最后剩下的那个就是最后一个元素了  
    再把队列2的元素放回队列1，以待下次pop，队列1暂时用队列2来保存队头前面的元素
    ```
    [back] queue1: 1 2 3 4  --> 4   queue2: 1 2 3 ---> queue1: 1 2 3
    ```




## 设计模式
TODO

### 单例模式


# 操作系统


## 对内存的理解

* `内存分配方式(生命周期)`  
   静态存储连续性: 函数外定义的变量(全局变量)和使用satic定义的变量, 他们在整个程序运行过程中都存在  
   自动存储连续性: 函数内定义的局部变量(包括函数参数), 他们在开始执行所属函数时被创建, 执行完函数后被释放  
   线程存储连续性: 用thread_local定义的变量, 其声明周期和所属线程一样  
   动态存储连续性: 用new/malloc动态申请的变量, 申请时被创建, 直到用delete/free将其释放

* `内存分配时期`  
   编译时不分配内存  
      编译时是不分配内存的。此时只是根据声明时的类型进行占位，到以后程序执行时分配内存才会正确;
      所以声明是给编译器看的，聪明的编译器能根据声明帮你识别错误；  
   运行时必分配内存    
      运行时程序是必须调到“内存”的。因为CPU（其中有多个寄存器）只与内存打交道的。程序在进入实际内存之前要首先分配物理内存;  
      注意，涉及到内存分配的都是在运行阶段分配才有意义。

* `内存分区`  
   栈区: 由编译器自动分配释放, 存放函数参数值和局部变量值等  
   堆区: 由程序员动态申请释放, 存放用new/malloc等申请的变量  
   代码区: 存放二进制代码  
   全局区/静态存储区: 这块内存在程序编译的时候就已经分配好了, 存放全局变量和静态变量  
   文字常量区: 存放字符串常量, 程序结后由系统释放

* `内存碎片`  
  * 内部碎片(操作系统导致)  
    * 已经被分配出去(能明确指出属于哪个进程)却不能被利用的内存空间;
    * 如某一数组容量为90，但实际只可以分配8字节的倍数大小可被 4、8 或 16 整除（视处理器体系结构而定）的地址容量即96,  
      也就是说会分配比实际需要稍微大一点的空间,`比如之前写dbf解析的时候用到mmap, 就是按整页分配, 不满一页也分配一页大小`
    * 剩下的6个字节内存在当前程序中得不到利用也不能再次分配给其他程序，所以成为了碎片。  
  * 外部碎片(程序员导致)  
    * 频繁的分配与回收物理页面会导致大量的、连续且小的页面块夹杂在已分配的页面中间，就会产生外部碎片。  
    * 例如:  
      ```
      有连续空闲字节空间0~99, 刚开始申请了10个字节(占用0~9), 接着申请了5个字节(10~14);  
      把刚才0~9的那10个字节释放, 然后需要申请20个字节, 此时, 刚释放掉的空间不满足大小, 所以分配在了15~34了;  
      0 --- 9 10 +++ 14 15 +++ 34 35 --- 99 (--表示空闲, ++表示占用)  
      所以, 如果10~14的空间一直占用着, 而往后申请的空间都大于10字节, 那么0~9的空间就一直用不上了
      ```
  * 怎么解决这个问题?  
    1. 利用分页单元把一组非连续的空闲页框映射到连续的线性地址, 意思是，我们使用地址转换技术，`把非连续的物理地址转换成连续的线性地址`
    2. 开发一种适当的技术来`记录现存的空闲的内存情况`，以尽量避免为满足对小块的请求而分割大的空闲块

* 内存泄漏的几种情况
  * 类的构造函数和析构函数中new和delete没有配套
  * 释放对象数组时没有使用delete[]，使用了delete
  * 没有将基类的析构函数定义为虚函数
  * 没有正确的清楚嵌套的对象指针

## 栈与堆的区别

* `管理方式不同`  
  栈是编译器自动管理的,堆需手动释放
* `空间大小不同`  
  在32位系统下,堆内存可达到4GB的的空间,而栈就小得可怜.(VC6中,栈默认大小是1M,当然,你可以修改它)
* `能否产生碎片不同`  
  对于栈来说,进栈/出栈都有着严格的顺序(先进后出),不会产生碎片;而堆频繁的new/delete,会造成内存空间的不连续,容易产生碎片.
* `生长方向不同`  
  栈向下生长,以降序分配内存地址;堆向上生长,以升序分配内在地址.
* `分配方式不同`  
  堆动态分配,无静态分配;栈分为静态分配和动态分配,比如局部变量的分配,就是动态分配(alloca函数)
* `分配效率不同`  
  栈是系统提供的数据结构,计算机会在底层对栈提供支持,进栈/出栈都有专门的指令,这就决定了栈的效率比较高.堆则不然,它由C/C++函数库提供,机制复杂,堆的效率要比栈低得多.


## mmp

* 常规操作  
  为了提高读写效率和保护磁盘，使用了页缓存机制。这样造成读文件时需要先将文件页从磁盘`拷贝到页缓存`中，由于页缓存处在内核空间，不能被用户进程直接寻址，所以还需要将`页缓存中数据页拷贝到用户空间`对应的内存
* mmap  
  mmap操作文件中，创建新的虚拟内存区域和建立文件磁盘地址和虚拟内存区域映射这两步，没有任何文件拷贝操作。而之后访问数据时发现内存中并无数据而发起的`缺页异常`过程，可以通过已经建立好的映射关系，只使用一次数据拷贝，就`从磁盘中将数据传入内存的用户空间`中，供进程使用。

## 段页式存储管理  

## 虚拟地址是怎么映射到物理地址的，说一下这个过程 TODO

## 进程

### `fork`
* 写时复制(copy-on-write):
   * fork()进程如果没有调用exec的话, 其代码空间和父进程是一样的
   * 只有在fork之后exec之前两个进程用的是相同的物理空间（内存区）
      子进程的代码段、数据段、堆栈都是指向父进程的物理空间，也就是说
      两者的虚拟空间不同，但其对应的物理空间是同一个。当父子进程中有
      更改相应段的行为发生时，再为子进程相应的段分配物理空间
   * 资源的复制只有在写入的时候才进行
     > 例: 进程A malloc()了一块内存，并将string s，存入该空间，fork出子进程B,B是否可以访问该内存，可以对内存的变量修改吗？
       不能，虽然是在堆上分配的，子进程还是会自己重新复制一份自己的空间，在自己的空间上操作
* fork之后的资源?


### 僵尸进程、孤儿进程

* 僵尸进程
   * 什么是僵尸进程  
      父进程还在运行, 而子进程挂了, 但父进程没有使用wait来清理子进程的进程信息  
      导致子进程虽然运行实体已消失, 但是仍在内核进程表中占有数据, 造成资源浪费
   * 有哪些危害  
      子进程号会一直被占用,系统所能使用的进程号是有限的,如果产生大量的僵尸进程,最终可能导致系统没有可用的进程号,从而不能产生新的进程  
   * 解决方法
      * 杀死其所属父进程, 使其孤儿进程
        ```
         wait
            主进程阻塞, 随便一个子进程结束就停止阻塞
         waitpid
            非阻塞, 但需要用轮询的方式监控子进程
         signal
            其实是子进程退出时会给父进程一个信号, signal里用wait或waitpid都是非阻塞的
         只要父进程还在就都会监测子进程信号, 可以把所有子进程都回收
        ```
      * `kill -s SIGCHLD pid`  
         将这里的 pid 替换成父进程的进程 id, 这样父进程就会删除所有已经死掉的子进程了

* `孤儿进程`  
  子进程还在运行, 而父进程挂了, 子进程变为孤儿进程, 将由init进程收养
* `wait 和 waitpid的区别`
  * 从本质上讲，系统调用waitpid和wait的作用是完全相同的，但waitpid多出了两个可由用户控制的参数pid和options
   从而为我们编程提供了另一种更灵活的方式
    ```
    sub_pid = waitpid(-1, &stat, WNOHANG);
    >0    只等待进程ID等于指定进程号的子进程，不管其它已经有多少子进程运行结束退出了，只要指定的子进程还没有结束 waitpid就会一直等下去。
    =-1   等待任何一个子进程退出，没有任何限制，此时waitpid和wait的作用一模一样。 　　
    =0    等待同一个进程组中的任何子进程，如果子进程已经加入了别的进程组，waitpid不会对它做任何理睬。
    <-1   等待一个指定进程组中的任何子进程，这个进程组的ID等于pid的绝对值
    ```


### 守护进程

* 运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件
  * 守护进程最重要的特性是[后台运行]  
  * 守护进程必须与其运行前的环境[隔离]开来  
    这些环境包括未关闭的文件描述符，控制终端，会话和进程组，工作目录以及文件创建掩码等; 这些环境通常是守护进程从执行它的父进程（特别是shell）中继承下来的  
     进程组
        就是多个进程，进程组由进程组ID标识，进程组ID 也是一个进程的必备属性，每个进程组都有一个组长进程,
        组长进程的ID等于进程组的ID，进程ID不会因为组长进程的退出而受到影响  
     会话组
        是多个进程组组成的，一个会话开始于用户登录，终止于用户退出，在此期间用户运行的所有进程都属于这个会话期，

   * 除开这些特殊性以外，守护进程与普通进程基本上没有什么区别  
      编写守护进程实际上是把一个普通进程按照上述的守护进程的特性改造成为守护进程
* 步骤
```
　1. [脱离终端]
　　　创建子进程，父进程退出
　　　所有工作在子进程中进行
　　　形式上脱离了控制终端
　2. 在子进程中[创建新会话]
　　　setsid()函数
　　　使子进程完全独立出来，脱离控制
　3. [改变当前目录]为根目录
　　　chdir()函数
　　　防止占用可卸载的文件系统
　　　也可以换成其它路径
　4. 重设[文件权限掩码]
　　　umask()函数
　　　防止继承的文件创建屏蔽字拒绝某些权限
　　　增加守护进程灵活性
　5. [关闭文件描述符]
　　　继承的打开文件不会用到，浪费系统资源，无法卸载
```

### 进程间通信

> [进程间通信](https://www.cnblogs.com/xcywt/category/778140.html)

> 管道(FIFO)、信号、共享内存、消息队列、信号量、套接字; IPC好像都是通过一个ID来让进程间通讯

* 无名管道
  * 其实就是依靠fork函数, 利用fork来和父进程公用一个管道
  * 参数 filedis 返回两个文件描述符：filedes[0] 为读而打开
    ```
    int pipe(int filedis[2]) // 1. 创建无名管道(fork之前)
    close(file_descriptors[INPUT]); // 2. 关闭管道的读端
    write(file_descriptors[OUTPUT], "test data", strlen("test data") + 1); // 写入数据
    close(file_descriptors[OUTPUT]); // 关闭管道的写端
    read(file_descriptors[INPUT], buf, sizeof(buf)); // 读取数据
    ```

* 有名管道
  * 可以认为是通过文件来进行进程间通信, 写入读出的对象都是一个文件
  * 管道都有同步和阻塞的问题, 读写有等待的情况; 而且当读写的数据大于最大长度时会阻塞等待
    ```
    mkfifo(PIPENAME, 0666);    // 1. 创建管道
    open(PIPENAME, O_WRONLY);  // 2. 打开管道
    write(fd, &i, sizeof(i));  // 3. 写数据
    close(fd);                 // 4. 关闭管道
    ```

* 消息队列
   * 和有名管道一样, 发送的数据都有一个最大长度限制
   * 生命周期随内核，消息队列会一直存在，需要我们显式的调用接口或使用命令删除
   * 消息队列可以双向通信
   * 克服了管道只能承载无格式字节流的缺点
     ```c++
     #include<sys/msg.h>
     key_t key = ftok("./", 88);                  // 1. ftok 产生key
     int msgget(key_t key,int msgflg);            // 2. 建立消息队列
     int msgsnd(int msgid,void *msg_ptr,size_t msg_sz,int msgflag);
                                                  // 3.1 发送消息 0 阻塞 IPC_NOWAIT 非阻塞
     int msgrcv(int msgid,void *msg_ptr,size_t msg_sz,long int msg_type,int msgflag);
                                                  // 3.2.  接收消息类型为msgtype的消息
     int msgctl(int magid,int cmd,struct msgid_ds *buf);
                                                  // 4. 控制消息队列(也i可以删除)
     ```

* 共享内存
   * 因为系统内核没有对访问共享内存进行同步，您必须提供自己的同步措施, 比如用信号量进行同步
     ```
     #include<sys/shm.h>
     key_t key = ftok("./", 88);                                 // 1. ftok 产生key
     int shmget(key_t key,size_t size,int shmflag);              // 2. 产生信号量ID
     void *shmat(int shm_id,const void *shm_addr,int shm_flag);  // 3. 映射共享内存地址，返回地址指针
     int shmctl(int shm_id,int cmd,struct shmid_ds *buf);        // 4. 控制共享内存(也可以删除)
     int shmdt(const void *shm_addr);                            // 5. 解除映射
     ```

* 信号量 Pv   
   解决进程间同步与互斥问题的一种进程间通讯机制
   ```
   #include<sys/sem.h>
   key_t key = ftok("./", 88);                                 // 1. ftok 产生key
   int semget(key_t key,int num_sems,int sem_flgs);            // 2. 产生信号量ID
   int semctl(int sem_id,int sem_num,int command...);          // 3. 控制信号量(也可以删除)
   int semop(int sem_id,struct sembuf *sem_ops,size_t num_sem_ops); // 解锁或锁定共享资源
   ```
   信号量就是一个计数器，主要是用来保护共享资源。如果允许n个进程访问共享资源，信号量就设置为n，有进程进房子里P操作（py) 锁头就减 1，如果没有锁了（锁数量为0），还有进程想进来，那就挂起这个进程；进程访问完会把锁头交还给房管，此时锁头>0，刚才挂起的进程可以进来操作了

* 基于套接字通信  
   所有的方法都是基于套接字通信的, 所以都有个套接字的入参
  * 服务器
    * 创建socket套接字
      ```
      int fd = socket(AF_INET, SOCK_STREAM, 0);
      AF_INET 表示使用TCP/IP协议族; SOCK_STREAM 表示使用TCP协议, SOCK_DGRAM 表示使用UDP协议;
      ```
     * bind绑定地址和端口
     * 设置套接字为listen状态,等待客户端链接
     * accept接收到客户端连接进来, 创建新套接字与该客户端进行通信
     * 进行读recv写send通信
        ```
        int write(int fd, void *buf, size_t nbytes);
        int send (int sockfd, void *buf, int len, int flags)
        ```
     * 关闭套接字
       ```
       close(fd);
       ```
  * 客户端
    * 创建socket套接字
    * connect与服务器进行链接(三次握手)
    * 与服务器进行收recv发send通信
    * 关闭套接字


## 线程

### 线程和进程的区别

> [线程和进程的区别](https://blog.csdn.net/lishenglong666/article/details/8557215)

* `资源分配(数据和CPU)`  
  进程是资源分配的最小单位，线程是CPU调度的最小单位  
  * `内存地址`   
    进程在执行过程中拥有独立的内存单元，而多个线程共享进程的地址空间;  
    一个进程崩了不会对其他进程产生影响，而一个线程崩了，会导致整个进程都崩掉。
  * `切换开销`   
    在Linux系统下，启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种"昂贵"的多任务工作方式  
    运行于一个进程中的多个线程，它们彼此之间使用相同的地址空间，共享大部分数据，启动一个线程所花费的空间远远小于启动一个进程所花费的空间  
    线程间彼此切换所需的时间也远远小于进程间切换所需要的时间。
  * `通信机制`  
    进程间通过IPC进行数据共享, 不仅耗时而且很不方便；而线程是公用同一进程下的数据，更方便边界（但是要注意多线程间锁的问题）

* `数量关系`  
  一个程序至少有一个进程，一个进程至少有一个线程，线程依赖于进程而存在;

* `使用场景`   
  对资源的管理和保护要求高，不限制开销和效率时，使用多进程   
  要求效率高，频繁切换时，资源的保护管理要求不是很高时，使用多线程


### 互斥量

* `mutex`  
* `lock_guard`  
  类模板, 构造函数进行加锁, 析构函数进行解锁. 可以自己用大括号来限定作用域
* `unique_lock`  
  比lock_gurad灵活在会记住锁的状态,
* `condition_variable + unique_lock + notify_once + wait`
* `future、promise、async`

* `atomic`
* `协程`





### 线程状态

> [多线程—线程的5种状态](https://www.cnblogs.com/domi22/p/8046851.html)  
> 1）就绪：参与调度，等待被执行，一旦被调度选中，立即开始执行  
> 2）运行：占用CPU，正在运行中  
> 3）休眠：暂不参与调度，等待特定事件发生  
> 4）中止：已经运行完毕，等待回收线程资源

* 挂起状态  
线程创建后并没有直接执行或是调用函数挂起了线程, 被挂起了的线程没有执行的能力，只有调用启动函数了之后才能执行;
* 运行状态  
指在线程的时间片内，拥有CPU资源的时候，这是，线程便开始执行
* 阻塞状态(休眠状态)  
是由于进行大量输入输出操作或发生执行错误时，线程失去执行状态，只有等待问题解除之后，线程才能进入等待状态
* 等待状态(就绪状态)  
是指线程启动或时间片抢占失败是等待其他线程执行，在此期间，线程随时可能被执行
* 终止状态  
已经运行完毕，等待回收线程资源
　　

### 死锁
```
1. 产生原因
   陷入互相等待的状态
   A线程锁住了mutex1, 在想用mutex2锁住的变量时尝试锁mutex2, 发现mutex2被锁了, 等待mutex2释放
   B线程锁住了mutex2, 在想用mutex1锁住的变量时尝试锁mutex1, 发现mutex1被锁了, 等待mutex1释放
   原因是A、B线程锁互斥量的顺序不一致, 解锁顺序倒是不影响
2. 解决：
   1) std:lock() 函数模板
      std:lock(mutex1, mutex 2)
      解锁还是要手工unlock()，解锁顺序不影响
      可以一次锁住>=2个互斥量，不存在因锁的顺序问题而导致死锁的存在，会等所有都锁住才继续往下走
      原理:
      如果有一个互斥量没锁成功，则会释放掉已锁成功的互斥量，过段时间再去尝试，直到把所有互斥量都锁住为止
      缺点:
      lock()解决死锁的痛点在于存在忘记unlock的危险，而lock_guard刚好可以自动unlock，可否两者优点都有呢？
   2) lock() 和 lock_guard
      使用lock_guard的adopt_lock参数可以做到，让lock_guard构造的时候不lock, 但是必需在lock_guard之前加锁
      std:lock（mutex1,mutex2)
      lock_guard<mutex>lock_guard(mutex1, adopt_lock)
   3) atomic 原子操作
      类模板atomic声明的对象确保了该操作是原子性的, 不需要加锁
      std::atomic<int> g_atomic_counter(0); // atomic是一个类模板
      g_atomic_counter++;
```


### 生产者消费者问题
TODO

### 进程池、线程池、内存池
TODO


## 协程

* 协程其实可以认为是`比线程更小`的执行单元。为啥说他是一个执行单元，因为他自带CPU上下文
* 协程的`调度完全由用户控制`，一个线程可以有多个协程，用户创建了几个线程，然后每个线程都是循环按照指定的任务清单顺序完成不同的任务，当任务被堵塞的时候执行下一个任务，当恢复的时候再回来执行这个任务，任务之间的切换只需要保存每个任务的上下文内容，就像直接操作栈一样的，这样就完全`没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快`；另外协程还需要保证是非堵塞的且没有相互依赖，协程基本上不能同步通讯，多采用一步的消息通讯，效率比较高。


## 大小端

> (高位) 0x12345678 (地位)  
> [低地址]: 12 34 56 78 (大端)  
> [低地址]: 78 56 34 12 (小端)  

* 大端  
   指数据的高字节保存在内存的低地址中，而数据的[低字节]保存在内存的[高地址]中
* 小端  
   指数据的高字节保存在内存的高地址中，而数据的[低字节]保存在内存的[低地址]中
* 利用union判断是大端还是小端
  ```
   由于union只存储一个成员，若一个union有一个int变量和一个char变量，那么若前一个int变量被赋值后 此时union存储的就是该int变量
   若此时读取char变量，由于char并没有被重写，所以读取的还是int变量的前8位
   根据读取的的8位字节判断是否=int的值, 如果相等，则证明int的值保存在低地址
              15       0        0        0
   [低地址->] 00001111 00000000 00000000 00000000[高地址] // 如果前8位=int的值, 则为小端
              0        0        0        15
   [高地址->] 00000000 00000000 00000000 00001111[低地址] // 如果后8位=int的值, 则为大端
  bool IsLittleEndian()
  {
      union
      {
        int a;
        char b;
      } u;
  
      int k = 15; //要在char范围内
      u.a = k;
      if ((int)u.b == k)
      {
          printf("小端\n");
          return true;
      }
      else
      {
          printf("大端\n");
          return false;
      }
  }
  ```


## 哈希

* 原理 
  * 哈希表（也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。
  * 它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度; 这个映射函数叫做散列函数，存放记录的数组叫做散列表。 `string --> key = hash(string)`

* 解决冲突的方法
   ```
   不同的内容经过同一个散列函数后得到的key值可能是相同的, 这样叫发生冲突(碰撞)
   缓冲区:
      把有冲突的数据都放到缓冲区, 如果在哈希表查不到就去缓冲区找
   二次探测法:
      如果发现数组下标为hash(string)中已有值了, 就往右找(或者同时往左找)第一个没值的位置存放
   再次哈希法:
      这种方法是同时构造多个不同的哈希函数： Hi=RH1（key）  i=1，2，…，k
      当哈希地址Hi=RH1（key）发生冲突时，再计算Hi=RH2（key）……，直到冲突不再产生。这种方法不易产生聚集，但增加了计算时间。
   拉链法
      数组的特点: 查找容易, 插入删除困难
      链表特点:   查找困难, 插入删除容易
      对于相同的key = hash(string)值的数据, 则以key为链表头结点, 往后拉出一条链表, 所有key相同的数据都插入到链表中
   ```

* 哈希表的应用
  ```
  安全领域
     如md5、sha1等消息摘要算法, 用来判断文件完整
  查找
     拿到string的key值后, 就能知道该string存储在哪了
  词频问题
  top-k问题
  查找问题
  ```



## 信号 

* linux进程也有三种方式来处理收到的信号：
  * 忽略信号  
    即对信号不做任何处理，其中，有两个信号不能忽略：SIGKILL及SIGSTOP
  * 捕捉信号  
    定义信号处理函数, 当信号发生时, 执行相应的处理函数
  * 执行缺省操作  
    Linux对每种信号都规定了默认操作

* 信号处理函数
  * SIGIGN    
    忽略信号的处理程序
  * SIG_DFL  
    默认信号处理程序

* 注册信号处理函数对信号做出响应
  ```
  signal(SIGCHLD, SignalHandler);
  // SignalHandle 为信号处理函数, 收到SIGCHLD会调用该函数
  ```
* [可靠信号(实时信号)、不可靠信号(非实时信号)](https://www.cnblogs.com/shichuan/p/4448030.html)
  * linux信号机制基本上是从unix系统中继承过来的。早期unix系统中的信号机制比较简单和原始，后来在实践中暴露出一些问题，它的主要问题是：
  * 进程每次处理信号后，就将对信号的响应设置为默认动作。在某些情况下，将导致对信号的错误处理；因此，用户如果不希望这样的操作，那么就要在信号处理函数结尾再一次调用signal()，重新安装该信号。
  * 早期unix下的不可靠信号主要指的是进程可能对信号做出错误的反应以及信号可能丢失。
  * linux支持不可靠信号，但是对不可靠信号机制做了改进：在调用完信号处理函数后，不必重新调用该信号的安装函数（信号安装函数是在可靠机制上的实现）。因此，linux下的不可靠信号问题主要指的是信号可能丢失。
 
* 信号
  * `SIGHUP`  
    和控制台操作有关，当控制台被关闭时系统会向拥有控制台sessionID的所有进程发送HUP信号，默认HUP信号的action是 exit，
  * `SIGINT`  
    interrupt 终止进程，通常我们的Ctrl+C就发送的这个消息。
  * `SIGKILL`  
    消息编号为9，我们经常用kill -9来杀死进程
  * `SIGSEGV`  
    SegmentFault 试图访问未分配给自己的内存, 或试图往没有写权限的内存地址写数据
  * `SIGIO`  
  * `SIGSYS`  
   系统调用中参数错，如系统调用号非法
  * `SIGCHILD`  
    通知父进程处理所有已经死掉的子进程了  
    如果服务器采用fork产生的子进程推出后要调用wait进行资源回收，防止僵尸进程的产生，但是如果程序对子进程退出后的状态不感兴趣的话可以调用signal(SIGCHLD, SIG_IGN); 交给系统init去回收。子进程也不会产生僵尸进程了
  * `SIGPIPE`  
    这个是向一个没有读进程的管道写数据产生的错误  
    在网络编程中这个信号发生在如果客户端已经关闭了套接字, 而服务器调用了一次write，服务器就会收到一个RST segment，如果服务器再次调用write，这个时候就会产生SIGPIPE信号，系统默认的处理方式是关掉这个进程
  


# 计算机网络和网络安全

## 分层模型

* 为什么要分层?
  * 层次之间`相互独立`。某一层并不需要知道它的下一层是如何实现的，而仅仅需要知道该层通过层间的接口所提供的服务。这样，整个问题的复杂程度就下降了。也就是说上一层的工作如何进行并不影响下一层的工作，这样我们在进行每一层的工作设计时只要保证接口不变可以随意调整层内的工作方式。

  * `灵活性好`。当任何一层发生变化时，只要层间接口关系保持不变，则在这层以上或以下层均不受影响。当某一层出现技术革新或者某一层在工作中出现问题时不会连累到其它层的工作，排除问题时也只需要考虑这一层单独的问题即可。

  * `易于实现和维护`。这种结构使得实现和调试一个庞大又复杂的系统变得易于处理，因为整个的系统已经被分解为若干个相对独立的子系统。进行调试和维护时，可以对每一层进行单独的调试，避免了出现找不到、解决错问题的情况。

  * 结构上可分割开。各层都可以采用最合适的技术来实现。技术的发展往往不对称的，层次化的划分有效避免了木桶效应，不会因为某一方面技术的不完善而影响整体的工作效率。

  * 能促进标准化工作。因为每一层的功能及其所提供的服务都已有了精确的说明。标准化的好处就是可以随意替换其中的某一层，对于使用和科研来说十分方便。

* 各层的作用
  ```
  应用层: 用户与网络间的接口    http
  运输层: 进程到进程间的接口    tcp/udp
  网络层: 主机到主机间的接口    ip
  数据链路层: 相邻结点间的接口  mac、以太网
  物理层: 物理介质间的接口
  ```

* 分层模型
  ```
  OSI
  应用层 -> 表示层 -> 会话层 -> 运输层 -> 网络层 -> 数据链路层 -> 物理层
  TCP/IP
  应用层 -> 运输层 -> 网际层 -> 网络接口层
  ```

* socket套接字接口就是七层模型中应用层以下封装的一个系统调用


## ARP

```
0. ARP是地址转换协议（Address Resolution Protocol）的英文缩写，它是一个链路层协议，工作在 OSI 模型的第二层

1：首先，每个主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址之间的对应关系。

2：当源主机要发送数据时，首先[检查ARP缓冲列表]中是否有对应IP地址的目的主机的MAC地址，如果有，则直接发送数据;
   如果没有，就向本网段(**局域网**)的所有主机[发送ARP数据包]，包括的内容有：源主机IP地址，源主机MAC地址，目的主机的IP地址。

3：当本网络的所有主机收到该ARP数据包时，首先检查数据包中的目的IP地址是否是自己的IP地址，如果不是，则忽略该数据包;
   如果是，则[更新自身Arp缓存]首先从数据包中取出源主机的IP和MAC地址写入到ARP列表中;
   如果已经存在，则覆盖，然后将自己的[MAC地址写入ARP响应包]中，告诉源主机自己是它想要找的MAC地址。

4：源主机收到ARP响应包后, [更新自身arp缓冲]将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据;
   如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。

0. A表示 IP地址, 电话号码表示Mac地址

1. 在公园里, A 想打电话给 B, 翻看通讯录[检查arp缓存]没发现B的号码; (如果有就直接打电话过去了)

2. 于是A在公园大喊一声[arp请求(广播)]:我是A,我号码是123, B你的电话号码是什么

3. 公园里其他人看到问的是B, 就没管它;
   B看到有人问自己号码, 于是就把对方存到通讯录[更新arp缓存], 然后打电话告诉对方:我就是B[arp响应(单播)]

4. A看到接到电话说他就是B, 于是就记录到自己通讯录中, 下次想找B直接从通讯录打电话过去
```

## Arp欺骗

* 有两个问题  
A不管谁打电话来说他是B, 他都认为是真的 B 打过来的  
B也不管谁说A的号码是什么, 他都认为这就是真的 A 的号码

* 假设有一个不规矩的C,电话号码是234  
  * A在公园喊：我是A, 我号码是123,  B你的电话是多少?  
   `单向欺骗` 这时候C就打电话给A, 说我就是B, 然后A就把234保存为B的号码, 这样以后A要联系B都会去通讯录找
   所以C就完全知道A想告诉B的内容了
  * `双向欺骗` C再可以假冒A, A虽然在公园喊谁是B的时候, C也在喊:我是A, 我的号码是234, B你的电话是多少?  
   这时候B会把234当作A的电话号码记到通讯录,.  
   之后, A要跟B交流会打234这个号码, C看到A发给B的内容后, 转手发给B, B看到是234发过来的, 就认为是A的内容, 然后继续通信下去...


## TCP/UDP的区别

* 用户数据包协议
  UDP是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部）。
* 传输控制协议
  TCP是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流  
  把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块
* TCP通过确认机制，丢包可以重发，保证数据的正确性;
  UDP不保证正确性，只是单纯的负责发送数据包；
* UDP是面向报文的。发送方的 UDP 对应用程序交下来的报文，在添加首部后就向下交付给 IP 层
  * 既不拆分，也不合并，而是保留这些报文的边界，因此，应用程序需要选择合适的报文大小；
* UDP的头部，只有 8 个字节，相对于TCP头部的 20 个字节信息包的额外开销很小。

* 连接性  
TCP是面向连接(Connection oriented)的协议，UDP是无连接(Connection less)协议
* 可靠性   
TCP可靠，UDP不可靠；TCP丢包会自动重传，UDP不会。
* 有序性  
TCP有序，UDP无序；消息在传输过程中可能会乱序，后发送的消息可能会先到达，TCP会对其进行重排序，UDP不会进行重排序。
* 有界性  
TCP无界，UDP有界； TCP通过字节流传输，UDP中每一个包都是单独的。
* 拥塞控制  
TCP有流量控制（拥塞控制），UDP没有；TCP主要靠三次握手实现以及慢开始、拥塞避免、快重传、快恢复。
* 传输速度  
TCP传输慢，UDP传输快； 因为TCP需要建立连接、保证可靠性和有序性，所以比较耗时。这就是为什么视频流、广播电视、在线多媒体游戏等选择使用UDP。
* 量级  
TCP是重量级的，UDP是轻量级的；TCP要建立连接、保证可靠性和有序性，就会传输更多的信息，如TCP的包头比较大。
* 头部大小  
TCP包头比较大。
* 应用场合  
TCP一般应用在对可靠性要求比较高的场合，例如http，ftp等等。而UDP一般应用在对实时性要求较高场合，例如视频直播，大文件传输等等。

## 三次握手

> 目的是为了保证双方都能正常收发数据
> ![](http://blog.chinaunix.net/attachment/201304/8/22312037_1365405910EROI.png)

* 第一次握手：建立连接时,客户端发送syn包(syn=j)到服务器,并进入SYN_SEND状态,等待服务器确认;
   SYN：同步序列编号(Synchronize Sequence Numbers)
* 第二次握手：服务器收到syn包,必须确认客户的SYN（ack=j+1）,同时自己也发送一个SYN包（syn=k);
   即SYN+ACK包,此时服务器进入SYN_RECV状态；
* 第三次握手：客户端收到服务器的SYN＋ACK包,向服务器发送确认包ACK(ack=k+1);
   此包发送完毕,客户端和服务器进入ESTABLISHED状态,完成三次握手.
* 三次握手失败, S主动关闭   
  当client与server的第三次握手失败了之后，即client发送至server的确认建立连接报文段未能到达server，server在等待client回复ACK的过程中超时了，那么`server会向client发送一个RST报文段并进入关闭状态`，即：并不等待client第三次握手的ACK包重传，直接关闭连接请求，这主要是为了防止泛洪攻击，即坏人伪造许多IP向server发送连接请求，从而将server的未连接队列塞满，浪费server的资源。
* 解释
```
        你能听到我说话吗?
A ---------------------------> B (A发完SYN进入SYN_SEND状态)
             SYN

       听到了,你能听到我吗?
A <--------------------------- B (B发完ACK和SYN两个包后, 进入SYN_RECV状态) // 半连接
           SYN,ACK

            我听到了
A ---------------------------> B (A发完ACK, A,B都进入ESTABLISHED状态) // 全连接
             ACK
```
 
## 全连接、半连接

* Linux内核协议栈为一个tcp连接管理两个队列，一个是半链接队列（用来保存处于SYN_SENT和SYN_RECV状态的请求），一个是全连接队列（accpetd队列）（用来保存处于established状态，但是应用层尚未调用accept取走的请求）
* 完成三次握手的链接被放到到全连接队列, 只完成了两次握手的队列放在半链接队列


## SYN攻击
拒绝服务(DDOS)攻击

* 在三次握手过程中，服务器发送SYN、ACK后,收到客户端的ACK之前的TCP连接称为半连接(half-open connect).此时服务器处于Syn_RECV状态.当收到ACK后，服务器转入ESTABLISHED状态.

* Syn攻击  
  * 伪冒客户端, 在短时间内伪造大量不存在的IP地址, 不断先服务器发SYN包, 服务器回复确认包并等待客户端的确认包(前两次握手的过程)  
但是由于这些IP是伪造的,不会回复ACK包, 服务器会不断重发直到超时, 这些为找的SYN包会长时间占用`半连接队列`, 导致正常的SYN请求被丢弃.  
导致服务器响应缓慢, 严重者导致网络堵塞甚至系统瘫痪
  * 每收到一个SYN包, 就需要为该请求分配一个TCB（Transmission Control Block）, 通常一个TCB至少需要280个字节，在某些操作系统中TCB甚至需要1300个字节，并返回一个SYN ACK命令, 立即转为SYN-RECEIVED即半开连接状态
  * Syn攻击是一个典型的DDOS攻击。检测SYN攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击

* 防范措施   
  * 监测是否被攻击  
  `netstat -n -p TCP | grep SYN_RECV`
  * `SynCache技术`
    这种技术是在收到SYN数据报文时不急于去分配TCB, 而是先回应一个SYN ACK报文, 并在一个专用HASH表（Cache）中保存这种半开连接信息，直到收到正确的回应ACK报文再分配TCB; 在FreeBSD系统中这种Cache每个半开连接只需使用160字节，远小于TCB所需的736个字节
    旧逻辑: 收到syn就分配TCB保存到半连接队列中
    现逻辑: 收到syn先计算一个哈希值, 把哈希值保存到半连接队列, 等收到ack后再实际分配TCB, 并转入全连接队列
    缺陷: 需要保存连接的序列号信息
  * `SynCookie技术`
    * 完成三次握手前不分配资源。
     原理是，在TCP服务器接收到TCP SYN包并返回TCP SYN + ACK包时, 不分配一个专门的数据区，而是根据这个SYN包计算出一个cookie值
     这个cookie作为将要返回的SYN ACK包的初始序列号。当客户端返回一个ACK包时，根据包头信息重新计算cookie，与返回的确认序列号(初始序列号 + 1)进行对比
     如果相同，则是一个正常连接，然后，分配资源，建立连接。
    * 它使用一种特殊的算法生成SequenceNumber, 这种算法考虑到了对方的IP、端口、己方IP、端口的固定信息, 以及对方无法知道而己方比较固定的一些信息,
      如MSS、时间等; 在收到对方的ACK报文后，重新计算一遍，看其是否与对方回应报文中的（SequenceNumber-1）相同，从而决定是否分配TCB资源。
  * `SYN proxy代理`  
    作为server与client连接的代理，代替server与client建立三次握手的连接，同时SYN proxy与client建立好了三次握手连接之后，确保是正常的TCP连接，而不是TCP泛洪攻击，那么SYN proxy就与server建立三次握手连接，来连通client与server
  * 增大最大半连接队列
  * 网关超时设置
    防火墙设置SYN转发超时参数, 该参数远小于服务器的timeout时间. 当客户端发送完SYN包，服务端发送确认包后（SYN＋ACK）
    防火墙如果在计数器到期时还未收到客户端的确认包(ACK)，则往服务器发送RST包，以使服务器从队列中删去该半连接。
    网关超时参数设置不宜过小也不宜过大，超时参数设置过小会影响正常的通讯，设置太大，又会影响防范SYN攻击的效果


## 只有两次握手行不行?

* `情形一：第一次握手重传`  
  试想一下, C第一次发送SYN1请求连接, 但是在网络某节点滞留了, 然后C超时重传SYN2, 然后这一次一切正常, C跟S可以正常进行数据传输;    
  等到连接释放了以后, 那个SYN1请求突然到了Service那, 如果是两次握手的话, Service发送确认ACK2, 它们就算是建立起了连接了;    
  事实上C并不会理会这个ACK2确认, 因为我压根没有要传数据啊. 但是S却傻傻地以为有数据要来, 苦苦等待. 结果就是造成资源的浪费.  
  ```
  C: 喂, 你听到了吗?
  C: 喂, 你听到了吗?(...那么久还没回应, 我再喊一次)
  S: 我听到了
  ......(交流)
  C: 喂, 你听到了吗?(就像回声, 会晚一点到达)
  S: 我听到了 (什么鬼?, 刚交流完, 又来?)
  C: 我没又要跟你聊天啊, 不管了
  S: 我都听到了, 怎么C还没说话?

  ```
  
* `情形二：第二次握手丢失`  
  假定C链接S, S发了syn+ack包给C; 此时S认为连接已经成功地建立了, 可以开始发送数据分组;
  但是如果syn+ack包丢失了, C不知道S是否准备好, C一直在等待S的ack报, 将忽略一切S发过来的任何数据报文, 而S发报文没收到C的回应, S就会一致超时重发
  ```
  C : 喂, 你听到了吗?
  S : 我听到了<由于网络原因, 这句话没有成功发给C>
  S ：(收了一大堆话)
  S : (不是连接好了吗，怎么没回应? 我重说一遍)
  C : ...(奇怪了, 怎么那么久还没回应, 也不知道他听到没有)
  ```



## 四次挥手

> 目的是确保双方都把消息发送完了  
https://zhidao.baidu.com/question/518425014.html
![](https://gss0.baidu.com/-vo3dSag_xI4khGko9WTAnF6hhy/zhidao/wh%3D600%2C800/sign=2b294494c31b9d168a929267c3ee98b7/8644ebf81a4c510f841634516d59252dd52aa5af.jpg)

```
[主动方]                                  [被动方]
                        FIN1报文
FIN_WAIT1状态  C --------------------------> S  CLOSE_WAIT状态
                  我给你的消息发送完了, 你收到了吗?

                           ACK
FIN_WAIT2状态  C <-------------------------- S
                          收到了

                           FIN2
               C <-------------------------- S LAST_ACK状态
                  我给你的也发送完了, 你收到了吗?

                           ACK
TIME_WAIT状态  C --------------------------> S CLOSED状态
                          收到了
CLOSED状态
```

## 为什么握手三次, 而挥手要四次？

* `建立连接时`   
  Server把响应客户端的请求和请求客户端的确认放在一起发送给客户端了,即第二次握手时有SYN+ACK,ACK用来应答，SYN用来同步
* `断开连接时`  
  一个方向的断开,只说明该方向数据已传输完毕 ,而另一个方向或许还有数据要发给对方,所以得等到另一个方向数据也全部传输完成后,才能执行第三次挥手

## `Time_Wait`为什么要等待`2MSL`

* TIME_WAIT状态有两种存在的理由：
  * 一个数据报在发送途中或者响应过程中有可能成为残余的数据报，因此必须等待足够长的时间`避免残余数据报影响新链接`.

  * `确保被动关闭方已正常关闭`，比如主动关闭方发完ACK，但被动关闭方没收到，就会重发一个FIN之后，客户端等待2msl保证能对这个报文进行应答.

* 当TCP连接断开时候，执行主动关闭那一端在发完最后一个ACK报文后，会进入TIME_WAIT状态，等待2msl（每个分节最长生命期）

* Time_wait状态存在于client收到server Fin并返回ack包时的状态 ，当处于time_wait状态时，我们无法创建新的连接，由于port被占用。

## 如果已经建立了连接，但是客户端突然出现故障了怎么办?

* `TCP设有一个保活计时器`，显然，客户端如果出现故障，服务器不能一直等下去，服务器每收到一次客户端的请求后都会重新复位这个计时器  
  * 时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75分钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。


## TCP重传机制

* TCP`每发送一个报文段，就设置一次定时器`。只要定时器设置的重发时间到而还没有收到确认，就要重发这一报文段

* TCP 的可靠传输机制用字节的序号进行控制。TCP 所有的确认都是基于序号而不是基于报文段(UDP才是发报文段)。 `发送窗口没收到确认不动，和收到新的确认后前移`

## TCP确认机制

* TCP 要求接收方必须有`累积确认功能`，这样可以减小传输开销  

* 累积确认：一般地讲，如果发送方发了包1，包2，包3，包4；接受方成功收到包1，包2，包3。那么`接受方可以发回一个确认包，序号为4(4表示期望下一个收到的包的序号`；当然你约定好用3表示也可以)，那么发送方就知道包1到包3都发送接收成功，必要时重发包4。一个确认包确认了累积到某一序号的所有包。而不是对没个序号都发确认包。

* TCP 标准没有规定对不按序到达的数据应如何处理。通常是先临时存放在接收窗口中，等到字节流中所缺少的字节收到后，再按序交付上层的应用进程。  


## 滑动窗口机制

* TCP 采用大小可变的滑动窗口进行流量控制。窗口大小的单位是字节。
* 在 TCP 报文段首部的窗口字段写入的数值就是当前`给对方设置的发送窗口数值的上限`。发送窗口在连接建立时由双方商定。但在通信的过程中，接收端可根据自己的资源情况，随时动态地调整对方的发送窗口上限值(可增大或减小)。 这样对方可以根据已发送的数据量来计算是否可以接着发送。在处理过程中，当接收缓冲池的大小发生变化时，要给对方发送更新窗口大小的通知，所以 A 的发送窗口并不总是和 B 的接收窗口一样大（因为有一定的时间滞后）。  

* TCP 连接的每一端都必须设有两个窗口, 一个`发送窗口`和一个`接收窗口`（对应socket编程中讲的接收缓冲区、发送缓冲区）
  * `发送缓存`用来暂时存放：发送应用程序传送给发送方 TCP 准备发送的数据；TCP 已发送出但尚未收到确认的数据。
  * `接收缓存`用来暂时存放：按序到达的、但尚未被接收应用程序读取的数据； 不按序到达的数据。




## 长连接、短链接

* 长连接  
  就是客户端发送连接请求，连接成功后就一直保持连接，直到客户端和服务端断开连接
* 短连接  
  就是客户端和服务端连接, 传输完数据之后，服务端再自动断开连接


## `GET`请求和`POST`请求的区别

* GET
  * 当客户端要从服务端读取数据时用GET，使用GET方法时，请求参数和对应的值 附加在URL后面
  * 利用问号?代表URL的结尾和请求参数的开始，传递参数长度受限制，例：/index.jsp?id=100&op=bind
* POST
  * 是向服务器提交数据，POST方法请求参数封装在HTTP请求数据中，可以传输大量数据，可用来传送文件。
* Get和Post请求的区别：
  * Get是向服务器索取数据的一种请求，而Post是向服务器提交数据的一种请求
  * [参数传递方式]Get请求的参数会跟在url后进行传递, POST请求的数据会放置在请求头内提交
  * [大小限制] Get对传输的数据有大小限制, POST没有
  * [安全性]Post比Get安全

## 浏览器输入地址后发生了什么

* 客户端[应用层]浏览器通过DNS解析到www.baidu.com的IP地址220.181.27.48，通过这个IP地址找到客户端到服务器的路径;
   客户端浏览器发起一个HTTP会话到220.161.27.48，然后通过TCP进行封装数据包，输入到网络层。
* 在客户端的[传输层]，把HTTP会话请求分成报文段，添加源和目的端口，如服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000，与服务器进行交换，服务器把相应的请求返回给客户端的5000端口。然后使用IP层的IP地址查找目的端。
* 客户端的[网络层]不用关心应用层或者传输层的东西，主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器，这些都是由路由器来完成的工作，无非就是通过查找路由表决定通过那个路径到达服务器。
* 客户端的[链路层]，包通过链路层发送到路由器，通过邻居协议查找给定IP地址的MAC地址，然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换的IP数据包现在就可以传输了，然后发送IP数据包到达服务器的地址。
1. [DNS]服务器(运行在应用层)把url转为ip地址
2. 浏览器发起一个http会话到这个ip地址, 进行[三次握手], 建立TCP连接, 通过TCP封装后, 进入到网络层
3. 浏览器发起HTTP的post请求, [传输数据]
4. 请求由应用层不断包装进入到数据链路层, 然后经过路由转发(拆解到网络层), 最终经过防火墙\NAT到达目的主机
5. 服务器处理该HTTP请求, 返回HTML文件
6. 浏览器解析HTML文件, 展示

## 常用端口

```
FTP      21
TELNET   23
SMTP     25
POP3     110
HTTP     80
DNS      53
SSL      443
HTTPS    443
```


## 拥塞

* 采用滑动窗口机制还可对网络进行拥塞控制，将网络中的分组（TCP报文段作为其数据部分）数量维持在一定的数量之下，  
  当超过该数值时，网络的性能会急剧恶化。传输层的拥塞控制有慢开始（Slow-Start）、拥塞避免（Congestion Avoidance）、快重传（Fast Retransmit）和快恢复（Fast Recovery）四种算法。

* 拥塞  
  对资源的需求超过了可用的资源。若网络中许多资源同时供应不足，网络的性能就要明显变坏，网络的吞吐量随之负荷的增大而下降。  
  大量数据报涌入同一交换节点（如路由器），导致该节点资源耗尽而必须丢弃后面到达的数据报时，就是拥塞。

### 拥塞控制方法  

* 慢启动 + 拥塞避免;  
* 快重传 + 快恢复。


## 指数退避

## 对称加密、非对称加密

* 对称加密  
  * 加解密用的是同样的密钥  
    比如用123进行加密，解密时也要用123才能解密
  * 特点  
    安全，密钥共享困难  
    速度快，适合加密大量数据
  * 例子  
    DES、AES

* 非对称加密  
  * 使用了一对密钥，公钥（public key）和私钥（private key）。私钥只能由一方安全保管，不能外泄，而公钥则可以发给任何请求它的人。非对称加密使用这对密钥中的一个进行加密，而解密则需要另一个密钥
  * 特点  
    不安全，密钥容易被截获  
    速度慢，适合加密少量数据
  * 例子  
   RSA、DSA
* 消息摘要算法
  * MD5、SHA1、SHA256

## `SSL`

* `SSL`中使用了非对称、对称加密，以及哈希算法

## `HTTPS`

  ![](http://seo-1255598498.file.myqcloud.com/full/998866f5946d50c6c989443edbf90d5b8494fd34.jpg)

* 握手过程  
  * 浏览器把自己支持的加密算法告诉服务器
  * 服务器选一个`加密算法`和`哈希算法`以及自己的`证书（私钥）`发给浏览器
  * 浏览器`校验证书`是否合法，`生成随机数`（对称加密的密钥），并用证书进行加密;  
    使用约定的哈希算法计算握手消息生成`消息摘要`，在使用随机数对消息摘要进行一层对称加密  
    最后将之前生成的所有信息发给服务器
  * 服务器用自己的私钥解密得到对称加密的密钥，用对称密钥对信息进行解密，也对消息摘要进行解密，然后计算一次消息摘要，比较是否和报文中的相等

* 通信过程



## `HTTP` 和 `HTTPS` 的区别

* https协议需要到ca`申请证书`，一般免费证书很少，需要交费。
* http是超文本传输协议，信息是明文传输，https 则是具有安全性的`ssl加密传输协议`。
* http和https使用的端口不同
* http的连接很简单,是无状态的 。
* HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议， 要比http协议安全。


## 挑战响应认证

* 一种客户端认证机制，挑战相当于咨询，应答相当于回答。

* 特点是`密码不在网络上传输`  
   该认证机制中认证者每次向被认证者发送一个随机挑战字串，客户端收到这个挑战字串后，按照双方事先协商好的方法应答;
   ```
   C ---------- 认证请求 ----------→ S
      # Client发出认证请求，进行身份认证，发送Client的id
   C <---------- 挑战 -------------- S
      # 发送Server产生的Random_s
   C ----------  响应 -------------→ S
      # 发送用提供的加密算法加密的(Random_s + id)
   C <---------- 验证结果 ---------→ S
      # S用服务器保存的C的密钥加密(Random_s + id)，和C发过来的做比较，返回认证结果。
   ```

## socket

* socket可以看作是`用户进程`与`内核`网络协议栈之间的编程接口, 所有的bind, listen, accept, send等都是内核函数  
所以应用层是通过socket来与其他几层进行交互的(socket是对其他几层的封装)  
socket不仅能在本机间进行进程通信, 还可以在异构系统(即硬件可以不同)中进行
  > 虚线框中为内核空间
  ```
  [Application]                                          [Application]
        ↓                                                      ↓
        ↓ (socket)                                             ↓ (socket)
        ↓                                                      ↓
   - - - - - - - - - - - - - - - -  - - - - - - - -  - - - - - - - - - - 
  |  [TCP / UDP]                                           [TCP / UDP]  |
  |     ↓                                                      ↓        |
  |     ↓                                                      ↓        |
  |   [IP]                                                    [IP]      |
  |     ↓                                                      ↓        |
  |     ↓                                                      ↓        |
  |       --> --> --> --> --> [网络接口层] --> --> --> --> -->           |
  | - - - - - - - - - - - - - - - -  - - - - - - - -  - - - - - - -  - -|
  ```

* 三次握手  
  ![](http://images.cnblogs.com/cnblogs_com/skynet/201012/201012122157467258.png)


### `send 和 renv` 阻塞和非阻塞模式

> socket 默认是阻塞的， `fcntl()`函数或者send、read最后一个参数可以设置为非阻塞模式  
> 阻塞与非阻塞 **返回值** 没有区分，都是 `<0 出错 =0 对方连接关闭 >0 数据大小`
> 
> `send/recv`只是把应用层的数据拷贝到内核发送缓冲区，真正执行发送以及什么时候发送是由系统(协议栈)决定的，所以函数返回成功，只能说明拷贝成功了，如果在还未发送之前网络断开，则发送失败。

* `send / sendto`  
  > 阻塞非阻塞就是当 `缓冲区大小buff < 要发送大小len` 时，是否等待
  * 阻塞模式  
    `buff < len`，则会阻塞，直到发送缓冲区里的数据被系统发送后，可用缓冲区大小比要发送的数据长度大时，send返回成功  

  * 非阻塞模式  
    `buff = 0`，则会立即返回 `EWOULDBLOCK` 错误，表示无法拷贝任何数据到发送缓冲区  
    `buff: (0, len)` 发送缓冲区有数据但是还未发送，则拷贝尽可能多的数据到缓冲区，所以存在非阻塞send返回的大小比发送数据的长度要小的情况，此时要轮询，直到要发送的大小等于已发送大小

* `recv / recvfrom`  
  从接收缓冲区拷贝数据。成功时，返回拷贝的字节数，失败返回-1  
  * 阻塞模式下`recv`会一直阻塞直到缓冲区至少有一个字节（TCP) / 至少有一个完整的数据包(UDP) 才返回   // TODO
  * 非阻塞模式下如果没有数据就会返回，不会阻塞着读，有数据返回大小，无数据置erno为`EWOULDBLOCK`因此需要循环读取。 

* 返回值的意义
  > 阻塞与非阻塞`recv`返回值没有区别
  * `> 0`  
    表示成功发送n个字节, 如果n不等于buff的长度, 则不能表示发送完毕  
    实际情形下，由于对端的 TCP 窗口可能因为缺少一部分字节就满了，所以返回值 n 的值可能在 (0, buf_len] 之间, 所以要把剩下的(buf_len,n]继续发
  * `= 0`  
    对方如果 send 或者 recv 函数返回 0，我们就认为对端关闭了连接，我们这端也关闭连接即可  
    但是，现在还有一种情形就是，假设调用 send 函数传递的数据长度就是0的时候  
    send 发送 0 字节数据，client 的协议栈并不会把这些数据发出去,  server 端由于没有数据会一直阻塞在 recv 函数调用处
  * `< 0`  
    调用出错, 并设置错误码errno
    ```c++
    (errno == EAGAIN || errno == EWOULDBLOCK || errno == EINTR)) 
    //这几种错误码，认为连接是正常的，继续接收
    ```

* 常见错误码
  * `EINTR`
    中断错误  
    阻塞操作被取消阻塞的调用打断
  * `EWOULDBLOCK`  
    资源暂时不可用,表示无法拷贝数据到缓冲区
  * `EAGAIN`  
    send返回值小于要发送的数据数目  
    recv返回值小于请求的长度时说明缓冲区已经没有可读数据  
    当socket是非阻塞时,如返回此错误,表示写缓冲队列已满,可以做延时后再重试
  * `EPIPE`  
    socket关闭


### send/recv 和 write/read的区别

> [send/recv 和 write/read的区别](https://blog.csdn.net/petershina/article/details/7946615)

* 在功能上，read/write是recv/send的子集。read/wirte是更通用的文件描述符操作，而recv/send在socket领域则更“专业”一些多一个参数用来进行socket控制  
  如: 为接收和发送进行一些选项设置;从多个客户端中接收报文等






# 数据结构

* TODO 所有的递归算法都可以借助栈或队列来实现非递归

## 排序

* 冒泡
  ```c++
   for (i = 0; i < len; i++)
   {
      for (j = 0; j < len - i - 1; j++)
  ```
* 快排

* 选择
  ```c++
   for (i = 0; i < len; i++)
   {
      minIndex = i;
      for (j = i + 1; j < len; j++)
      {
  ```

* 插入
  ```c++
  for (i = 1; i < len; i++)
  {
      tmp = s[i];
      for (j = i - 1; j >= 0 && s[j] > tmp; j--)
      {
  ```

* 希尔排序

### 堆排

* 堆排
  > 弄明白二叉树节点间关系就懂了


### 写个快排看看、如何优化？不用递归怎么写
TODO


## 队列和栈

### 用栈来判断括号是否匹配

* 描述  
  给定一个只包括 `'('，')'，'{'，'}'，'['，']' `的字符串，判断字符串是否有效(如`{[]}`有效，但`{[}]无效`)

* 思路  
  遇到左括号就入栈，遇到右括号就判断栈顶是否是对应的左括号, 是则出栈，最后剩下的是没右括号匹配的数据，看一下栈是否空就行了

### 用两个栈实现一个队列

* 思路  
  已知栈是先进后出，队列则反过来，先进先出，则把栈A的数据弹出依次压入栈B，顺序就颠倒过来，此时栈B的出栈顺序就是队的出队顺序   
  出队操作是先进先出，但是栈是先进后出的，如果把栈的元素颠倒一下，再出栈就是实际出队的顺序了

* 入队操作  
  数据全部存放在栈A，比如入队顺序为：`1,2,3,4,5,6`

* 出队操作  
  把栈A的数据依次出栈，则栈A为：`1,2,3,4,5,6 [top]`，然后把出栈的数据依次弹出全部压入栈B，则栈B为：`6,5,4,3,2,1 [top]`
  因此，出队顺序就是栈B的出栈顺序

* 缺点和改进
  * 问题  
    如果是全入队，出队是全出队则上诉思路没问题，但是如果是入队: `1,2,3,4,5,6 [top]` 出队: `1,2,3` 再入队 `7,8`  
    此时栈A为:`7,8 [top]`，栈B为：`6,5,4 [top]`，如果继续出队的话，栈A数据会全倒入栈B，则栈B为：`6,5,4,8,7 [top]`，  
    出队为：`7,8,4,5,6`，不是我们期望的 1~8
    问题就在于每次出队都是直接把栈A的数据倒入栈B再从栈B弹出数据，这样，如果栈B非空的话，数据顺序就会有问题
  * 改进  
    因此，在出队操作的时候，应该是先判断栈B是否还有数据，如果还有则应该先把栈B数据弹，直到栈B为空才把栈A倒入栈B  
    所以队列长度和是否为空都要判断两个栈的长度和是否为空

### 用两个队列实现一个栈

* 分析  
  已知队列是先进先出，因此按照两个栈实现队列的方法没用，因为队A倒入队B的顺序还是和队A一样  
  出栈的操作是先进后出，也就是后进先出，所以出栈就是把最上面的元素弹出

* 思路  
  队B作为队A的缓存，用来保存到队A里的 `size()-1`个元素，则最后留在队A的就是最上面的元素了，每次把最上面的元素弹出后，把保存在队B中的元素返回队A，因为入队的元素都是保存在队A的



## 链表

* 结点结构
  ```c++
  typedef struct ListNode
  {
     DataType info;
     struct ListNode *next;
  }ListNode, *pListNode;
  ```
* 总结一下遍历链表的`while`循环退出条件  
  如果需要遍历链表，且是从头结点开始`head = llist;` 则循环条件是`head->link != NULL`
  如果是用快慢指针，而且循环中fast比low走的快，则循环条件是`fast && fast->link`

* 计算节点个数
  ```c++
  while (llist->link != NULL)
  {
      iNum++;
      llist = llist->link;
  }
  ```

### 翻转链表

  ```
  思路：
     把头结点后面的结点一个个插入到头结点和第一个结点之间
     循环条件: while(pFirst->next != NULL) // 所有待插入结点都处理了
     指针修改按从后往前的顺序
  ```

### 输出倒数第k个结点
  ```
  思路：
     [快慢指针]
     快慢指针都从第一个结点出发, fast先走k个结点, 然后一起走(**low指针应该从第一个结点和fast一起走**)，直到fast走完
     循环条件: while(fast->link)
     因为fast走了k之后low才开始走, 而且fast走完全程, 所有low只走了n-k（就是倒数第k个）
     其实和先计算链表结点数再走n-k是一个道理
  ```

### 输出链表中间结点
  ```
  思路：
     [快慢指针]
     快慢指针都从第一个结点出发, fast和low同时前进，fast一次走两步, low一次只走一步
     循环条件：while(fast !=NULL && fast->next != NULL)
     因为fast走的路程是low的两倍, 所以fast走完的时候low刚好是走到n/2
  ```

### 判断链表是否有环
  ```
  思路：
     [快慢指针], 这里其实快指针走3步4步都可以，只要比慢指针快就行
     同上;
     循环条件：while(fast !=NULL && fast->next != NULL)
     循环退出条件是：low=fast的时候
  ```
### 求单向局部循环链表的环入口

  ```
  思路:  
    假如有快慢指针判断一个链表有局部环，链表起点是A，环的入口是B，快慢指针在环中的相遇点是C。那么按照原来的运动方向，有AB=CB，这是可以证明的结论
    做法就是先找到相遇点，然后把快指针重置会头结点，快慢指针继续同步走，如果再次相遇，则相遇点就是环的入口
   循环条件:     while(fast && fast->link) // 判断是否有环, 找相遇点     while (fast->link != NULL) // fast重置为llist后遍历链表
  ```

### 判断链表是否相交
  ```
  思路：
     如果相交, 则从相交结点开始到末尾结点肯定都是相同的，Y型
     所以只要判断两条链表最末尾的结点是否相等就行了
  输出相交结点:
    计算两条链表的长度差len, 然后长链表先走len步(为了与短链表对齐)
    长短链表再一起走, 直到遇到第一个相等的结点
  ```


### 有序链表合并
TODO

## 二叉树

* 结点结构
  ```c++
  typedef char DataType;
  typedef struct TreeNode
  {
     DataType data;
     struct TreeNode *lchild;
     struct TreeNode *rchild;
  }TreeNode, *pTreeNode;
  ```

### 父节点和子节点间关系

> [父节点和子节点间关系](https://blog.csdn.net/lanchunhui/article/details/52663514)

* 如果根节点标记为0
  ```
  · 第 i 个结点的左右孩子分别为：
  2i + 1
  2i + 2

  · 结点i的父节点为:
  i/2       当i 为左孩子结点；
  i/2-1     当i 为右孩子结点；

* 如果根节点标记为1
  ```
  · 结点 i 的左右孩子分别为：
  2*i
  2*i + 1

  · 结点 i (不论为左还是右孩子结点)
  其父节点都是 i/2
  ```


### 概念
* 性质
  * 非空二叉树第k层结点最多为**2^(k-1)** 个结点
  * 高度为 K 的二叉树中，总共最多有 **2^k - 1** 个结点
  * 非空二叉树普遍情况下,**n0 = n2 + 1**

* 完全二叉树
  * 只有最下面两层结点度<2,也就是：如果没有最后一层，那么它将是一个满二叉树
  * 最后一层结点都分布在左边
  * 共有n个结点，则深度为**log2(n)+1**
  * 深度为k的完全二叉树，至少有**2^(k-1)**,至多有**2^k-1** so,满二叉树是完全二叉树
  ![](https://images2015.cnblogs.com/blog/818487/201510/818487-20151007234152284-380514952.jpg)

* 满二叉树
  * 深度为k，且最多有2^k-1个结点,可以知道，其每一层节点数都是最大节点数
  * 深度为 k 的完全二叉树去掉第K层就变为满二叉树了  
    可以看出完全二叉树和满二叉树的关系

* 扩充二叉树
  * 添加外层结点，把原树中度数<2的结点都补为2
  * 外部结点个数 N 内部结点个数 n     **N - n = 1**
  * 外部路径 E 内部路径 I             **E - I = 2n**

* 平衡二叉树
  * 其左右子树都是平衡二叉树，左右子树的高度的绝对值<=1

TODO
### 先序遍历

* 递归
* 非递归


### 中序遍历
### 后序遍历
### 翻转二叉树

* 递归实现  
  跟交换两个变量一样的操作, 结点相当于变量
  ```c++
  void swap_biTree(BiTree t)
  {
      if (t == NULL || (t->lchild == NULL && t->rchild == NULL))
          return;
      BiTree tmp = t->lchild;
      t->lchild = t->rchild;
      t->rchild = tmp;
      if (t->lchild)
          swap_biTree(t->lchild);
      if (t->rchild)
          swap_biTree(t->rchild);
  }
  ```

* 非递归实现  



### 二叉树第K层的节点个数
### 二叉树中叶子节点的个数
### 二叉树中节点的最大距离
### 二叉树中节点的最大距离
### 判断是否是平衡二叉树

### 二叉树还原

* 先+中
    根据终先序找到第一个根后，就可以在中序中将序列分成左右两部分,对分开后的两部分也这样分析就可以还原了
* 中+后
    方法和上面差不多，后序中最后一个元素就是根,倒数第二个就是根右边的儿子
* 先+后
   无解,只能确定父子关系而已

### 二叉树的存储

1. 数组  
   如果用数组来存储的话，可以根据父子结点的位置关系来确定一颗二叉树<如果子节点为i则富结点为i/2>
   但是无论如何都得按照完全二叉树的空间来分配即:2^k-1,很明显太浪费
   . 如果将一个算式存到二叉树那么先中后序遍历得到的式子刚好就是前缀中缀后缀

2. 链式存储  
   [data][llink][rlink]

有空找找二叉树的选择题看看。


### 二叉排序树

* 结点间是左小右大，子树也是二叉排序树, 结点元素是唯一的
* 插入删除都不改变树的结构
* 经过中序遍历后得到的是递增的序列(所以插入的时候，不可以在中间插入，必须遍历完,找到的位置一般都是末尾)
* 根始终大于左子树，小于右子树
* 子树也是二叉排序树

#### 删除
三种情况:
* 所删结点为叶节点
* 所删结点左/右子树空
* 所删结点左右子树都非空

### 优先队列
* 和队列一样，队尾进,队头出。不同的是优先队列中的最大/小元素总是位于对首，所以并非先进先出，而是最大/小的元素先出。

### 线索二叉树
* 为了充分利用空指针,如果有儿子，指针就指向儿子,否则，作为线索只想前驱或后继结点。

### 最优二叉树
* 哈夫曼树 `WPL`

### 红黑树
TODO


## 堆

* 特点:  
  大/小根堆:  每个子二叉树的根均大/小于其左右子树
* 构建堆:  
  当新增加一个数被放置到堆顶时, 如果此时不符合最小堆的特性,则将需要将这个数向下调整`与左右儿子作比较, 与小儿子做交换(小根堆)`直到找到合适的位置为止,使其重新符合最小堆的特性。

## 图

### 图的遍历

*  中国象棋中马走日字, 给定棋盘上两个点A、B, 马从A到B最短走几步

#### DFS

  深度优先搜索是类似于树的一种先序遍历，利用栈，：V1，V2，V4，V8，V5，V3，V6，V7.
![](http://img.blog.csdn.net/20130603151418281)

#### BFS  

广度优先搜索类似于树的层次遍历，利用队列，广度优先搜索次序为：V1，V2，V3，V4，V5，V6，V7，V8.
![](http://img.blog.csdn.net/20130603151426015)


# 算法

## 100层楼和两个玻璃球

*  [100层楼和两个玻璃球](https://mp.weixin.qq.com/s?__biz=MzUyNjQxNjYyMg==&mid=2247484557&idx=1&sn=739d80488fe1169a9c9ca26ecfcdfba6&chksm=fa0e6b0ccd79e21a1c2b0d99db69f6206cddddfe2367742e9de1d7d17ec35a5ce29fa4e30d63&scene=21#wechat_redirect)

* [100层楼和两个玻璃球](https://blog.csdn.net/JIEJINQUANIL/article/details/52344857)
* 描述  
  有一栋100层高的大楼，给你两个完全相同的玻璃球;
  假设从某一层开始, 丢下玻璃球会摔碎. 那么怎么利用手中的两个球, 用什么最优策略知道这个临界的层是第几层？？？
* 一颗球:
  * 想法一：逐层扔  
    如果只有一个球, 那只能一层一层试, 从第2层~第99层,因为如果第二层没碎, 那第一层肯定也不会碎, 如果第99层没碎, 那肯定第100层会碎  
    所以需要尝试98次
  * 想法二：隔层扔  
    既然一层一层扔太慢, 那可不可以隔一层扔一次? 比如从第2层扔没碎, 下一次就从第4层扔, 因为如果第4层碎了, 那临界层肯定就是第3层了...  
    所以最少需要 n/2 (向下取整, 如11则5次, 12则6次)次
* 两颗球:  
  现在多了一个球, 可以借助这个球来划定区间, 就像二分查找, 也是在一个个区间中去找答案  
  * 想法一：`二分法`  
    如果第一个球在50层扔下没碎, 那扔下会碎的层肯定在(50, 100]之间, 那怎么划分这个区间更合理呢?
    是不是可以用二分查找的方法来做? 不行的, 比如在50层扔没碎, 按照二分法, 下一次从50到100的一半75层开始扔, 如果这时候碎了, 碎了这个球就不能再用了那能确定的是临界层是在50到75之间, 最坏的情况下还需要扔51、52、53...74 = 24, 也就是说总共需要扔1(50层) + 1(75层) + 24 = 26次
  * 想法二：`逐层递减`  
    既然第一步（确定临界段）的投掷数增加不可避免, 我们就让第二步（确定临界层）的投掷数随着第一步的次数增加而减少. 第一步的投掷数是一次一次增加的, 那就让第二步的投掷数一次一次减少  
    转化为数学模型就是: f+(f-1)+…+2+1>=99, 即f(f+1)/2>=99, 解出结果是14(以下均为最坏的情况时的次数)  
    实际操作就是：从14开始扔, 如果碎了, 另一颗球就从[1,13], 一共 1 + 13 = 14 次
    如果14层扔没碎, 下一步从14+13=27层开始扔, 如果碎了, 一共就是 1 + 1 + [15, 26] = 14
    ...依此类推  
* 其实只需要13次就好了, 比如第一次从14楼扔下, 球碎了, 那第二颗球就从[2,13]区间扔就行了, 一共是 1 + 12 = 13次, 因为如果在第二层扔没碎, 那第一层肯定没碎, 如果在第二层扔下就碎了, 那第一层肯定就是临界层了)

## 4亿个数，你只有1G内存，你怎么判断某个数已经出现？

* 位图法: int的取值范围是`−2^31至2^31−1`, 我们可以连续申请`2^32 bit = 2^30 byte = 1G`的内存, 这样，每个bit都可以对应一个int数字，将这1G内存初始化为0
  接下来每次处理一个数字，就给它所对应的bit设为1，查询时就只要看其对应的bit值，当然0会有两个bit对应所以特殊处理一下。

* 位图法的基本原理是：使用位数组来表示某些元素是否存在，每一个bit位可以标记一个元素对应的Value。

## 有n级台阶，一个人每次上一级或者两级，问有多少种走完n级台阶的方法。

* 用动态规划表来抽象出实际问题  
  在这个问题上，我们让f(n)表示走上n级台阶的方法数。
  那么当n为1时，f(n)= 1,n为2时，f(n)=2,就是说当台阶只有一级的时候，方法数是一种，台阶有两级的时候，方法数为2。
  那么当我们要走上n级台阶，必然是从n-1级台阶迈一步或者是从n-2级台阶迈两步,
  所以到达n级台阶的方法数必然是到达n-1级台阶的方法数加上到达n-2级台阶的`方法数之和`。即f(n)= f(n-1)+f(n-2)

## 一个公交站在1分钟内有车经过概率是p，问3分钟内有车经过概率
* 概率论知识
  ```
  正向考虑：P = p+(1−p)∗p+(1−p)∗(1−p)∗p
  反向考虑：P = 1−(1−p)^3
  ```

# 数据库

## 连接查询

## 索引


# 项目

## 一篇英文文章，求找出出现频率最多的单词(双缓存多线程分析大文件词频)

* 用流的方式打开文件, 读入指定大小的字节到内存中, 注意要进行截断检查
* 词频统计, 那怎么处理非英文的字符?   
  维护一个word数组, memset初始化为false, 下标在大小写字母和数字之间的ascii码为true;
  所以, word[i]为false的字符则不读入
* 利用两个缓存, 读入数据到buff[0]后就开多线程去处理buff[0], 然后切换buff, 读入数据到buff[1].  
  实现IO分离; 多线程在创建开始之前, 就计算好了开始处理的位置和处理结束的位置,所以不会发生冲突.
* 怎么分析  
  定义一个word字符数组来装单词,读入内存的数据一个个判断是否是有效的字符(用第2步的方法, 把字符作为下标,
  判断是否为true), 知道发现第一个不在word中字符(比如空格), 则word[128]中保存的就是一个有效的单词.
  然后去<char *, unsigned int>map中find, 看是否以该单词为key值的map, 有则+1(map中的key为单词, value为数目)
* 最后把所有的子map合并在一起, 然后遍历一遍总的map就知道了

## 探针

1. 需求  
   通过实时分析生产环境后台产生的业务日志, 一旦发现超时请求串就及时发送给对接系统进行处理, 减少人工干预, 保证业务办理顺畅

2. 须知  
   请求串和应答串有唯一msgid值来确定对应关系

3. 技术
4. 概述
```
系统使用双缓存多线程的方式, 把指定量的日志通过fstream读入到内存中,（如果读入的数据不是行尾, 则会继续往后读, 知道是行尾为止, 一面请求串被截断);
读取完后切换缓存, 这样可以继续分析处理已读入的文件;
具体处理方法是: 开多线程把已读入到内存的数据按照行尾分割到vector中, 然后再把这个vector按照msgid为key处理到unorder_multimap中;
   Q1: `既然使用多线程处理一个文件, 那你处理过程中有没有加锁呢？`
   A1: 第一步处理到vector是通过for循环来创建线程, 而且是指定了该线程需要处理的文件长度(也会做防截位处理)才开始创建;
       所以, 新线程处理的开始位置和处理大小都是确定的, 每个线程处理的位置不一样, 不会发生冲突
       但是确实是操作着同一块缓冲, 为什么就没发生多线程问题呢?
   A1: 创建线程代码如下, 其实是先计算线程1需要处理的 vecThreadLines, 然后让线程去吧这个 vector里的行映射到 map1 中,
       创建线程2的时候又计算了线程2需要处理的 vecThreadLines, 所以线程2处理的是这个新计算出来的vector, 处理到 map2 中
       也就是说不存在多线程同时处理一个文件的问题, 这个文件先被切割到不同的vec中了,各个线程处理的是各个vector
      for (int i = 1; i < iThreadCount; ++i)
		{
			if (llThreadIndex != llRealSize) // 避免文件只有一行时 getBlockSize 报错
			{
				llFileLen = getBlockSize(bBufferIndex, llThreadIndex, llThreadPart);
			}

			// 若剩余行数少于线程数,还需要判断一下线程已处理的字符和该块数据的大小
			if (llFileLen + llThreadIndex < llRealSize)
			{
				vecThreadLines = ReadLineToVec(bBufferIndex, llThreadIndex, llFileLen);
				threads[i] = thread(&CLbmRiskWarning::ParseMsgLine, this, vecThreadLines, i, strMsgKey);
				llThreadIndex += llFileLen;
			}
			else
			{
				break;
			}
		}



   Q2: 那你不是要处理到一个map中吗? 又开多线程, 怎么会没有多线程问题?
   A2: 如果是多个线程同时去写一个map, 那肯定是会有多线程问题的; 我的做法是: 每个线程从vector处理到map时, 都是处理到自己的那个map;
       比如1号线程解析数据到map1, 2号到map2; 这样各自线程都是解析到自己的那个map上, 不会冲突, 最后再把几个map合并到一起继续做后面的处理
   Q3:为什么不用锁呢?
   A3: 用锁可以保证最终处理到一个map上, 避免使用锁是因为在数据产生很快的情况下, 每条数据都要插入到map中, 这明显会把处理这一步拖慢;
       所以我就采用分map的方法, 最后合并实在处理线程外合并的, 不会影响处理速度.
处理完毕后扫描逻辑会去扫描unorder_multimap，找出一个key值只有一条记录的串, 然后判断如果是req串而且已经超时了, 那么就把它删除, 如果是ans串也把它删除; 如果只有req串但没超时则保留
   Q4: 既然你是一次读入n大小的内存, 那万一你的req串在内存A, ans串在内存B呢? 怎么处理?
   A4: 如果是这样, 如果扫描发现这个req串没有超时, 则保留在map中, 如果已超时则删除, 因为已超时了, 没必要去等ans串了
对于扫描发现超时的请求会异步发送给webservice, 并查看返回结果, 看是否发送成功, 如果没发送成功则继续发送, 发送成功则获取返回的json串做展示
   Q5: **异步发送?**
   A5: 因为扫描的时候发送webservice不可能阻塞在那里等它返回结果再扫描下一条, 所以这里是用c++11的future、promise来异步发送数据, 并开了一个监视线程来轮询监视future的结果;
      这样就可以保证接收端一有结果返回，本程序就能知道, 并作出相应的动作, 因为future对象是放在一个vector中, 所以对于因客观原因比如断网没有发送成功的记录会继续发送, 知道发送成功为止, 发送成功则从vector中删除记录.
   Q6: 为什么不直接用getline()来获取?
   A6：我的实现中是读入内存,然后按照\n分割到vec, 然后遍历vec映射到map中, 前面那两步明显可以用getline来直接从文件中获取一行数据啊
   Q7: 你的这个系统在分布式架构中适用吗？
   A7：不适用, 这个系统须放在服务器上, 如果是分布式架构, 每台服务器都要部署一个这样的程序, 程序后续的更新维护很不方便;
       (而且有的请求的请求串在服务器1, 应答串在服务器2上,金正的框架实际上不会这样)
       更好的做法是用 C/S架构, customer的职责是实时获取log日志的最新行, 并通过socket发送给service, 把这么一个customer程序部署到所有服务器中;
       这样所有的日志最终都是在service端做分析处理, 解决了req串在服务器A, ans串在服务器B的问题
```

## dbf提交到oracle的工具

* 需求 
   把dbf文件插入到数据库中, dbf文件很大(有一两g), 记录数有两千多万

* 技术方案
  ```
   使用[mmap]把dbf文件读到内存中, 提高处理效率
   dbfread 知道了dbf的二进制格式,就可以根据格式来进行解包了, 先把文件头去掉, 然后根据长度使用memcpy来进行内存拷贝
   Q1: mmap提高处理效率? 那你说说你对mmap的理解TODO
   A1: mmp 
   Q2: 说说系统调用和库函数的区别
   A2: xxxxxxxxxxxxxxxxxx
  ```


## 中登账户数据核对

* [参考方案](https://mp.weixin.qq.com/s?__biz=MzI4NDMyNzA4NQ==&idx=1&mid=2247483816&sn=9c60561b82c016ed8be741260bc5b157)

1. 需求
  ```
   DBF文件中保存着客户的信息资料, 需要用该信息和系统内数据表的客户信息做比对，找出系统内数据库数据和文件数据不一致的数据
   ```

2. 实行方案
   将数据插入哈希表的之前进行一次查询操作，如果插入位置已经有数据了，且恰好不是本端的数据，ok，直接删掉原有的数据，分析下一条结果就行了;
   这样，最后两端的数据插入完后，哈希表为空，说明比对结果正常。

* 比对其他字段一致, 但客户全称是否一致的例子
  ```
  1. 基于股东号维度, 把股东号、一码通号、客户证件类型、客户证件号码、客户全称 从数据库中导出到txt文件
  
  2. 解析dbf文件, 按顺序组装, 比如 string strCmpDbf = 股东号+证件类型+证件号码+客户全称;
     这样的话dbf文件每一行记录就对应一个字符串, 然后把这些字符串哈希到文件中, 用hash(strCmpDbf)的值作为文件名, 值相同的会保存到同一文件中
  
  3. 把第1步导出的数据做同样处理, 按照同样的顺序组装成字符串 string strCmpDb;
     然后计算该字符串的哈希值, 用该哈希值与第2步的文件做碰撞(与第2步中的做比较) 如果存在hash值相同的文件, 则从该文件中查找是否存在字符串strCmpDb, 存在则删除;
   如果文件没有字符串了则删除该文件, 这样的话,最终剩下来的文件就是不一致的记录了, 由于是基与股东号维度, 所以可以确保这个记录是客户全称不一致的记录.
  ```

# 架构

## 如何设计一个高并发的系统

* `SQL优化`，包括合理的事务隔离级别、SQL语句优化、索引的优化；
* 使用缓存，尽量`减少数据库 IO`
* `分布式`数据库、分布式缓存
* 服务器的`负载均衡`

## 分布式系统
TODO

## 缓存与数据库

> [缓存与数据库](https://www.cnblogs.com/duanxz/p/3788366.html)

* 用过 `mysql + redis` 的模式，redis作为数据库的缓存，查询过的数据会存放到缓存中，如果下次再来查就先检查缓冲，缓存不存在再去查数据库, 缓存中找到数据，就直接从缓存返回；每次修改数据都要持久化到数据库
  ![](https://user-gold-cdn.xitu.io/2018/3/14/162237b7c0c5296d?imageslim)


### 缓存穿透

* 现象   
  当业务系统需要`查询数据库不存在的数据时，每一次求最终都要访问一次数据库`，即业务访问根本不存在的数据。
* 危害  
  大量这种根本查询不到数据的请求会对数据库造成冲击，拖慢数据库性能，甚至导致数据库崩溃
* 解决方案  
  * 缓存空数据   
    即将空数据null也做成一个缓存结果，这样在下次有相同请求到来时，缓存可以拦截该请求，返回缓存中的结果。
  * `BloomFilter(布隆过滤器)`  
    它需要在缓存之前再加一道屏障，里面存储目前数据库中存在的所有key。当业务系统有查询请求的时候，首先去BloomFilter中查询该key是否存在。若不存在，则说明数据库中也不存在该数据，因此缓存都不要查了，直接返回null。若存在，则继续执行后续的流程，先前往缓存中查询，缓存中没有的话再前往数据库中的查询。

### 缓存雪崩

* 现象  
  如果缓存在某个时刻挂了，那么大量的请求也将会直接访问数据库，造成很大压力。
* 危害  
  如果缓存因某种原因宕机，那原本被缓存抵挡的海量查询请求就会像疯狗一样涌向数据库。此时数据库如果抵挡不了这巨大的压力，它就会崩溃。
* 解决方案  
  * 使用`缓存集群`，增大可用性，当一个缓存挂了还有其他的缓存跟上。
  * 使用`Hystrix`，它是一款开源的“防雪崩工具”，它通过 熔断、降级、限流三个手段来降低雪崩发生后的损失。

### 缓存击穿

* 现象  
  指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，`当key失效的瞬间，且key值还没更新，持续的大并发就穿破缓存，直接请求数据库`，就像在一个屏障上凿开了一个洞。
* 危害    
  对于一些请求量极高的热点数据而言，一旦过了有效时间，此刻将会有大量请求落在数据库上，从而可能会导致数据库崩溃。
* 解决方案  
  * 使用`互斥锁`  
    上锁的对象为key，当失效后的第一个查询请求到来时，就会对缓存上锁，这时其他的查询请求就会被挡在外面，只有一个查询请求去访问数据库，直到缓存中更新了这个结果之后，剩余的查询请求才可查询缓存。
  * 对于很多热点数据集中失效，可以`设置不同的失效时间`，这样可以错开一部分热点数据的更新时间


## 消息队列

> [消息队列](https://www.cnblogs.com/linjiqin/p/5720865.html)  
> 消息队列主要解决了`应用耦合、异步处理、流量削锋`等问题。
> 当不需要立即获得结果，但是并发量又需要进行控制的时候，差不多就是需要使用消息队列的时候。


# Linux

## netstat

* ps

* 对 `find` 到的文件进行 `command` 操作
  ```sh
  find /your/path -type f -name "*.swf" -exec cp {} dest_path \;
  find . -name "*log" -print -exec rm -rf {} \;
  ```
